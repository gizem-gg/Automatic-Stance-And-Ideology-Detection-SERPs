{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65fa865-6abe-4fe5-a915-77bce4e0c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_utils():\n",
    "    # Get the GPU device name.\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    # The device name should look like the following:\n",
    "    if device_name == '/device:GPU:0':\n",
    "        print('Found GPU at: {}'.format(device_name))\n",
    "    else:\n",
    "        raise SystemError('GPU device not found')\n",
    "\n",
    "    device = None\n",
    "    # If there's a GPU available...\n",
    "    if torch.cuda.is_available():    \n",
    "        # Tell PyTorch to use the GPU.    \n",
    "        device = torch.device(\"cuda\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    # If not...\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260ec63-3bea-4ef2-8ce4-d95c6ba68ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seed():\n",
    "    return int.from_bytes(os.urandom(4), \"big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af06c65-1629-4de0-80ea-1e0596d5c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9cdbfc-b30c-4cef-a20b-8a16f2d516e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_emergent(path):\n",
    "    df = pd.read_csv(path, delimiter=',', header = 0, names=['', 'claimHeadline', 'articleHeadline', 'stance', 'articleID', 'claimID'])    \n",
    "    \n",
    "    #df[\"stance\"] = df[\"stance\"].replace({\"Pro\": \"0\", \"Agst\": \"1\", \"Neut\": \"2\", \"Not-rel\": \"3\"})\n",
    "    #df[\"stance\"] = df[\"stance\"].replace({\"Not-rel\": \"Notrel\"})\n",
    "\n",
    "    df['claimHeadline'] = df['claimHeadline'].str.lower()\n",
    "    df['articleHeadline'] = df['articleHeadline'].str.lower()\n",
    "    #df['title'] = df['title'].str.lower()\n",
    "    \n",
    "    df = df.astype({'claimHeadline': 'str'})\n",
    "    df = df.astype({'articleHeadline': 'str'})\n",
    "    df = df.astype({'articleID': 'str'})\n",
    "    df = df.astype({'claimID': 'str'})\n",
    "    \n",
    "    df[\"stance\"] = df[\"stance\"].replace({\"for\": \"Pro\", \"against\": \"Agst\", \"observing\": \"Neut\", \"not\": \"Not-rel\"})\n",
    "\n",
    "    \n",
    "    #df = df.drop('ideology', axis=1).copy(deep=True)\n",
    "    \n",
    "    print(df.iloc[0])\n",
    "    \n",
    "    print(df.dtypes)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cac74-6535-4b42-b96a-0dea3fd8d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_stance(path):\n",
    "    df = pd.read_csv(path, delimiter='\\t', header = 0, names=['qID', 'docID', 'stance', 'ideology', 'docCont', 'Q', 'title'])    \n",
    "    \n",
    "    #df[\"stance\"] = df[\"stance\"].replace({\"Pro\": \"0\", \"Agst\": \"1\", \"Neut\": \"2\", \"Not-rel\": \"3\"})\n",
    "    #df[\"stance\"] = df[\"stance\"].replace({\"Not-rel\": \"Notrel\"})\n",
    "\n",
    "    df['docCont'] = df['docCont'].str.lower()\n",
    "    df['Q'] = df['Q'].str.lower()\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    \n",
    "    df = df.astype({'docCont': 'str'})\n",
    "    df = df.astype({'Q': 'str'})\n",
    "    df = df.astype({'title': 'str'})\n",
    "    \n",
    "    df.insert(2, \"tokenized\", df[\"docCont\"].values)\n",
    "    df[\"tokenized\"] = df[\"tokenized\"].str.split()\n",
    "    \n",
    "    #df_notneut = df.loc[df[\"stance\"] != \"Neut\"]\n",
    "    #df_neut = df.loc[df[\"stance\"] == \"Neut\"]\n",
    "    \n",
    "    #print(df_neut.shape[0])\n",
    "    #df_neut = df_neut.sample(800)\n",
    "    #df_neut = df_neut[0:800]\n",
    "    \n",
    "    #df = df_notneut.append(df_neut, ignore_index = True)\n",
    "    mask = (df[\"tokenized\"].str.len() < 800) & (df[\"tokenized\"].str.len() > 50)\n",
    "    df = df.loc[mask]\n",
    "\n",
    "    print(df['ideology'])\n",
    "    print(\"**********\")\n",
    "    \n",
    "    df = df.drop('tokenized', axis=1).copy(deep=True)\n",
    "    \n",
    "    print(df.iloc[0])\n",
    "    \n",
    "    print(df.dtypes)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fda29-7790-4a53-80d4-aef6ecf00b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_ambigious(path):\n",
    "    # Load the dataset into a pandas dataframe.\n",
    "    df = pd.read_csv(path, delimiter='\\t', header=0, names=['qID', 'docID', 'Ambigious', 'stance', 'ideology', 'docCont', 'Q', 'title'])       \n",
    "\n",
    "    df['docCont'] = df['docCont'].str.lower()\n",
    "    #df['topic'] = df['topic'].str.lower()\n",
    "    df['Q'] = df['Q'].str.lower()\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    \n",
    "    df = df.astype(str)\n",
    "    \n",
    "    #df.insert(0, \"stanceStr\", df['stance'], True)\n",
    "    #df[\"stanceStr\"] = df[\"stanceStr\"].replace({1: \"Pro\", 0: \"Agst\"})\n",
    "    print(\"Train\")\n",
    "    print (\"Ambigious\", df[df['Ambigious'] == \"1\"].shape[0])\n",
    "    print (\"Non-ambigious\", df[df['Ambigious'] == \"0\"].shape[0])\n",
    "    \n",
    "    print(df.dtypes)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee89f2-9166-4edf-835b-47158c2c30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(df, dfVal):\n",
    "    from numpy import nan\n",
    "    dfTrain = df.append(dfVal, ignore_index = True)\n",
    "    \n",
    "    #df.replace(\"\", nan, inplace=True)\n",
    "    #df.replace(\" \", nan, inplace=True)\n",
    "    #df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "    \n",
    "    #dfLabel = df['ideology'].copy(deep=True)\n",
    "    #df = df.drop('ideology', axis=1).copy(deep=True)\n",
    "    \n",
    "    return dfTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f1890-7423-439b-a645-3a28d70067a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_more_notrel_docs(df):\n",
    "    #path = './dataset/batches_cleaned/stance/Latest_Merged_Batches.tsv'\n",
    "    \n",
    "    #df = pd.read_csv(path, delimiter='\\t', header = 0, names=['qID', 'docID', 'stance', 'docCont', 'Q', 'title'])\n",
    "    #df['docCont'] = df['docCont'].str.lower()\n",
    "    #df['Q'] = df['Q'].str.lower()\n",
    "    #df['title'] = df['title'].str.lower()\n",
    "    \n",
    "    df_pro = df[df['stance'] == \"Pro\"]\n",
    "    df_agst = df[df['stance'] == \"Agst\"]\n",
    "    df_neut = df[df['stance'] == \"Neut\"]\n",
    "    df_na = df[df['stance'] == \"Not-rel\"]\n",
    "    \n",
    "    pro_len = df_pro.shape[0]\n",
    "    agst_len = df_agst.shape[0]\n",
    "    neut_len = df_neut.shape[0]\n",
    "    not_rel_len = df_na.shape[0]\n",
    "    \n",
    "    print(\"Pro\", df_pro.shape[0])\n",
    "    print(\"Agst\", df_agst.shape[0])\n",
    "    print(\"Neut\", df_neut.shape[0])\n",
    "    print(\"Not-rel\", df_na.shape[0])\n",
    "    \n",
    "    print(\"before create more not-rel documents\")\n",
    "    \n",
    "    #neut_len = max(pro_len, agst_len)\n",
    "    rel_len = pro_len + agst_len + neut_len\n",
    "    all_len = rel_len + not_rel_len\n",
    "    rest = 0\n",
    "    \n",
    "    print(\"There are \" + str(rel_len) + \" rel instances in the original dataset!\")\n",
    "    print(\"There are \" + str(not_rel_len) + \" not-rel instances in the original dataset!\")\n",
    "    if rel_len > not_rel_len:\n",
    "        rest = rel_len - not_rel_len\n",
    "    else:\n",
    "        print(\"not_rel is bigger!\")\n",
    "        \n",
    "    print(\"There are \" + str(rest) + \" instances to be created!\")\n",
    "  \n",
    "     \n",
    "    path_queries = './dataset/batches_cleaned/stance/queries.tsv'\n",
    "    df_queries = pd.read_csv(path_queries, delimiter='\\t', header = 0, names=['qID', 'Q'])      \n",
    "    \n",
    "    \n",
    "    df_pro = df[df['stance'] == \"Pro\"]\n",
    "    df_agst = df[df['stance'] == \"Agst\"]\n",
    "    df_neut = df[df['stance'] == \"Neut\"]\n",
    "    df_na = df[df['stance'] == \"Not-rel\"]\n",
    "    \n",
    "    df_new = df_pro.append(df_agst, ignore_index = True)\n",
    "    df_new = df_new.append(df_neut, ignore_index = True)\n",
    "    #df_new = df_new.append(df_neut.sample(neut_len), ignore_index = True)\n",
    "    df_new = df_new.append(df_na, ignore_index = True)\n",
    "\n",
    "    \n",
    "    tot_count = rest #old:900\n",
    "    for idx in range(0, tot_count):\n",
    "        valueRow = randint(1, all_len)\n",
    "        valueQ = randint(1, 57)\n",
    "        \n",
    "        old_doc_inst = df.iloc[valueRow-1]\n",
    "        \n",
    "        while old_doc_inst['stance'] == \"Not-rel\" or old_doc_inst['stance'] == \"Pro\" or old_doc_inst['stance'] == \"Neut\":\n",
    "            valueRow = randint(1, all_len)\n",
    "            valueQ = randint(1, 57)\n",
    "            \n",
    "            old_doc_inst = df.iloc[valueRow-1]\n",
    "        \n",
    "        new_inst = old_doc_inst\n",
    "        new_q_row = df_queries.iloc[valueQ-1]\n",
    "\n",
    "        new_qID = new_q_row['qID']\n",
    "        while new_qID == old_doc_inst['qID']:\n",
    "            valueQ = randint(1, 57)\n",
    "            new_q_row = df_queries.iloc[valueQ-1]\n",
    "            new_qID = new_q_row['qID']\n",
    "                \n",
    "        new_inst['qID'] = new_qID\n",
    "        new_inst['Q'] = new_q_row['Q']\n",
    "        new_inst['stance'] = \"Not-rel\"\n",
    "        new_inst['ideology'] = 'No'\n",
    "            \n",
    "        df_new = df_new.append(new_inst, ignore_index = True)\n",
    "        \n",
    "    print(df_new.shape[0])\n",
    "\n",
    "    df_pro = df_new[df_new['stance'] == \"Pro\"]\n",
    "    df_agst = df_new[df_new['stance'] == \"Agst\"]\n",
    "    df_neut = df_new[df_new['stance'] == \"Neut\"]\n",
    "    df_na = df_new[df_new['stance'] == \"Not-rel\"]\n",
    "    \n",
    "    print(\"Pro\", df_pro.shape[0])\n",
    "    print(\"Agst\", df_agst.shape[0])\n",
    "    print(\"Neut\", df_neut.shape[0])\n",
    "    print(\"Not-rel\", df_na.shape[0])\n",
    "    \n",
    "    print(\"after create more not-rel documents\")\n",
    "    \n",
    "    \n",
    "    df_new.to_csv('./dataset/batches_cleaned/stance/Final_Dataset_AddedNotRelated.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294fcfe-2c6b-49c7-8bb2-0ecd1d7ffcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(model):\n",
    "    tokenizer = None\n",
    "    from transformers import BertTokenizer, RobertaTokenizer, XLNetTokenizer, DistilBertTokenizer, AlbertTokenizer\n",
    "    from transformers import AutoTokenizer, AutoConfig\n",
    "    \n",
    "    if 'roberta' in model:\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model)\n",
    "    elif 'distilbert' in model:\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "    elif 'albert' in model:\n",
    "        tokenizer = AlbertTokenizer.from_pretrained('albert-xxlarge-v2')\n",
    "    elif 'bert' in model:\n",
    "        tokenizer = BertTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "    elif 'xlnet' in model:\n",
    "        tokenizer = XLNetTokenizer.from_pretrained(model)\n",
    "    elif 'long' in model:\n",
    "        print(\"Long tokenizer\")\n",
    "        tokenizer = LongformerTokenizer.from_pretrained(model)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3909c-1fcf-4c31-9307-f053c8b0453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def predict_classwise_stance_bert(P_related, P_unrelated, P_stance, stance_labels, P_ideology, ideology_labels):\n",
    "    \n",
    "    target_labels = torch.argmax(torch.abs(stance_labels), 1)\n",
    "    predict_labels = torch.argmax(P_stance, 1)\n",
    "    \n",
    "    true_predict_count_ideology = 0\n",
    "    con_true = 0\n",
    "    lib_true = 0\n",
    "    na_true = 0\n",
    "    \n",
    "    agree_true = 0\n",
    "    agree_total = 0\n",
    "    \n",
    "    disagree_true = 0\n",
    "    disagree_total = 0\n",
    "    \n",
    "    discuss_true = 0\n",
    "    discuss_total = 0\n",
    "    \n",
    "    unrelated_true = 0\n",
    "    unrelated_total = 0\n",
    "    \n",
    "    for idx, true_label in enumerate(target_labels):\n",
    "        predict_label = predict_labels[idx] \n",
    "        if true_label == 0:\n",
    "            agree_total += 1\n",
    "            if predict_label == 0:\n",
    "                agree_true += 1\n",
    "        elif true_label == 1:\n",
    "            disagree_total += 1\n",
    "            if predict_label == 1:\n",
    "                disagree_true += 1\n",
    "        elif true_label == 2:\n",
    "            discuss_total += 1\n",
    "            if predict_label == 2:\n",
    "                discuss_true += 1\n",
    "        elif true_label == 3:\n",
    "            unrelated_total += 1\n",
    "            if predict_label == 3:\n",
    "                unrelated_true += 1\n",
    "        else:\n",
    "            print(\"Problem!!!!\")\n",
    "\n",
    "        \n",
    "    true_predict_count_stance= len((torch.eq(predict_labels, target_labels)).nonzero().flatten())\n",
    "\n",
    "\n",
    "    return true_predict_count_stance, agree_true, disagree_true, discuss_true, unrelated_true, true_predict_count_ideology, con_true, lib_true, na_true, predict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e3f52-48b1-463b-8781-e69b333ce076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def predict_classwise_stance_ideology_meta(P_relatedness, P_stance, stance_labels):\n",
    "\n",
    "    true_predict_count_ideology = 0\n",
    "    con_true = 0\n",
    "    lib_true = 0\n",
    "    na_true = 0\n",
    "    \n",
    "    P_related = torch.reshape(P_relatedness[:, 0], (-1, 1))\n",
    "    P_unrelated = torch.reshape(P_relatedness[:, 1], (-1, 1))\n",
    "    \n",
    "    tmp1 = P_stance[:,:3]\n",
    "    tmp2 = torch.reshape(torch.sum(tmp1,dim=1),[-1,1])\n",
    "    tmp3 = torch.cat([tmp2,tmp2,tmp2],dim=1)\n",
    "    tmp4 = torch.cat([P_related, P_related, P_related],dim=1)\n",
    "    tmp5 = torch.div(tmp1,tmp3)\n",
    "    tmp6 = tmp5*tmp4\n",
    "    prob_stance = torch.cat([tmp6,P_unrelated],1)#tmp6\n",
    "\n",
    "    \n",
    "    target_labels = torch.argmax(torch.abs(stance_labels), 1)\n",
    "    predict_labels = torch.argmax(prob_stance, 1)\n",
    "            \n",
    "    \n",
    "    agree_true = 0\n",
    "    agree_total = 0\n",
    "    \n",
    "    disagree_true = 0\n",
    "    disagree_total = 0\n",
    "    \n",
    "    discuss_true = 0\n",
    "    discuss_total = 0\n",
    "    \n",
    "    unrelated_true = 0\n",
    "    unrelated_total = 0\n",
    "    \n",
    "    for idx, true_label in enumerate(target_labels):\n",
    "        predict_label = predict_labels[idx] \n",
    "        if true_label == 0:\n",
    "            agree_total += 1\n",
    "            if predict_label == 0:\n",
    "                agree_true += 1\n",
    "        elif true_label == 1:\n",
    "            disagree_total += 1\n",
    "            if predict_label == 1:\n",
    "                disagree_true += 1\n",
    "        elif true_label == 2:\n",
    "            discuss_total += 1\n",
    "            if predict_label == 2:\n",
    "                discuss_true += 1\n",
    "        elif true_label == 3:\n",
    "            unrelated_total += 1\n",
    "            if predict_label == 3:\n",
    "                unrelated_true += 1\n",
    "        else:\n",
    "            print(\"Problem!!!!\")\n",
    "        \n",
    "    true_predict_count_stance= len((torch.eq(predict_labels, target_labels)).nonzero().flatten())    \n",
    "    true_total = agree_true + disagree_true + discuss_true + unrelated_true\n",
    "\n",
    "    return true_predict_count_stance, agree_true, disagree_true, discuss_true, unrelated_true, true_predict_count_ideology, con_true, lib_true, na_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0200a-f580-4d03-8671-35202f6260d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def predict_classwise_stance_ideology_bert(P_stance, stance_labels):\n",
    "\n",
    "    true_predict_count_ideology = 0\n",
    "    con_true = 0\n",
    "    lib_true = 0\n",
    "    na_true = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    #tmp1 = prob_stance[:,:2]\n",
    "    #tmp2 = torch.reshape(torch.sum(tmp1,dim=1),[-1,1])\n",
    "    #tmp3 = torch.cat([tmp2,tmp2],dim=1)\n",
    "    #tmp4 = torch.cat([P_oneside, P_oneside],dim=1)\n",
    "    #tmp5 = torch.div(tmp1,tmp3)\n",
    "    #tmp6 = tmp5*tmp4\n",
    "    #prob_stance_plus_existed = torch.cat([tmp6,P_noside,P_noside],1)#tmp6\n",
    "    \n",
    "    target_labels = torch.argmax(torch.abs(stance_labels), 1)\n",
    "    predict_labels = torch.argmax(P_stance, 1)\n",
    "    \n",
    "    #for idx in range(0, len(predict_labels)):\n",
    "        #max_val = max(prob_stance[idx])\n",
    "        #if max_val <= 0.5:\n",
    "            #predict_labels[idx] = 2\n",
    "            \n",
    "    \n",
    "    agree_true = 0\n",
    "    agree_total = 0\n",
    "    \n",
    "    disagree_true = 0\n",
    "    disagree_total = 0\n",
    "    \n",
    "    discuss_true = 0\n",
    "    discuss_total = 0\n",
    "    \n",
    "    unrelated_true = 0\n",
    "    unrelated_total = 0\n",
    "    \n",
    "    for idx, true_label in enumerate(target_labels):\n",
    "        predict_label = predict_labels[idx] \n",
    "        if true_label == 0:\n",
    "            agree_total += 1\n",
    "            if predict_label == 0:\n",
    "                agree_true += 1\n",
    "        elif true_label == 1:\n",
    "            disagree_total += 1\n",
    "            if predict_label == 1:\n",
    "                disagree_true += 1\n",
    "        elif true_label == 2:\n",
    "            discuss_total += 1\n",
    "            if predict_label == 2:\n",
    "                discuss_true += 1\n",
    "        elif true_label == 3:\n",
    "            unrelated_total += 1\n",
    "            if predict_label == 3:\n",
    "                unrelated_true += 1\n",
    "        else:\n",
    "            print(\"Problem!!!!\")\n",
    "        \n",
    "    true_predict_count_stance= len((torch.eq(predict_labels, target_labels)).nonzero().flatten())    \n",
    "    true_total = agree_true + disagree_true + discuss_true + unrelated_true\n",
    "\n",
    "    return true_predict_count_stance, agree_true, disagree_true, discuss_true, unrelated_true, true_predict_count_ideology, con_true, lib_true, na_true, P_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c270a78-8d07-493c-8593-20e285703c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def predict_classwise_stance_ideology(P_relatedness, P_stance, P_exisstance, stance_labels):\n",
    "\n",
    "    true_predict_count_ideology = 0\n",
    "    con_true = 0\n",
    "    lib_true = 0\n",
    "    na_true = 0\n",
    "    \n",
    "    \n",
    "    P_related = torch.reshape(P_relatedness[:, 0], (-1, 1))\n",
    "    P_unrelated = torch.reshape(P_relatedness[:, 1], (-1, 1))\n",
    "    \n",
    "    tmp1 = P_stance[:,:3]\n",
    "    tmp2 = torch.reshape(torch.sum(tmp1,dim=1),[-1,1])\n",
    "    tmp3 = torch.cat([tmp2,tmp2,tmp2],dim=1)\n",
    "    tmp4 = torch.cat([P_related, P_related, P_related],dim=1)\n",
    "    tmp5 = torch.div(tmp1,tmp3)\n",
    "    tmp6 = tmp5*tmp4\n",
    "    prob_stance = torch.cat([tmp6,P_unrelated],1)#tmp6\n",
    "    \n",
    "    \n",
    "    #existed-stance layer\n",
    "    #P_oneside = torch.reshape(P_exisstance[:, 0], (-1, 1))\n",
    "    #P_noside = torch.reshape(P_exisstance[:, 1], (-1, 1)) #discuss\n",
    "    \n",
    "    #tmp1 = prob_stance[:,:2]\n",
    "    #tmp2 = torch.reshape(torch.sum(tmp1,dim=1),[-1,1])\n",
    "    #tmp3 = torch.cat([tmp2,tmp2],dim=1)\n",
    "    #tmp4 = torch.cat([P_oneside, P_oneside],dim=1)\n",
    "    #tmp5 = torch.div(tmp1,tmp3)\n",
    "    #tmp6 = tmp5*tmp4\n",
    "    #prob_stance_plus_existed = torch.cat([tmp6,P_noside,P_noside],1)#tmp6\n",
    "    \n",
    "    target_labels = torch.argmax(torch.abs(stance_labels), 1)\n",
    "    predict_labels = torch.argmax(prob_stance, 1)\n",
    "    \n",
    "    #for idx in range(0, len(predict_labels)):\n",
    "        #max_val = max(prob_stance[idx])\n",
    "        #if max_val <= 0.5:\n",
    "            #predict_labels[idx] = 2\n",
    "            \n",
    "    \n",
    "    agree_true = 0\n",
    "    agree_total = 0\n",
    "    \n",
    "    disagree_true = 0\n",
    "    disagree_total = 0\n",
    "    \n",
    "    discuss_true = 0\n",
    "    discuss_total = 0\n",
    "    \n",
    "    unrelated_true = 0\n",
    "    unrelated_total = 0\n",
    "    \n",
    "    for idx, true_label in enumerate(target_labels):\n",
    "        predict_label = predict_labels[idx] \n",
    "        if true_label == 0:\n",
    "            agree_total += 1\n",
    "            if predict_label == 0:\n",
    "                agree_true += 1\n",
    "        elif true_label == 1:\n",
    "            disagree_total += 1\n",
    "            if predict_label == 1:\n",
    "                disagree_true += 1\n",
    "        elif true_label == 2:\n",
    "            discuss_total += 1\n",
    "            if predict_label == 2:\n",
    "                discuss_true += 1\n",
    "        elif true_label == 3:\n",
    "            unrelated_total += 1\n",
    "            if predict_label == 3:\n",
    "                unrelated_true += 1\n",
    "        else:\n",
    "            print(\"Problem!!!!\")\n",
    "        \n",
    "    true_predict_count_stance= len((torch.eq(predict_labels, target_labels)).nonzero().flatten())    \n",
    "    true_total = agree_true + disagree_true + discuss_true + unrelated_true\n",
    "\n",
    "    return true_predict_count_stance, agree_true, disagree_true, discuss_true, unrelated_true, true_predict_count_ideology, con_true, lib_true, na_true, prob_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914bcd6-06ca-464c-87fb-40494e9b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_class_num(df):\n",
    "    pro_num = 0\n",
    "    agst_num = 0\n",
    "    neut_num = 0\n",
    "    notrel_num = 0\n",
    "    \n",
    "    if len(df.columns) == 4:\n",
    "        \n",
    "        pro_num = len(df[df[0] == 1])\n",
    "        agst_num = len(df[df[1] == 1])\n",
    "        neut_num = len(df[df[2] == 1])\n",
    "        notrel_num = len(df[df[3] == 1])\n",
    "    else:\n",
    "        df_pro = df[df['stance'] == \"Pro\"]\n",
    "        df_agst = df[df['stance'] == \"Agst\"]\n",
    "        df_neut = df[df['stance'] == \"Neut\"]\n",
    "        df_na = df[df['stance'] == \"Not-rel\"]\n",
    "        \n",
    "        pro_num = (df_pro.shape[0])\n",
    "        agst_num = (df_agst.shape[0])\n",
    "        neut_num = (df_neut.shape[0])\n",
    "        notrel_num = (df_na.shape[0])\n",
    "        \n",
    "    return [pro_num, agst_num, neut_num, notrel_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad3a8a-5538-48b0-87d2-f2b37101cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_class_num_ideology(df):\n",
    "    df_con = df[df['ideology'] == \"Con\"]\n",
    "    df_lib = df[df['ideology'] == \"Lib\"]\n",
    "    df_na = df[df['ideology'] == \"No\"]\n",
    " \n",
    "    return [df_con.shape[0], df_lib.shape[0], df_na.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf8b10-03f2-45e6-aff2-78aa5436ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_class_num_ambigious(df):\n",
    "    df_A = df[df['Ambigious'] == \"1\"]\n",
    "    df_N = df[df['Ambigious'] == \"0\"]\n",
    " \n",
    "    return [df_A.shape[0], df_N.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7d470-cd11-4c83-bc30-b6862bd76ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_query_wise(df):\n",
    "    query_docs = {}\n",
    "    for idx in range(0, df.shape[0]):\n",
    "        doc_inst = df.iloc[idx]\n",
    "        my_q = doc_inst[\"Q\"]\n",
    "        if my_q not in query_docs.keys():\n",
    "            query_docs[my_q] = []\n",
    "            query_docs[my_q].append(doc_inst)\n",
    "        else:\n",
    "            query_docs[my_q].append(doc_inst)\n",
    "        \n",
    "    return query_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7de75-0d37-4459-91d4-7b7553b42ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset_ambigious(df, seedVal):\n",
    "    #create_determinism(seedVal)\n",
    "    \n",
    "    df_A = df[df['Ambigious'] == \"1\"]\n",
    "    df_N = df[df['Ambigious'] == \"0\"]\n",
    "    \n",
    "    print(df.shape[0])\n",
    "    \n",
    "    df_new = df_A.append(df_N, ignore_index = True)\n",
    "\n",
    "    y_copy = df_new['Ambigious'].copy(deep=True)\n",
    "    X_copy = df_new.drop('Ambigious', axis=1).copy(deep=True)\n",
    "    \n",
    "    X = pd.DataFrame (columns=['qID', 'docID', 'stance', 'ideology', 'docCont', 'Q', 'title'])\n",
    "    y = pd.DataFrame (columns=['Ambigious'])\n",
    "    \n",
    "    X = X_copy\n",
    "    y = y_copy\n",
    "    \n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    \n",
    "    print(len(X_train))\n",
    "    print(len(y_train))\n",
    "    print(len(X_test))\n",
    "    print(len(y_test))\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle=True)\n",
    "    \n",
    "    X_train.insert(2, \"Ambigious\", y_train.values) \n",
    "    X_val.insert(2, \"Ambigious\", y_val.values) \n",
    "    X_test.insert(2, \"Ambigious\", y_test.values)\n",
    "    \n",
    "    \n",
    "    df_A = X_train[X_train['Ambigious'] == \"1\"]\n",
    "    df_N = X_train[X_train['Ambigious'] == \"0\"]\n",
    "    \n",
    "    \n",
    "    print(\"****Train****\")\n",
    "    print(\"Ambigious\", df_A.shape[0])\n",
    "    print(\"Not Ambigious\", df_N.shape[0])\n",
    "    \n",
    "    \n",
    "    df_A = X_test[X_test['Ambigious'] == \"1\"]\n",
    "    df_N = X_test[X_test['Ambigious'] == \"0\"]\n",
    "    \n",
    "    print(\"****Test****\")\n",
    "    print(\"Ambigious\", df_A.shape[0])\n",
    "    print(\"Not Ambigious\", df_N.shape[0])\n",
    "    \n",
    "    X_train.to_csv('./dataset/batches_cleaned/stance/train_serp_ambigious.tsv', sep='\\t', index=False)\n",
    "    X_val.to_csv('./dataset/batches_cleaned/stance/val_serp_ambigious.tsv', sep='\\t', index=False)\n",
    "    X_test.to_csv('./dataset/batches_cleaned/stance/test_serp_ambigious.tsv', sep='\\t', index=False)\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e03f07-18ed-4ab7-8914-2cdeb2418c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset_stance(df, seedVal):\n",
    "    #create_determinism(seedVal)\n",
    "    \n",
    "    df_pro = df[df['stance'] == \"Pro\"]\n",
    "    df_agst = df[df['stance'] == \"Agst\"]\n",
    "    df_neut = df[df['stance'] == \"Neut\"]\n",
    "    df_na = df[df['stance'] == \"Not-rel\"]\n",
    "    \n",
    "    df_con = df[df['ideology'] == \"Con\"]\n",
    "    df_lib = df[df['ideology'] == \"Lib\"]\n",
    "    df_no = df[df['ideology'] == \"No\"]\n",
    "    \n",
    "    \n",
    "    df_neut = df_neut\n",
    "\n",
    "    \n",
    "    print(\"Pro\", df_pro.shape[0])\n",
    "    print(\"Agst\", df_agst.shape[0])\n",
    "    print(\"Neut\", df_neut.shape[0])\n",
    "    print(\"Not-rel\", df_na.shape[0])\n",
    "    \n",
    "    print(\"Con\", df_con.shape[0])\n",
    "    print(\"Lib\", df_lib.shape[0])\n",
    "    print(\"NA\", df_no.shape[0])\n",
    "    \n",
    "    df_new = df_pro.append(df_agst, ignore_index = True)\n",
    "    df_new = df_new.append(df_neut, ignore_index = True)\n",
    "    df_new = df_new.append(df_na, ignore_index = True)\n",
    "\n",
    "    y_copy = df_new['stance'].copy(deep=True)\n",
    "    X_copy = df_new.drop('stance', axis=1).copy(deep=True)\n",
    "    \n",
    "    X = pd.DataFrame (columns=['qID', 'docID', 'ideology', 'docCont' 'Q', 'title'])\n",
    "    y = pd.DataFrame (columns=['stance'])\n",
    "    \n",
    "    X = X_copy\n",
    "    y = y_copy\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    \n",
    "    print(len(X_train))\n",
    "    print(len(y_train))\n",
    "    print(len(X_test))\n",
    "    print(len(y_test))\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle=True)\n",
    "    \n",
    "    X_train.insert(2, \"stance\", y_train.values) \n",
    "    X_val.insert(2, \"stance\", y_val.values) \n",
    "    X_test.insert(2, \"stance\", y_test.values)\n",
    "    \n",
    "    \n",
    "    df_pro = X_train[X_train['stance'] == \"Pro\"]\n",
    "    df_agst = X_train[X_train['stance'] == \"Agst\"]\n",
    "    df_neut = X_train[X_train['stance'] == \"Neut\"]\n",
    "    df_na = X_train[X_train['stance'] == \"Not-rel\"]\n",
    "    \n",
    "    \n",
    "    print(\"****Train****\")\n",
    "    print(\"Pro\", df_pro.shape[0])\n",
    "    print(\"Agst\", df_agst.shape[0])\n",
    "    print(\"Neut\", df_neut.shape[0])\n",
    "    print(\"Not-rel\", df_na.shape[0])\n",
    "    \n",
    "    \n",
    "    df_pro = X_test[X_test['stance'] == \"Pro\"]\n",
    "    df_agst = X_test[X_test['stance'] == \"Agst\"]\n",
    "    df_neut = X_test[X_test['stance'] == \"Neut\"]\n",
    "    df_na = X_test[X_test['stance'] == \"Not-rel\"]\n",
    "    \n",
    "    print(\"****Test****\")\n",
    "    print(\"Pro\", df_pro.shape[0])\n",
    "    print(\"Agst\", df_agst.shape[0])\n",
    "    print(\"Neut\", df_neut.shape[0])\n",
    "    print(\"Not-rel\", df_na.shape[0])\n",
    "    \n",
    "    X_train.to_csv('./dataset/batches_cleaned/stance/train_serp.tsv', sep='\\t', index=False)\n",
    "    X_val.to_csv('./dataset/batches_cleaned/stance/val_serp.tsv', sep='\\t', index=False)\n",
    "    X_test.to_csv('./dataset/batches_cleaned/stance/test_serp.tsv', sep='\\t', index=False)\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289a1da-f7fd-4261-b43a-22cbad410ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ideology_ambigious(ambigious_labels):\n",
    "    t_ideology = []\n",
    "\n",
    "    for idx, a_label in enumerate(ambigious_labels):\n",
    "        a_label = ambigious_labels[idx]\n",
    "        if a_label == \"0\": #con\n",
    "            t_ideology.append([0])\n",
    "        else:#lib\n",
    "            t_ideology.append([1])\n",
    "            \n",
    "    t_ideology = torch.as_tensor(t_ideology, dtype=torch.int32)\n",
    "    \n",
    "    return t_ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e3387-6810-4292-b5ee-1c152948ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stance_ideology_new(s_labels, i_labels):\n",
    "    t_relatedness = []\n",
    "    t_stance = []\n",
    "    \n",
    "    t_existedstance = []\n",
    "    t_ideology = []\n",
    "    \n",
    "    t_mmd_symbol = []\n",
    "    t_mmd_symbol_ = []\n",
    "    \n",
    "    #print(labels.shape)\n",
    "        \n",
    "\n",
    "    for idx, s_label in enumerate(s_labels):\n",
    "        i_label = i_labels[idx]\n",
    "        if s_label == \"Not-rel\": #unrelated\n",
    "            t_relatedness.append([0,1])\n",
    "            t_stance.append([0,0,0,1])\n",
    "            t_mmd_symbol.append(0)\n",
    "            t_mmd_symbol_.append(1)\n",
    "            t_existedstance.append([0,1])\n",
    "            t_ideology.append([0,0,1])\n",
    "        elif s_label == \"Pro\": #agree\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([1,0,0,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "            t_existedstance.append([1,0])\n",
    "            if i_label == \"Con\":\n",
    "                t_ideology.append([1,0,0])\n",
    "            elif i_label == \"Lib\":\n",
    "                t_ideology.append([0,1,0])\n",
    "            else:\n",
    "                t_ideology.append([0,0,1])\n",
    "        elif s_label == \"Agst\": #disagree\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([0,1,0,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "            t_existedstance.append([1,0])\n",
    "            if i_label == \"Con\":\n",
    "                t_ideology.append([1,0,0])\n",
    "            elif i_label == \"Lib\":\n",
    "                t_ideology.append([0,1,0])\n",
    "            else:\n",
    "                t_ideology.append([0,0,1])\n",
    "        elif s_label == \"Neut\": #discuss\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([0,0,1,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "            t_existedstance.append([0,1])\n",
    "            t_ideology.append([0,0,1])\n",
    "        else:\n",
    "            print(\"Error-labels\", s_label, i_label)\n",
    "            \n",
    "    \n",
    "    t_relatedness = torch.as_tensor(t_relatedness, dtype=torch.int32)\n",
    "    t_stance = torch.as_tensor(t_stance, dtype=torch.int32)\n",
    "    t_existedstance = torch.as_tensor(t_existedstance, dtype=torch.int32)\n",
    "    t_ideology = torch.as_tensor(t_ideology, dtype=torch.int32)\n",
    "    \n",
    "    t_mmd_symbol  = torch.as_tensor(t_mmd_symbol, dtype=torch.float32)\n",
    "    t_mmd_symbol_ = torch.as_tensor(t_mmd_symbol_, dtype=torch.float32)\n",
    "    \n",
    "    return t_relatedness, t_stance, t_mmd_symbol, t_mmd_symbol_, t_existedstance, t_ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b00de-2303-47b5-a34f-d4802573c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stance_ideology_meta(s_labels):\n",
    "    \n",
    "    t_stance = []\n",
    "    for idx, s_label in enumerate(s_labels):\n",
    "        if s_label == \"Not-rel\": #unrelated\n",
    "            t_stance.append([0,0,0,1])\n",
    "        elif s_label == \"Pro\": #agree\n",
    "            t_stance.append([1,0,0,0])\n",
    "        elif s_label == \"Agst\": #disagree\n",
    "            t_stance.append([0,1,0,0])\n",
    "        elif s_label == \"Neut\": #discuss\n",
    "            t_stance.append([0,0,1,0])\n",
    "        else:\n",
    "            print(\"Error-labels\", s_label)\n",
    "\n",
    "    return t_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6349a3-94f6-447d-8767-42560eadbff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stance_ideology_new_meta(s_labels):\n",
    "    t_relatedness = []\n",
    "    t_stance = []\n",
    "    \n",
    "    t_mmd_symbol = []\n",
    "    t_mmd_symbol_ = []\n",
    "        \n",
    "    num_rows = s_labels.shape[0]\n",
    "    for idx in range(0, num_rows):\n",
    "        row = s_labels.iloc[idx]\n",
    "        if row[3] == -1 or row[3] == 1: #unrelated\n",
    "            t_relatedness.append([0,1])\n",
    "            t_stance.append([0,0,0,1])\n",
    "            t_mmd_symbol.append(0)\n",
    "            t_mmd_symbol_.append(1)\n",
    "        elif row[0] == 1: #agree\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([1,0,0,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "        elif row[1] == 1: #disagree\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([0,1,0,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "        elif row[2] == 1: #discuss\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([0,0,1,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "        else:\n",
    "            print(\"Error-labels\")\n",
    "            \n",
    "    \n",
    "    t_relatedness = torch.as_tensor(t_relatedness, dtype=torch.int32)\n",
    "    t_stance = torch.as_tensor(t_stance, dtype=torch.int32)\n",
    "    \n",
    "    t_mmd_symbol  = torch.as_tensor(t_mmd_symbol, dtype=torch.float32)\n",
    "    t_mmd_symbol_ = torch.as_tensor(t_mmd_symbol_, dtype=torch.float32)\n",
    "    \n",
    "    return t_relatedness, t_stance, t_mmd_symbol, t_mmd_symbol_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a993da-3757-4849-94a0-7ea1f4922239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stance_ideology(s_labels, i_labels):\n",
    "    t_relatedness = []\n",
    "    t_stance = []\n",
    "    \n",
    "    t_existedstance = []\n",
    "    t_ideology = []\n",
    "    \n",
    "    t_mmd_symbol = []\n",
    "    t_mmd_symbol_ = []\n",
    "    \n",
    "    #print(labels.shape)\n",
    "        \n",
    "\n",
    "    for idx, s_label in enumerate(s_labels):\n",
    "        i_label = \"Con\"\n",
    "        if s_label == \"Not-rel\": #unrelated\n",
    "            t_relatedness.append([0,1])\n",
    "            t_stance.append([0,0,0,1])\n",
    "            t_mmd_symbol.append(0)\n",
    "            t_mmd_symbol_.append(1)\n",
    "            t_existedstance.append([0,1])\n",
    "            t_ideology.append([0,0,1])\n",
    "        elif s_label == \"Pro\": #agree\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([1,0,0,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "            t_existedstance.append([1,0])\n",
    "            if i_label == \"Con\":\n",
    "                t_ideology.append([1,0,0])\n",
    "            elif i_label == \"Lib\":\n",
    "                t_ideology.append([0,1,0])\n",
    "            else:\n",
    "                t_ideology.append([0,0,1])\n",
    "        elif s_label == \"Agst\": #disagree\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([0,1,0,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "            t_existedstance.append([1,0])\n",
    "            if i_label == \"Con\":\n",
    "                t_ideology.append([1,0,0])\n",
    "            elif i_label == \"Lib\":\n",
    "                t_ideology.append([0,1,0])\n",
    "            else:\n",
    "                t_ideology.append([0,0,1])\n",
    "        elif s_label == \"Neut\": #discuss\n",
    "            t_relatedness.append([1,0])\n",
    "            t_stance.append([0,0,1,0])\n",
    "            t_mmd_symbol.append(1)\n",
    "            t_mmd_symbol_.append(0)\n",
    "            t_existedstance.append([0,1])\n",
    "            t_ideology.append([0,0,1])\n",
    "        else:\n",
    "            print(\"Error-labels\", s_label, i_label)\n",
    "            \n",
    "    \n",
    "    t_relatedness = torch.as_tensor(t_relatedness, dtype=torch.int32)\n",
    "    t_stance = torch.as_tensor(t_stance, dtype=torch.int32)\n",
    "    t_existedstance = torch.as_tensor(t_existedstance, dtype=torch.int32)\n",
    "    t_ideology = torch.as_tensor(t_ideology, dtype=torch.int32)\n",
    "    \n",
    "    t_mmd_symbol  = torch.as_tensor(t_mmd_symbol, dtype=torch.float32)\n",
    "    t_mmd_symbol_ = torch.as_tensor(t_mmd_symbol_, dtype=torch.float32)\n",
    "    \n",
    "    return t_relatedness, t_stance, t_mmd_symbol, t_mmd_symbol_, t_existedstance, t_ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15051ae1-f5e9-4d2a-a9ee-7947a04970a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concanListStringsLonger(list1, list2):\n",
    "    list3 = []\n",
    "    myLen1 = len(list1)\n",
    "    if myLen1 != len(list2):\n",
    "        print(\"Length - error\")\n",
    "    for idx in range(0, myLen1):\n",
    "        list3.append(list1[idx] + \" \" + list2[idx])\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0d4d3-e84c-496d-b4f0-4ae8269a9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concanListStringsLonger2(list1, list2):\n",
    "    list3 = []\n",
    "    myLen1 = len(list1)\n",
    "    if myLen1 != len(list2):\n",
    "        print(\"Length - error\")\n",
    "    for idx in range(0, myLen1):\n",
    "        list3.append(list1[idx] + \" GIZEM \" + list2[idx])\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3b129-7707-4787-8d5e-3941562ed0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concanListStrings(list1, list2):\n",
    "    list3 = []\n",
    "    new_labels = []\n",
    "    myLen1 = len(list1)\n",
    "    if myLen1 != len(list2):\n",
    "        print(\"Length - error\")\n",
    "    for idx in range(0, myLen1):\n",
    "        list3.append(list1[idx] + \" \" + list2[idx])\n",
    "        #list3.append(list1[idx] + \" \" + list2[idx][-512:])\n",
    "        #new_labels.append(labels[idx])\n",
    "        #new_labels.append(labels[idx])\n",
    "        \n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ffba1-d5dc-490a-b893-0cfcfb7a773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concanListStrings_sep(list1, list2):\n",
    "    list3 = []\n",
    "    myLen1 = len(list1)\n",
    "    if myLen1 != len(list2):\n",
    "        print(\"Length - error\")\n",
    "   # list3 = list(zip(list1, list2))\n",
    "    for idx in range(0, myLen1):\n",
    "        list3.append((list1[idx], list2[idx]))\n",
    "        #list3.append(list1[idx], list2[idx])\n",
    "\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ced100-a4fa-4995-a5bd-d058048074db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the datasets with the different fields.\n",
    "def generate_datasets_ambigious(df):\n",
    "\n",
    "    sentencesQuery= df.Q.values\n",
    "    sentencesTitle = df.title.values\n",
    "    sentencesCont = df.docCont.values\n",
    "\n",
    "    labels = df.Ambigious.values\n",
    "    labels_stances = df.stance.values\n",
    "    \n",
    "    #print(stances[0:10])\n",
    "\n",
    "    sentencesQueryTitle = concanListStrings(sentencesQuery, sentencesTitle)\n",
    "    sentencesQueryTitleCont = concanListStringsLonger(sentencesQueryTitle, sentencesCont)\n",
    "\n",
    "    return sentencesQueryTitle, sentencesQueryTitleCont, labels, labels_stances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9cd1d-1a18-416e-9376-d786b84fc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the datasets with the different fields.\n",
    "def generate_datasets_emergent(df):\n",
    "\n",
    "    sentencesQuery = df.claimHeadline.values #claim in this case\n",
    "    sentencesTitle = df.articleHeadline.values\n",
    "    labels = df.stance.values\n",
    "\n",
    "    sentencesQueryTitle = concanListStrings_sep(sentencesQuery, sentencesTitle)\n",
    "\n",
    "    return sentencesQueryTitle, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba161291-464b-4973-8b5c-bdc2ee765376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the datasets with the different fields.\n",
    "def generate_datasets(df):\n",
    "\n",
    "    sentencesQuery = df.Q.values #claim in this case\n",
    "    sentencesTitle = df.title.values\n",
    "    labels = df.stance.values\n",
    "    labels_ideology = df.ideology.values\n",
    "    #df.ideology.values\n",
    "    \n",
    "    sentencesCont = df.docCont.values\n",
    "\n",
    "    sentencesQueryTitle = concanListStrings(sentencesQuery, sentencesTitle)\n",
    "    sentencesTitleCont = concanListStrings(sentencesTitle, sentencesCont)\n",
    "    sentencesQueryTitleCont = concanListStrings(sentencesQuery, sentencesTitleCont)        \n",
    "        \n",
    "    \n",
    "\n",
    "    return sentencesQueryTitle, sentencesQueryTitleCont, labels, labels_ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb7294-1aaa-40f4-a8dd-d6fdc6980896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert(tokenizer, docs, max_len, doc_stride, long = False):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    input_ids_last = []\n",
    "    attention_masks_last = []\n",
    "    \n",
    "    content_input_ids = {}\n",
    "    \n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in docs:\n",
    "        #print(sent)\n",
    "        #print(sentences[0])\n",
    "        #print(sentences[1])\n",
    "        \n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        \n",
    "        if not long:\n",
    "            encoded_sent = tokenizer.encode_plus (\n",
    "                sent,  # Preprocess sentence\n",
    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "                max_length=64,                  # Max length to truncate/pad\n",
    "                #padding='longest',         # Pad sentence to max length\n",
    "                pad_to_max_length = True,\n",
    "                return_tensors='pt',           # Return PyTorch tensor\n",
    "                return_attention_mask=True      # Return attention mask\n",
    "                )\n",
    "            # Add the outputs to the lists\n",
    "            input_ids.append(encoded_sent['input_ids'])\n",
    "            attention_masks.append(encoded_sent['attention_mask'])\n",
    "        else:\n",
    "            input_ids.append(torch.tensor(tokenizer.encode(sent, padding=True)))\n",
    "            input_ids_pd = pd.DataFrame(input_ids)\n",
    "            attention_masks.append(torch.ones(input_ids_pd.shape, dtype=torch.long))\n",
    "\n",
    "        \n",
    "        # Print the original sentence.\n",
    "        #print(' Original: ', sent)\n",
    "\n",
    "        # Print the sentence split into tokens.\n",
    "        #print('Tokenized: ', input_ids)\n",
    "        \n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    # Print sentence 0, now as a list of IDs.\n",
    "    #print('Original: ', docs[0])\n",
    "    #print('Token IDs:', input_ids[0])\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a0e3a-aed7-45cc-9c18-470dde3b08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.val_acc_max_stance = -1\n",
    "        self.val_acc_max_ideology = -1\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, val_acc_stance, val_acc_ideology, model_save_state, model_save_path, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, val_acc_stance, val_acc_ideology, model_save_state, model_save_path, model)\n",
    "            self.val_acc_max_stance = val_acc_stance\n",
    "            self.val_acc_max_ideology = val_acc_ideology\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            #self.save_checkpoint(val_loss, val_acc_stance, val_acc_ideology, model_save_state, model_save_path, model, tokenizer)\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, val_acc_stance, val_acc_ideology, model_save_state, model_save_path, model)\n",
    "            self.val_acc_max_stance = val_acc_stance\n",
    "            self.val_acc_max_ideology = val_acc_ideology\n",
    "            self.counter = 0\n",
    "\n",
    "            #self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_loss, val_acc_stance, val_acc_ideology, model_save_state, model_save_path, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            print(f'Validation acc stance : ({self.val_acc_max_stance:.6f} --> {val_acc_stance:.6f}).  Saving model ...')\n",
    "            print(f'Validation acc ideology : ({self.val_acc_max_ideology:.6f} --> {val_acc_ideology:.6f}).  Saving model ...')\n",
    "        #torch.save(model.module.state_dict(), 'checkpoint.pt')\n",
    "        \n",
    "        #torch.save(model_save_state, model_save_path)\n",
    "        torch.save(model_save_state, model_save_path)  \n",
    "        \n",
    "        #tokenizer.save_pretrained('model_save/')\n",
    "        # Good practice: save your training arguments together with the trained model\n",
    "        #torch.save(model, './model_save/entire_model.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35e74c-a195-4be8-bf6b-3ec84fd5700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, RobertaModel\n",
    "class AmbigiousDetectionClass(torch.nn.Module):\n",
    "    def __init__(self, modelUsed):\n",
    "        super(AmbigiousDetectionClass, self).__init__()\n",
    "        input_size = 768\n",
    "        hidden_size = 768\n",
    "        mmd_size = 10\n",
    "        dropout_prob = 0.1\n",
    "        relatedness_size = 2\n",
    "        classes_size = 1\n",
    "        #agreement_size = 3\n",
    "        \n",
    "        self.input_pl = RobertaModel.from_pretrained(modelUsed) #input\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.bn1_hidden = torch.nn.BatchNorm1d(hidden_size, momentum=0.05)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.theta_d = torch.nn.Linear(hidden_size, mmd_size)\n",
    "        self.bn1_theta = torch.nn.BatchNorm1d(mmd_size, momentum=0.05)\n",
    "        \n",
    "        self.probability = torch.nn.Linear(hidden_size, relatedness_size)\n",
    "        self.output_prob = torch.nn.Softmax(dim = 1)\n",
    "        self.output_binary = torch.nn.Sigmoid()\n",
    "        self.stance = torch.nn.Linear(hidden_size, classes_size)\n",
    "\n",
    "        #self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        relatedness_size = 2\n",
    "        classes_size = 1\n",
    "        \n",
    "        input_1 = self.input_pl(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        input_1 = input_1[0]    \n",
    "        input_1 = input_1[:, 0]\n",
    "        \n",
    "        #hidden layer\n",
    "        #hidden_state = self.l1(input_1)\n",
    "        #hidden_state_normalized = self.bn1_hidden(hidden_state)\n",
    "        #hidden_state_normalized = torch.nn.ReLU()(hidden_state_normalized)\n",
    "        #hidden_layer= self.dropout(hidden_state_normalized)\n",
    "\n",
    "        stance_state = self.stance(input_1) #batch size x classes_size\n",
    "        stance_flat = self.dropout(stance_state) #batch size x classes_size\n",
    "        \n",
    "        #stance_flat_reshaped = torch.reshape(stance_flat, (-1, classes_size))\n",
    "        P_stance = self.output_prob(stance_flat)\n",
    "        \n",
    "        #output = self.classifier(hidden_state)\n",
    "        return P_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89c5df-6c9b-4020-9543-2bbd835d852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, RobertaModel, DistilBertModel\n",
    "class StanceMetaLearnerSimple(torch.nn.Module):\n",
    "    def __init__(self, datasetUsed):\n",
    "        super(StanceMetaLearnerSimple, self).__init__()\n",
    "        input_size = len(datasetUsed[0])\n",
    "        hidden_size = 10\n",
    "        dropout_prob = 0.5\n",
    "        classes_size = 4\n",
    "        mmd_size = 10\n",
    "        relatedness_size = 2\n",
    "\n",
    "        #self.input_pl = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.output_prob = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.stance = torch.nn.Linear(hidden_size, classes_size)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, mmd_pl, mmd_pl_):\n",
    "        \n",
    "        relatedness_size = 2\n",
    "        classes_size = 4        \n",
    "        \n",
    "        #hidden layer\n",
    "        hidden_state = self.l1(input_ids)    \n",
    "        stance_state = self.stance(hidden_state) #batch size x classes_size\n",
    "        P_stance = self.output_prob(stance_state)\n",
    "\n",
    "        return P_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a18e21-be20-44ec-850f-8dbfeb504740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, RobertaModel, DistilBertModel\n",
    "class StanceDetectionUnigramClass(torch.nn.Module):\n",
    "    def __init__(self, datasetUsed):\n",
    "        super(StanceDetectionUnigramClass, self).__init__()\n",
    "        input_size = len(datasetUsed[0])\n",
    "        hidden_size_initial = 20\n",
    "        hidden_size = 20\n",
    "        mmd_size = 10\n",
    "        dropout_prob = 0.6\n",
    "        dropout_prob2 = 0.6\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        ideology_class_size = 3\n",
    "        #agreement_size = 3\n",
    "        #self.input_pl = BertForPreTraining.from_pretrained(modelUsed) #input\n",
    "        #self.input_pl = BertModel.from_pretrained(modelUsed)\n",
    "        #self.input_pl = RobertaModel.from_pretrained(modelUsed)\n",
    "        #self.input_pl = DistilBertModel.from_pretrained(modelUsed)\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size_initial)\n",
    "        self.l2 = torch.nn.Linear(hidden_size_initial, hidden_size)\n",
    "        self.l3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.bn1_hidden = torch.nn.BatchNorm1d(hidden_size_initial, momentum=0.05)\n",
    "        self.bn2_hidden = torch.nn.BatchNorm1d(hidden_size, momentum=0.05)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = torch.nn.Dropout(dropout_prob2)\n",
    "\n",
    "        self.theta_d = torch.nn.Linear(hidden_size, mmd_size)\n",
    "        self.bn1_theta = torch.nn.BatchNorm1d(mmd_size, momentum=0.05)\n",
    "        \n",
    "        self.probability = torch.nn.Linear(hidden_size, relatedness_size)\n",
    "        self.output_prob = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.stance = torch.nn.Linear(hidden_size + relatedness_size - 1, classes_size)\n",
    "        self.ideology = torch.nn.Linear(hidden_size + classes_size - 2, ideology_class_size)\n",
    "        \n",
    "        #for param in self.input_pl.embeddings.parameters():\n",
    "            #param.requires_grad = False\n",
    "        \n",
    "        #for param in self.input_pl[2][0:5].parameters():\n",
    "            #param.requires_grad = False\n",
    "\n",
    "        #self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, mmd_pl, mmd_pl_):\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        ideology_class_size = 3\n",
    "        \n",
    "        #hidden layer\n",
    "        hidden_state = self.l1(input_ids)\n",
    "        hidden_state_normalized = self.bn1_hidden(hidden_state)\n",
    "        hidden_state_normalized = torch.nn.ReLU()(hidden_state_normalized)\n",
    "        hidden_layer= self.dropout2(hidden_state_normalized)\n",
    "    \n",
    "        #mmd layer        \n",
    "        theta_d = self.theta_d(hidden_layer)\n",
    "        theta_d_normalized = self.bn1_theta(theta_d)\n",
    "        theta_d_normalized = torch.nn.ReLU()(theta_d_normalized)\n",
    "        theta_d_layer= self.dropout2(theta_d_normalized)\n",
    "        \n",
    "        \n",
    "        n1 = torch.sum(mmd_pl, dim = 0) + 1e-10\n",
    "        n2 = torch.sum(mmd_pl_, dim = 0)  + 1e-10\n",
    "        aa = torch.reshape(mmd_pl, (-1,1))\n",
    "        bb = torch.reshape(mmd_pl_, (-1,1))\n",
    "        \n",
    "        #calculate mmd_loss                  \n",
    "        d1 = torch.div(torch.sum(torch.mul(theta_d_layer, aa), dim=1), n1)\n",
    "        d2 = torch.div(torch.sum(torch.mul(theta_d_layer, bb), dim=1), n2)\n",
    "                             \n",
    "        mmd_loss = torch.sum(d1 - d2)\n",
    "\n",
    "        #probability layer\n",
    "        relatedness_state = self.probability(hidden_layer)\n",
    "        relatedness_flat = self.dropout2(relatedness_state)\n",
    "        \n",
    "        relatedness_flat_reshaped = torch.reshape(relatedness_flat, (-1, relatedness_size))\n",
    "        P_relatedness = self.output_prob(relatedness_flat_reshaped)\n",
    "        #P_relatedness = relatedness_flat_reshaped\n",
    "        \n",
    "        P_related = torch.reshape(P_relatedness[:, 0], (-1, 1))\n",
    "        P_unrelated = torch.reshape(P_relatedness[:, 1], (-1, 1))\n",
    "        \n",
    "        #stance layer\n",
    "        concat_fea = torch.cat([hidden_layer, P_related], dim = 1)\n",
    "        stance_state = self.stance(concat_fea) #batch size x classes_size\n",
    "        stance_flat = self.dropout2(stance_state) #batch size x classes_size\n",
    "        \n",
    "        stance_flat_reshaped = torch.reshape(stance_flat, (-1, classes_size))\n",
    "        P_stance = self.output_prob(stance_flat_reshaped) \n",
    "        \n",
    "\n",
    "        return mmd_loss, P_relatedness, P_stance, P_related, P_unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb25437-20e0-4205-a090-c0c0a98ae2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, RobertaModel\n",
    "class StanceDetectionClassBERTBiLSTM(torch.nn.Module):\n",
    "    def __init__(self, modelUsed):\n",
    "        super(StanceDetectionClassBERTBiLSTM, self).__init__()\n",
    "        input_size = 128\n",
    "        hidden_size = 128\n",
    "        lstm_hidden_size = 32\n",
    "        linear_size = 32\n",
    "        mmd_size = 10\n",
    "        dropout_prob = 0.6\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        #agreement_size = 3\n",
    "        #self.input_pl = BertForPreTraining.from_pretrained(modelUsed) #input\n",
    "        #self.input_pl = BertModel.from_pretrained(modelUsed)\n",
    "        self.input_pl = RobertaModel.from_pretrained(modelUsed)\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(hidden_size, lstm_hidden_size, bidirectional = True)\n",
    "        self.bn1_hidden = torch.nn.BatchNorm1d(lstm_hidden_size*2, momentum=0.05)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.hidden = torch.nn.Linear(lstm_hidden_size*2, linear_size)\n",
    "        \n",
    "        self.probability = torch.nn.Linear(hidden_size, relatedness_size)\n",
    "        self.output_prob = torch.nn.Softmax(dim = 1)\n",
    "        self.stance = torch.nn.Linear(linear_size, classes_size)\n",
    "\n",
    "        #self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, mmd_pl, mmd_pl_):\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        \n",
    "        input_1 = self.input_pl(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #for param in self.input_pl.parameters():\n",
    "            #param.requires_grad = False\n",
    "            \n",
    "        ##for name, param in model.named_parameters():\n",
    "        #    if 'classifier' not in name: # classifier layer\n",
    "        #        param.requires_grad = False\n",
    "\n",
    "        input_1 = input_1[0]\n",
    "        input_1 = input_1[:, 0]\n",
    "        \n",
    "        lstm_out, _ = self.lstm(input_1.view(len(input_ids), 1, -1))\n",
    "        lstm_out_reshaped = lstm_out.view(len(input_ids), -1)\n",
    "        \n",
    "        #BiLSTM hidden layer\n",
    "        #hidden_state = self.bilstm(input_1_lstm)\n",
    "        hidden_state_normalized = self.bn1_hidden(lstm_out_reshaped)\n",
    "        hidden_state_normalized = torch.nn.ReLU()(hidden_state_normalized)\n",
    "        hidden_layer= self.dropout(hidden_state_normalized)\n",
    "        \n",
    "        hidden_layer = self.hidden(hidden_layer)\n",
    "\n",
    "        stance_state = self.stance(hidden_layer) #batch size x classes_size\n",
    "        stance_flat = self.dropout(stance_state) #batch size x classes_size\n",
    "        \n",
    "        stance_flat_reshaped = torch.reshape(stance_flat, (-1, classes_size))\n",
    "        P_stance = self.output_prob(stance_flat_reshaped)\n",
    "\n",
    "        return P_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc529f-f50e-49fc-b882-84ef0a070632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, RobertaModel, DistilBertModel, AlbertModel, XLNetModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "class StanceIdeologyDetectionClassPrev(torch.nn.Module):\n",
    "    def __init__(self, modelUsed):\n",
    "        super(StanceIdeologyDetectionClassPrev, self).__init__()\n",
    "        input_size = 1024\n",
    "        hidden_size_initial = 100\n",
    "        hidden_size = 50\n",
    "        mmd_size = 10\n",
    "        dropout_prob = 0.1\n",
    "        dropout_prob2 = 0.1\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        exist_stance_size = 2\n",
    "        ideology_class_size = 3\n",
    "        \n",
    "        self.input_pl = None\n",
    "        if 'roberta' in modelUsed:\n",
    "            self.input_pl = RobertaModel.from_pretrained(modelUsed)\n",
    "        elif 'distilbert' in modelUsed:\n",
    "            self.input_pl = DistilBertModel.from_pretrained(modelUsed)\n",
    "        elif 'albert' in modelUsed:\n",
    "            self.input_pl = AlbertModel.from_pretrained(modelUsed)\n",
    "        elif 'bert' in modelUsed:\n",
    "            self.input_pl = BertModel.from_pretrained(modelUsed)\n",
    "        elif 'xlnet' in modelUsed:\n",
    "            input_size = 1024\n",
    "            self.input_pl = XLNetModel.from_pretrained(modelUsed)\n",
    "\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size_initial)\n",
    "        self.l2 = torch.nn.Linear(hidden_size_initial, hidden_size)\n",
    "        self.l3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.bn1_hidden = torch.nn.BatchNorm1d(hidden_size_initial, momentum=0.05)\n",
    "        self.bn2_hidden = torch.nn.BatchNorm1d(hidden_size, momentum=0.05)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        self.relu = torch.nn.ReLU(hidden_size)\n",
    "\n",
    "        self.theta_d = torch.nn.Linear(hidden_size, mmd_size)\n",
    "        self.bn1_theta = torch.nn.BatchNorm1d(mmd_size, momentum=0.05)\n",
    "        self.relu_theta = torch.nn.ReLU(mmd_size)\n",
    "    \n",
    "        self.probability = torch.nn.Linear(hidden_size, relatedness_size)\n",
    "        self.probability_existstance = torch.nn.Linear(hidden_size, exist_stance_size)\n",
    "        self.output_prob = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.stance = torch.nn.Linear(hidden_size + relatedness_size + exist_stance_size - 2, classes_size)\n",
    "        self.stance2 = torch.nn.Linear(hidden_size, classes_size)\n",
    "        self.existstance = torch.nn.Linear(hidden_size + relatedness_size + exist_stance_size - 1, exist_stance_size)\n",
    "        self.ideology = torch.nn.Linear(hidden_size + classes_size - 2, ideology_class_size)\n",
    "        \n",
    "        #for param in self.input_pl.embeddings.parameters():\n",
    "            #param.requires_grad = False\n",
    "        \n",
    "        #for param in self.input_pl[2][0:5].parameters():\n",
    "            #param.requires_grad = False\n",
    "\n",
    "        #self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, mmd_pl, mmd_pl_):\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        exist_stance_size = 2\n",
    "        ideology_class_size = 3\n",
    "\n",
    "        \n",
    "        input_1 = self.input_pl(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        last_hidden_state_cls = input_1[0][:, 0, :]\n",
    "    \n",
    "        frozen_layer_list = [0, 1, 2, 3]\n",
    "        params = list(self.input_pl.named_parameters())\n",
    "    \n",
    "        #hidden layer\n",
    "        hidden_state = self.l1(last_hidden_state_cls)\n",
    "        hidden_state_normalized = self.bn1_hidden(hidden_state)\n",
    "        hidden_state_normalized = self.relu(hidden_state_normalized)\n",
    "        hidden_layer= self.dropout(hidden_state_normalized)\n",
    "        \n",
    "        #hidden layer\n",
    "        hidden_state = self.l2(hidden_layer)\n",
    "        hidden_state_normalized = self.bn2_hidden(hidden_state)\n",
    "        hidden_state_normalized = self.relu(hidden_state_normalized)\n",
    "        hidden_layer= self.dropout(hidden_state_normalized)\n",
    "        \n",
    "        #hidden layer\n",
    "        hidden_state = self.l3(hidden_layer)\n",
    "        hidden_state_normalized = self.bn2_hidden(hidden_state)\n",
    "        hidden_state_normalized = self.relu(hidden_state_normalized)\n",
    "        hidden_layer= self.dropout(hidden_state_normalized)\n",
    "        \n",
    "        stance_state = self.stance2(hidden_layer) #batch size x classes_size\n",
    "        P_stance = self.output_prob(stance_state) \n",
    "\n",
    "        return P_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94effaa4-6bc2-4e88-8517-01d4aaaa88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, RobertaModel, DistilBertModel, AlbertModel, XLNetModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "class StanceIdeologyDetectionClassMixout(nn.Module):\n",
    "    def __init__(self, modelUsed):\n",
    "        super(StanceIdeologyDetectionClassMixout, self).__init__()\n",
    "        input_size = 1024\n",
    "        hidden_size_initial = 100\n",
    "        hidden_size = 100\n",
    "        hidden_size2 = 100\n",
    "        mmd_size = 10\n",
    "        dropout_prob = 0.6\n",
    "        dropout_prob2 = 0.1\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        exist_stance_size = 2\n",
    "        ideology_class_size = 3\n",
    "        \n",
    "        if 'roberta' in modelUsed:\n",
    "            self.input_pl = RobertaModel.from_pretrained(modelUsed)\n",
    "        elif 'distilbert' in modelUsed:\n",
    "            self.input_pl = DistilBertModel.from_pretrained(modelUsed)\n",
    "        elif 'albert' in modelUsed:\n",
    "            self.input_pl = AlbertModel.from_pretrained(modelUsed)\n",
    "        elif 'bert' in modelUsed:\n",
    "            self.input_pl = BertModel.from_pretrained(modelUsed)\n",
    "        elif 'xlnet' in modelUsed:\n",
    "            self.input_pl = XLNetModel.from_pretrained(modelUsed)\n",
    "        elif 'long' in modelUsed:\n",
    "            self.input_pl = LongformerModel.from_pretrained(modelUsed, gradient_checkpointing=True)\n",
    "\n",
    "\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size_initial)\n",
    "        self.l2 = torch.nn.Linear(hidden_size_initial, hidden_size)\n",
    "        self.l3 = torch.nn.Linear(hidden_size, hidden_size2)\n",
    "        \n",
    "        self.bn1_hidden = torch.nn.BatchNorm1d(hidden_size_initial, momentum=0.05)\n",
    "        self.bn2_hidden = torch.nn.BatchNorm1d(hidden_size, momentum=0.05)\n",
    "        self.bn3_hidden = torch.nn.BatchNorm1d(hidden_size2, momentum=0.05)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = torch.nn.Dropout(dropout_prob2)\n",
    "        \n",
    "        self.leaky = torch.nn.LeakyReLU(hidden_size_initial)\n",
    "        self.relu = torch.nn.ReLU(hidden_size_initial)\n",
    "        self.relu2 = torch.nn.ReLU(hidden_size)\n",
    "        self.relu3 = torch.nn.ReLU(hidden_size2)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "        self.theta_d = torch.nn.Linear(hidden_size_initial, mmd_size)\n",
    "        self.theta_d2 = torch.nn.Linear(mmd_size, mmd_size)\n",
    "        self.bn1_theta = torch.nn.BatchNorm1d(mmd_size, momentum=0.05)\n",
    "        self.relu_theta = torch.nn.ReLU(mmd_size)\n",
    "        self.leaky_theta = torch.nn.LeakyReLU(mmd_size)\n",
    "        self.gelu_theta = torch.nn.GELU()\n",
    "    \n",
    "        self.probability = torch.nn.Linear(hidden_size_initial, relatedness_size)\n",
    "        self.probability_existstance = torch.nn.Linear(hidden_size2, exist_stance_size)\n",
    "        self.output_prob = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.stance = torch.nn.Linear(hidden_size_initial + relatedness_size - 1, classes_size)\n",
    "        self.stance2 = torch.nn.Linear(input_size, classes_size)\n",
    "        #self.existstance = torch.nn.Linear(hidden_size + relatedness_size + exist_stance_size - 1, exist_stance_size)\n",
    "        \n",
    "        #for param in self.input_pl.embeddings.parameters():\n",
    "            #param.requires_grad = False\n",
    "        \n",
    "        #for param in self.input_pl[2][0:5].parameters():\n",
    "            #param.requires_grad = False\n",
    "\n",
    "        #self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, mmd_pl, mmd_pl_, epoch_num):\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        exist_stance_size = 2\n",
    "        ideology_class_size = 3\n",
    "        \n",
    "        input_1 = self.input_pl(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        last_hidden_state_cls = input_1[0][:, 0, :]\n",
    "    \n",
    "                        \n",
    "        #for param in self.input_pl.parameters():\n",
    "            #param.requires_grad = False\n",
    "        \n",
    "        \n",
    "        frozen_layer_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "        new_frozen_layers = frozen_layer_list\n",
    "        #if (epoch_num  % 12) != 0:\n",
    "            #new_frozen_layers = frozen_layer_list[-((epoch_num%12)-1):]\n",
    "            \n",
    "        #params = list(self.input_pl.named_parameters())\n",
    "        #for name, param in params:\n",
    "        #    if 'embeddings' in name:\n",
    "         #       param.requires_grad = False\n",
    "            #if 'encoder.layer' in name:\n",
    "            #for layer_num in new_frozen_layers:\n",
    "                #if str(layer_num) in name:\n",
    "                    #param.requires_grad = True\n",
    "        \n",
    "        #for name, param in params:\n",
    "            #if 'encoder' not in name: # classifier layer\n",
    "                #param.requires_grad = False\n",
    "        \n",
    "        #freeze_layer_count = 9\n",
    "        #for layer in self.input_pl.bert.encoder.layer[:freeze_layer_count]:\n",
    "            #for param in layer.parameters():\n",
    "                #param.requires_grad = False\n",
    "\n",
    "            \n",
    "        ##for name, param in model.named_parameters():\n",
    "        #    if 'classifier' not in name: # classifier layer\n",
    "        #        param.requires_grad = False\n",
    "\n",
    "        #input_1 = input_1[0]\n",
    "        #input_1 = input_1[:, 0]\n",
    "\n",
    "        \n",
    "        #bert_hidden_states = input_1[2]\n",
    "        #print(len(bert_hidden_states))\n",
    "        \n",
    "        #sentence_embedding = torch.mean(bert_hidden_states[-1], dim=1).squeeze()\n",
    "        #print(sentence_embedding)\n",
    "        #print(sentence_embedding.size())\n",
    "        \n",
    "        \n",
    "        # get last four layers\n",
    "        #last_four_layers = [bert_hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        # cast layers to a tuple and concatenate over the last dimension\n",
    "        #cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "        #print(cat_hidden_states.size())\n",
    "        \n",
    "        \n",
    "        #print(\"**********\")\n",
    "\n",
    "        # take the mean of the concatenated vector over the token dimension\n",
    "        #cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "        #print(cat_sentence_embedding)\n",
    "        #print(cat_sentence_embedding.size())\n",
    "        \n",
    "        #hidden layer\n",
    "        hidden_state = self.l1(last_hidden_state_cls)\n",
    "        hidden_state_normalized = self.bn1_hidden(hidden_state)\n",
    "        hidden_state_normalized = self.relu(hidden_state_normalized)\n",
    "        hidden_layer= self.dropout(hidden_state_normalized)\n",
    "        \n",
    "        #concat_hidd_inp = torch.cat([last_hidden_state_cls, hidden_layer], dim = 1)     \n",
    "\n",
    "        #concat_hidd_inp_2 = torch.cat([last_hidden_state_cls, hidden_layer], dim = 1)\n",
    "        \n",
    "        #hidden layer\n",
    "        #hidden_state = self.l2(hidden_layer)\n",
    "        #hidden_state_normalized = self.bn3_hidden(hidden_state)\n",
    "        #hidden_state_normalized = self.relu(hidden_state_normalized)\n",
    "        #hidden_layer= self.dropout(hidden_state_normalized)\n",
    "        \n",
    "        #concat_hidd_inp_3 = torch.cat([last_hidden_state_cls, hidden_layer], dim = 1)\n",
    "        \n",
    "        #mmd layer        \n",
    "        theta_d = self.theta_d(hidden_layer)\n",
    "        theta_d_normalized = self.bn1_theta(theta_d)\n",
    "        theta_d_normalized = self.relu_theta(theta_d_normalized)\n",
    "        theta_d_layer= self.dropout(theta_d_normalized)\n",
    "        #theta_d_layer = theta_d_normalized\n",
    "        \n",
    "        #+ 1e-10\n",
    "        n1 = torch.sum(mmd_pl, dim = 0) + 1e-3\n",
    "        n2 = torch.sum(mmd_pl_, dim = 0)  + 1e-3\n",
    "        aa = torch.reshape(mmd_pl, (-1,1))\n",
    "        bb = torch.reshape(mmd_pl_, (-1,1))\n",
    "        \n",
    "        #calculate mmd_loss                  \n",
    "        d1 = torch.div(torch.sum(torch.mul(theta_d_layer, aa), dim=1), n1)\n",
    "        d2 = torch.div(torch.sum(torch.mul(theta_d_layer, bb), dim=1), n2)\n",
    "                             \n",
    "        mmd_loss = torch.sum(d1 - d2)\n",
    "        \n",
    "        #probability layer\n",
    "        relatedness_state = self.probability(hidden_layer)\n",
    "        relatedness_flat = self.dropout2(relatedness_state)\n",
    "        #relatedness_flat = relatedness_state\n",
    "        \n",
    "        relatedness_flat_reshaped = torch.reshape(relatedness_flat, (-1, relatedness_size))\n",
    "        P_relatedness = self.output_prob(relatedness_flat_reshaped)\n",
    "        \n",
    "        P_related = torch.reshape(P_relatedness[:, 0], (-1, 1))\n",
    "        P_unrelated = torch.reshape(P_relatedness[:, 1], (-1, 1))\n",
    "        \n",
    "        #********************#\n",
    "\n",
    "        P_exist_stance = P_related\n",
    "        \n",
    "        #stance layer\n",
    "        concat_fea = torch.cat([hidden_layer, P_related], dim = 1)        \n",
    "        stance_state = self.stance(concat_fea) #batch size x classes_size\n",
    "        stance_flat = self.dropout2(stance_state) #batch size x classes_size\n",
    "        #stance_flat = stance_state\n",
    "        \n",
    "        #stance_flat_reshaped = torch.reshape(stance_flat, (-1, classes_size))\n",
    "        #P_stance = self.output_prob(stance_flat_reshaped)\n",
    "        \n",
    "        #stance_state = self.stance2(last_hidden_state_cls) #batch size x classes_size\n",
    "        #stance_flat = self.dropout(stance_state) #batch size x classes_size\n",
    "        P_stance = self.output_prob(stance_flat) \n",
    "\n",
    "        return mmd_loss, P_relatedness, P_stance, P_exist_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7cc1bf-4b4c-4db2-856d-109a72d03a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, RobertaModel, DistilBertModel, AlbertModel, XLNetModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "class StanceIdeologyDetectionClass(torch.nn.Module):\n",
    "    def __init__(self, modelUsed):\n",
    "        super(StanceIdeologyDetectionClass, self).__init__()\n",
    "        input_size = 1024\n",
    "        hidden_size_initial = 100\n",
    "        hidden_size = 100\n",
    "        hidden_size2 = 50\n",
    "        mmd_size = 10\n",
    "        dropout_prob = 0.4\n",
    "        dropout_prob2 = 0.4\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        exist_stance_size = 2\n",
    "        ideology_class_size = 3\n",
    "        \n",
    "        self.input_pl = None\n",
    "        if 'roberta' in modelUsed:\n",
    "            self.input_pl = RobertaModel.from_pretrained(modelUsed)\n",
    "        elif 'distilbert' in modelUsed:\n",
    "            self.input_pl = DistilBertModel.from_pretrained(modelUsed)\n",
    "        elif 'albert' in modelUsed:\n",
    "            self.input_pl = AlbertModel.from_pretrained(modelUsed)\n",
    "        elif 'bert' in modelUsed:\n",
    "            self.input_pl = BertModel.from_pretrained(modelUsed)\n",
    "        elif 'xlnet' in modelUsed:\n",
    "            self.input_pl = XLNetModel.from_pretrained(modelUsed)\n",
    "\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size_initial)\n",
    "        self.l2 = torch.nn.Linear(hidden_size_initial, hidden_size)\n",
    "        self.l3 = torch.nn.Linear(hidden_size, hidden_size2)\n",
    "        self.bn1_hidden = torch.nn.BatchNorm1d(hidden_size_initial, momentum=0.05)\n",
    "        self.bn2_hidden = torch.nn.BatchNorm1d(hidden_size, momentum=0.05)\n",
    "        self.bn3_hidden = torch.nn.BatchNorm1d(hidden_size2, momentum=0.05)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        self.relu = torch.nn.ReLU(hidden_size_initial)\n",
    "        self.relu2 = torch.nn.ReLU(hidden_size)\n",
    "        self.relu3 = torch.nn.ReLU(hidden_size2)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "        self.theta_d = torch.nn.Linear(hidden_size, mmd_size)\n",
    "        self.theta_d2 = torch.nn.Linear(mmd_size, mmd_size)\n",
    "        self.bn1_theta = torch.nn.BatchNorm1d(mmd_size, momentum=0.05)\n",
    "        self.relu_theta = torch.nn.ReLU(mmd_size)\n",
    "        self.gelu_theta = torch.nn.GELU()\n",
    "    \n",
    "        self.probability = torch.nn.Linear(hidden_size, relatedness_size)\n",
    "        self.probability_existstance = torch.nn.Linear(hidden_size, exist_stance_size)\n",
    "        self.output_prob = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.stance = torch.nn.Linear(hidden_size + relatedness_size + exist_stance_size - 2, classes_size)\n",
    "        self.existstance = torch.nn.Linear(hidden_size + relatedness_size + exist_stance_size - 1, exist_stance_size)\n",
    "        self.ideology = torch.nn.Linear(hidden_size + classes_size - 2, ideology_class_size)\n",
    "        \n",
    "        #for param in self.input_pl.embeddings.parameters():\n",
    "            #param.requires_grad = False\n",
    "        \n",
    "        #for param in self.input_pl[2][0:5].parameters():\n",
    "            #param.requires_grad = False\n",
    "\n",
    "        #self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, mmd_pl, mmd_pl_, epoch_num):\n",
    "        relatedness_size = 2\n",
    "        classes_size = 4\n",
    "        exist_stance_size = 2\n",
    "        ideology_class_size = 3\n",
    "        \n",
    "        input_1 = self.input_pl(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        last_hidden_state_cls = input_1[0][:, 0, :]\n",
    "    \n",
    "                        \n",
    "        for param in self.input_pl.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        \n",
    "        frozen_layer_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "        new_frozen_layers = frozen_layer_list\n",
    "        if (epoch_num  % 12) != 0:\n",
    "            new_frozen_layers = frozen_layer_list[-((epoch_num%12)-1):]\n",
    "            \n",
    "        params = list(self.input_pl.named_parameters())\n",
    "        for name, param in params:\n",
    "        #    if 'embeddings' in name:\n",
    "         #       param.requires_grad = False\n",
    "            #if 'encoder.layer' in name:\n",
    "            for layer_num in new_frozen_layers:\n",
    "                if str(layer_num) in name:\n",
    "                    param.requires_grad = True\n",
    "        \n",
    "        #for name, param in params:\n",
    "            #if 'encoder' not in name: # classifier layer\n",
    "                #param.requires_grad = False\n",
    "        \n",
    "        #freeze_layer_count = 9\n",
    "        #for layer in self.input_pl.bert.encoder.layer[:freeze_layer_count]:\n",
    "            #for param in layer.parameters():\n",
    "                #param.requires_grad = False\n",
    "\n",
    "            \n",
    "        ##for name, param in model.named_parameters():\n",
    "        #    if 'classifier' not in name: # classifier layer\n",
    "        #        param.requires_grad = False\n",
    "\n",
    "        #input_1 = input_1[0]\n",
    "        #input_1 = input_1[:, 0]\n",
    "\n",
    "        \n",
    "        #bert_hidden_states = input_1[2]\n",
    "        #print(len(bert_hidden_states))\n",
    "        \n",
    "        #sentence_embedding = torch.mean(bert_hidden_states[-1], dim=1).squeeze()\n",
    "        #print(sentence_embedding)\n",
    "        #print(sentence_embedding.size())\n",
    "        \n",
    "        \n",
    "        # get last four layers\n",
    "        #last_four_layers = [bert_hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        # cast layers to a tuple and concatenate over the last dimension\n",
    "        #cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "        #print(cat_hidden_states.size())\n",
    "        \n",
    "        \n",
    "        #print(\"**********\")\n",
    "\n",
    "        # take the mean of the concatenated vector over the token dimension\n",
    "        #cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "        #print(cat_sentence_embedding)\n",
    "        #print(cat_sentence_embedding.size())\n",
    "        \n",
    "        #hidden layer\n",
    "        hidden_state = self.l1(last_hidden_state_cls)\n",
    "        hidden_state_normalized = self.bn1_hidden(hidden_state)\n",
    "        hidden_state_normalized = self.relu(hidden_state_normalized)\n",
    "        hidden_layer= self.dropout(hidden_state_normalized)\n",
    "        \n",
    "        #mmd layer        \n",
    "        theta_d = self.theta_d(hidden_layer)\n",
    "        theta_d_normalized = self.bn1_theta(theta_d)\n",
    "        theta_d_normalized = self.relu_theta(theta_d_normalized)\n",
    "        theta_d_layer= self.dropout(theta_d_normalized)\n",
    "        \n",
    "        #+ 1e-10\n",
    "        n1 = torch.sum(mmd_pl, dim = 0) + 1e-3\n",
    "        n2 = torch.sum(mmd_pl_, dim = 0)  + 1e-3\n",
    "        aa = torch.reshape(mmd_pl, (-1,1))\n",
    "        bb = torch.reshape(mmd_pl_, (-1,1))\n",
    "        \n",
    "        #calculate mmd_loss                  \n",
    "        d1 = torch.div(torch.sum(torch.mul(theta_d_layer, aa), dim=1), n1)\n",
    "        d2 = torch.div(torch.sum(torch.mul(theta_d_layer, bb), dim=1), n2)\n",
    "                             \n",
    "        mmd_loss = torch.sum(d1 - d2)\n",
    "        \n",
    "        #probability layer\n",
    "        relatedness_state = self.probability(hidden_layer)\n",
    "        relatedness_flat = self.dropout(relatedness_state)\n",
    "        \n",
    "        relatedness_flat_reshaped = torch.reshape(relatedness_flat, (-1, relatedness_size))\n",
    "        P_relatedness = self.output_prob(relatedness_flat_reshaped)\n",
    "        \n",
    "        P_related = torch.reshape(P_relatedness[:, 0], (-1, 1))\n",
    "        P_unrelated = torch.reshape(P_relatedness[:, 1], (-1, 1))\n",
    "        \n",
    "        #********************#\n",
    "        \n",
    "        #probability layer - exist stance\n",
    "        exist_stance = self.probability_existstance(hidden_layer)\n",
    "        exist_stance_flat = self.dropout(exist_stance)\n",
    "        \n",
    "        exist_stance_flat_reshaped = torch.reshape(exist_stance_flat, (-1, exist_stance_size))\n",
    "        P_exist_stance = self.output_prob(exist_stance_flat_reshaped)\n",
    "        \n",
    "        #existed-stance layer\n",
    "        P_existedstance = torch.reshape(P_exist_stance[:, 0], (-1, 1))\n",
    "        P_notexistedstance = torch.reshape(P_exist_stance[:, 1], (-1, 1)) #discuss\n",
    "        \n",
    "        #********************#\n",
    "        \n",
    "        #stance layer\n",
    "        concat_fea = torch.cat([hidden_layer, P_related, P_existedstance], dim = 1)        \n",
    "        stance_state = self.stance(concat_fea) #batch size x classes_size\n",
    "        stance_flat = self.dropout(stance_state) #batch size x classes_size\n",
    "        \n",
    "        stance_flat_reshaped = torch.reshape(stance_flat, (-1, classes_size))\n",
    "        P_stance = self.output_prob(stance_flat_reshaped) \n",
    "\n",
    "        return mmd_loss, P_relatedness, P_stance, P_exist_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8e701-19c5-4995-b876-25e72ed866d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install adabelief-pytorch==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9a310-f4ac-4141-9aa0-f987c2082f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "def prepare_for_training_ambigious(input_idsTrain, attention_masksTrain, ideology_labels_Train, input_idsVal, attention_masksVal, \n",
    "                                   ideology_labels_Val, modelUsed, batch_size=16, epochs = 50, num_warmup_steps=0, learning_rate=5e-5):\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "\n",
    "    from transformers import BertForSequenceClassification, AdamW, BertConfig, RobertaConfig, AutoModelWithLMHead\n",
    "    from transformers import DistilBertForSequenceClassification, RobertaForSequenceClassification\n",
    "    \n",
    "    from torch.utils.data import DataLoader, RandomSampler\n",
    "    \n",
    "    t_train_stance = preprocess_ideology_ambigious(ideology_labels_Train)\n",
    "    \n",
    "    datasetTrain = TensorDataset(input_idsTrain, attention_masksTrain, t_train_stance)\n",
    "\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "    t_val_stance  = preprocess_ideology_ambigious(ideology_labels_Val)\n",
    "    \n",
    "    \n",
    "    datasetVal = TensorDataset(input_idsVal, attention_masksVal, t_val_stance)\n",
    "    \n",
    "    model = AmbigiousDetectionClass(modelUsed)\n",
    "\n",
    "    # Tell pytorch to run this model on the GPU.\n",
    "    model.cuda()\n",
    "\n",
    "    # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "    # I believe the 'W' stands for 'Weight Decay fix\"\n",
    "    \n",
    "    \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  betas=(0.9, 0.999), \n",
    "                  eps=1e-08, \n",
    "                  weight_decay=1e-3,\n",
    "                  correct_bias=True\n",
    "               )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            datasetTrain,  # The training samples.\n",
    "            sampler =  RandomSampler(datasetTrain), # Select batches randomly\n",
    "            batch_size = batch_size, # Trains with this batch size., \n",
    "            num_workers=8\n",
    "        )\n",
    "    batch_size = batch_size\n",
    "\n",
    "\n",
    "    from transformers import get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "    # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "    # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "    # training data.\n",
    "    epochs = epochs\n",
    "\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "    # (Note that this is not the same as the number of training samples).\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Create the learning rate scheduler.\n",
    "    schedulerOld = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "    \n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps, num_cycles = 5)\n",
    "    \n",
    "    loss_fct = torch.nn.BCELoss()\n",
    "    return model, datasetTrain, datasetVal, optimizer, schedulerOld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92225b93-204e-4cdf-89f0-95a293e4876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "def prepare_for_training_stance_ideology_metalearner(instancesTrain, labelsTrain, instancesVal, labelsVal, batch_size=16, epochs = 50, num_warmup_steps=0, learning_rate=5e-5):\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "\n",
    "    epochs = 1000\n",
    "    from transformers import BertForSequenceClassification, AdamW, BertConfig, RobertaConfig, AutoModelWithLMHead\n",
    "    from transformers import DistilBertForSequenceClassification, RobertaForSequenceClassification\n",
    "    \n",
    "    from torch.utils.data import DataLoader, RandomSampler\n",
    "    \n",
    "    t_instancesTrain = torch.as_tensor(instancesTrain.to_numpy(), dtype=torch.float32)\n",
    "    t_train_relatedness, t_train_stance, t_train_mmd_symbol, t_train_mmd_symbol_ = preprocess_stance_ideology_new_meta(labelsTrain)\n",
    "    datasetTrain = TensorDataset(t_instancesTrain, t_train_relatedness, t_train_stance, t_train_mmd_symbol, t_train_mmd_symbol_)\n",
    "    #print(labelsTrain)\n",
    "\n",
    "    #t_labels_train = torch.as_tensor(labelsTrain.to_numpy(), dtype=torch.int64)\n",
    "    #t_instancesTrain  = torch.as_tensor(instancesTrain, dtype=torch.float32)\n",
    "\n",
    "    #datasetTrain = TensorDataset(t_instancesTrain, t_labels_train)\n",
    "\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "    t_instancesVal = torch.as_tensor(instancesVal.to_numpy(), dtype=torch.float32)\n",
    "    #t_labels_val = torch.as_tensor(labelsVal.to_numpy(), dtype=torch.int64)\n",
    "    \n",
    "    t_val_relatedness, t_val_stance, t_val_mmd_symbol, t_val_mmd_symbol_ = preprocess_stance_ideology_new_meta(labelsVal)\n",
    "    datasetVal = TensorDataset(t_instancesVal, t_val_relatedness, t_val_stance, t_val_mmd_symbol, t_val_mmd_symbol_)\n",
    "    \n",
    "    #datasetVal = TensorDataset(t_instancesVal, t_labels_val)\n",
    "    \n",
    "    \n",
    "    model = StanceMetaLearner(t_instancesTrain)    \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  betas=(0.9, 0.999), \n",
    "                  eps=1e-08, \n",
    "                  weight_decay=1e-4,\n",
    "                  correct_bias=True\n",
    "               )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            datasetTrain,  # The training samples.\n",
    "            sampler =  RandomSampler(datasetTrain), # Select batches randomly\n",
    "            batch_size = batch_size, # Trains with this batch size., \n",
    "            num_workers=8\n",
    "        )\n",
    "    batch_size = batch_size\n",
    "\n",
    "\n",
    "    from transformers import get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "    # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "    # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "    # training data.\n",
    "    epochs = epochs\n",
    "\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "    # (Note that this is not the same as the number of training samples).\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Create the learning rate scheduler.\n",
    "    schedulerOld = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "    \n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps, num_cycles = 5)\n",
    "    \n",
    "    return model, datasetTrain, datasetVal, optimizer, schedulerOld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213b751-ee50-4a53-b14a-e65e4adc92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "def prepare_for_training_stance_ideology_paper(input_idsTrain, attention_masksTrain, labelsTrain, labelsTrain_ideology, input_idsVal, attention_masksVal, labelsVal, labelsVal_ideology, modelUsed, batch_size, epochs, num_warmup_steps, learning_rate):\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "\n",
    "    from transformers import BertForSequenceClassification, AdamW, BertConfig, RobertaConfig, AutoModelWithLMHead\n",
    "    from transformers import DistilBertForSequenceClassification, RobertaForSequenceClassification\n",
    "    \n",
    "    from torch.utils.data import DataLoader, RandomSampler\n",
    "    \n",
    "    t_train_relatedness, t_train_stance, t_train_mmd_symbol, t_train_mmd_symbol_, t_train_existedstance, t_train_ideology = preprocess_stance_ideology(labelsTrain, labelsTrain_ideology)\n",
    " \n",
    "    datasetTrain = TensorDataset(input_idsTrain, attention_masksTrain, t_train_relatedness, t_train_stance, t_train_mmd_symbol, t_train_mmd_symbol_, t_train_existedstance, t_train_ideology)\n",
    "\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "    t_val_relatedness, t_val_stance, t_val_mmd_symbol, t_val_mmd_symbol_, t_val_existedstance, t_val_ideology = preprocess_stance_ideology(labelsVal, labelsVal_ideology)\n",
    "    datasetVal = TensorDataset(input_idsVal, attention_masksVal, t_val_relatedness, t_val_stance, t_val_mmd_symbol, t_val_mmd_symbol_, t_val_existedstance, t_val_ideology)\n",
    "    \n",
    "    #modelUsed = fasttext.load_model('model.bin')\n",
    "    model = StanceIdeologyDetectionClassMixout(modelUsed)\n",
    "    \n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if name in ['dropout', 'dropout2'] and isinstance(module, nn.Dropout):\n",
    "            setattr(model, name, nn.Dropout(0))\n",
    "        if name in ['l1'] and isinstance(module, nn.Linear):\n",
    "            target_state_dict = module.state_dict()\n",
    "            bias = True if module.bias is not None else False\n",
    "            new_module = MixLinear(module.in_features, module.out_features, \n",
    "                                  bias, target_state_dict['weight'], 0.4)\n",
    "            new_module.load_state_dict(target_state_dict)\n",
    "            setattr(model, name, new_module)\n",
    "        if name in ['input_pl', 'theta_d', 'probability', 'stance', 'l2', 'l3'] and isinstance(module, nn.Linear):\n",
    "            target_state_dict = module.state_dict()\n",
    "            bias = True if module.bias is not None else False\n",
    "            new_module = MixLinear(module.in_features, module.out_features, \n",
    "                                   bias, target_state_dict['weight'], 0.9)\n",
    "            new_module.load_state_dict(target_state_dict)\n",
    "            setattr(model, name, new_module)\n",
    "    print(\"After applying mixout\")\n",
    "    print(model)\n",
    "    \n",
    "\n",
    "    #print(model)\n",
    "    # Tell pytorch to run this model on the GPU.\n",
    "    #model.cuda()\n",
    "        \n",
    "    # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "    # I believe the 'W' stands for 'Weight Decay fix\"\n",
    "    ##optimizer = AdamW(\n",
    "    #[\n",
    "    ##    {\"params\": model.input_pl.parameters(), \"lr\": 1e-5},\n",
    "   #     {\"params\": model.l1.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.l2.parameters(), \"lr\": learning_rate},\n",
    "   #     {\"params\": model.bn1_hidden.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.dropout.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.relu.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.theta_d.parameters(), \"lr\": learning_rate},\n",
    "   #     {\"params\": model.bn1_theta.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.relu_theta.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.probability.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.output_prob.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.stance.parameters(), \"lr\": learning_rate},\n",
    "     #   {\"params\": model.ideology.parameters(), \"lr\": learning_rate},\n",
    "    #],\n",
    "    ##    betas=(0.9, 0.999), \n",
    "    #    eps=1e-08, \n",
    "    #    weight_decay=1e-5,\n",
    "    #    correct_bias=True\n",
    "    #)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  betas=(0.9, 0.999), \n",
    "                  eps=1e-06, \n",
    "                  weight_decay=0.1,\n",
    "                  correct_bias=True\n",
    "           )\n",
    "    \n",
    "    #from adabelief_pytorch import AdaBelief\n",
    "    #optimizer = AdaBelief(model.parameters(), lr=learning_rate, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = True, fixed_decay = False, amsgrad = False)\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            datasetTrain,  # The training samples.\n",
    "            sampler =  RandomSampler(datasetTrain), # Select batches randomly\n",
    "            batch_size = 16, # Trains with this batch size., \n",
    "            num_workers=8\n",
    "        )\n",
    "    batch_size = batch_size\n",
    "\n",
    "\n",
    "    from transformers import get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "    # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "    # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "    # training data.\n",
    "    epochs = epochs\n",
    "\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "    # (Note that this is not the same as the number of training samples).\n",
    "    total_steps = len(train_dataloader)*(batch_size//2)* epochs\n",
    "\n",
    "    # Create the learning rate scheduler.\n",
    "    schedulerOld = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "    \n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps, num_cycles = 5)\n",
    "    \n",
    "    return model, datasetTrain, datasetVal, optimizer, schedulerOld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ac5c5-c7d0-4c13-bebe-c621ccbff82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training_stance_ideology(input_idsTrain, attention_masksTrain, labelsTrain, labelsTrain_ideology, input_idsVal, attention_masksVal, labelsVal, labelsVal_ideology, modelUsed, batch_size, epochs, num_warmup_steps, learning_rate):\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "\n",
    "    from transformers import BertForSequenceClassification, AdamW, BertConfig, RobertaConfig, AutoModelWithLMHead\n",
    "    from transformers import DistilBertForSequenceClassification, RobertaForSequenceClassification\n",
    "    \n",
    "    from torch.utils.data import DataLoader, RandomSampler\n",
    "    \n",
    "    t_train_relatedness, t_train_stance, t_train_mmd_symbol, t_train_mmd_symbol_, t_train_existedstance, t_train_ideology = preprocess_stance_ideology(labelsTrain, labelsTrain_ideology)\n",
    " \n",
    "    datasetTrain = TensorDataset(input_idsTrain, attention_masksTrain, t_train_relatedness, t_train_stance, t_train_mmd_symbol, t_train_mmd_symbol_, t_train_existedstance, t_train_ideology)\n",
    "\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "    t_val_relatedness, t_val_stance, t_val_mmd_symbol, t_val_mmd_symbol_, t_val_existedstance, t_val_ideology = preprocess_stance_ideology(labelsVal, labelsVal_ideology)\n",
    "    datasetVal = TensorDataset(input_idsVal, attention_masksVal, t_val_relatedness, t_val_stance, t_val_mmd_symbol, t_val_mmd_symbol_, t_val_existedstance, t_val_ideology)\n",
    "    \n",
    "    #modelUsed = fasttext.load_model('model.bin')\n",
    "    model = AmbigiousDetectionClass(modelUsed)\n",
    "    \n",
    "\n",
    "    #print(model)\n",
    "    # Tell pytorch to run this model on the GPU.\n",
    "    #model.cuda()\n",
    "        \n",
    "    # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "    # I believe the 'W' stands for 'Weight Decay fix\"\n",
    "    ##optimizer = AdamW(\n",
    "    #[\n",
    "    ##    {\"params\": model.input_pl.parameters(), \"lr\": 1e-5},\n",
    "   #     {\"params\": model.l1.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.l2.parameters(), \"lr\": learning_rate},\n",
    "   #     {\"params\": model.bn1_hidden.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.dropout.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.relu.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.theta_d.parameters(), \"lr\": learning_rate},\n",
    "   #     {\"params\": model.bn1_theta.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.relu_theta.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.probability.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.output_prob.parameters(), \"lr\": learning_rate},\n",
    "    #    {\"params\": model.stance.parameters(), \"lr\": learning_rate},\n",
    "     #   {\"params\": model.ideology.parameters(), \"lr\": learning_rate},\n",
    "    #],\n",
    "    ##    betas=(0.9, 0.999), \n",
    "    #    eps=1e-08, \n",
    "    #    weight_decay=1e-5,\n",
    "    #    correct_bias=True\n",
    "    #)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  betas=(0.9, 0.98), \n",
    "                  eps=1e-08, \n",
    "                  weight_decay=0.1,\n",
    "                  correct_bias=True\n",
    "           )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            datasetTrain,  # The training samples.\n",
    "            sampler =  RandomSampler(datasetTrain), # Select batches randomly\n",
    "            batch_size = batch_size, # Trains with this batch size., \n",
    "            num_workers=8\n",
    "        )\n",
    "    batch_size = batch_size\n",
    "\n",
    "\n",
    "    from transformers import get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "    # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "    # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "    # training data.\n",
    "    epochs = epochs\n",
    "\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "    # (Note that this is not the same as the number of training samples).\n",
    "    total_steps = len(train_dataloader) * batch_size//16 * epochs\n",
    "\n",
    "    # Create the learning rate scheduler.\n",
    "    schedulerOld = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "    \n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps, num_cycles = 5)\n",
    "    \n",
    "    return model, datasetTrain, datasetVal, optimizer, schedulerOld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edc6e9-1082-4e8f-9be4-6eea4eac0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50e898-1840-4535-8ec7-143a4b5eff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_batches_datasets(datasetTrain, datasetVal, batch_size = 16):\n",
    "    from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "        \n",
    "    # Create the DataLoaders for our training and validation sets.\n",
    "    # We'll take training samples in random order. \n",
    "    train_dataloader = DataLoader(\n",
    "            datasetTrain,  # The training samples.\n",
    "            sampler =  RandomSampler(datasetTrain), # Select batches randomly\n",
    "            batch_size = batch_size, # Trains with this batch size., \n",
    "            num_workers=8, drop_last=True\n",
    "        )\n",
    "\n",
    "    # For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "    validation_dataloader = DataLoader(\n",
    "            datasetVal, # The validation samples.\n",
    "            sampler = SequentialSampler(datasetVal), # Pull out batches sequentially.\n",
    "            batch_size = batch_size, # Evaluate with this batch size.\n",
    "            num_workers=8, drop_last=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    #validation_dataloader = DataLoader(\n",
    "    #        datasetVal, # The validation samples.\n",
    "    #        sampler = SequentialSampler(datasetVal), # Pull out batches sequentially.\n",
    "    #        batch_size = batch_size, # Evaluate with this batch size.\n",
    "    #        num_workers=0, drop_last=True\n",
    "    #)\n",
    "    \n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf60d3-4e2c-4a29-b0ba-9d7baa376a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "#from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import EarlyStopping\n",
    "def train_stance_ideology_metalearner(train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, datasetTrain, datasetVal, epochs, batch_size, optimizer, scheduler, patience, verbose, delta, seedVal, continue_train = False):\n",
    "    \n",
    "    epochs = 1000\n",
    "    pro_val_num = val_nums[0]\n",
    "    agst_val_num = val_nums[1]\n",
    "    neut_val_num = val_nums[2]\n",
    "    notrel_val_num = val_nums[3]\n",
    "    \n",
    "    stance_all_num = pro_val_num + agst_val_num + neut_val_num + notrel_val_num\n",
    "    \n",
    "    con_val_num = 0.1\n",
    "    lib_val_num = 0.1\n",
    "    na_val_num = 0.1\n",
    "    \n",
    "    con_train_num = 0.1\n",
    "    lib_train_num = 0.1\n",
    "    na_train_num = 0.1\n",
    "    \n",
    "    #con_train_num = train_nums_ideology[0]\n",
    "    #lib_train_num = train_nums_ideology[1]\n",
    "    #na_train_num = train_nums_ideology[2]\n",
    "    \n",
    "    my_max_train_stance = max(pro_val_num, agst_val_num, neut_val_num, notrel_val_num)\n",
    "    my_max_train = max(con_train_num, lib_train_num, na_train_num)\n",
    "    \n",
    "    #con_val_num = val_nums_ideology[0]\n",
    "    #lib_val_num = val_nums_ideology[1]\n",
    "    #na_val_num = val_nums_ideology[2]\n",
    "    \n",
    "    my_max = max(con_val_num, lib_val_num, na_val_num)\n",
    "    \n",
    "    ideology_all_num = con_val_num + lib_val_num + na_val_num\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    min_val_loss = 100\n",
    "    \n",
    "    relatedness_size = 2\n",
    "    classes_size = 4\n",
    "    loss_fct_relatedness = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_fct_stance = torch.nn.CrossEntropyLoss()\n",
    "    #loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    alpha = 1.3\n",
    "    beta = 1e-3\n",
    "    theta = 0\n",
    "    gamma = 0\n",
    "    \n",
    "    batch_size_max_once = 64\n",
    "\n",
    "    if batch_size < batch_size_max_once:\n",
    "        batch_size_max_once = batch_size\n",
    "        \n",
    "    accumulation_steps = batch_size/batch_size_max_once\n",
    "    \n",
    "    es = EarlyStopping(patience,verbose, delta)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    train_dataloader, validation_dataloader = return_batches_datasets(datasetTrain, datasetVal, batch_size_max_once)\n",
    "    \n",
    "    epoch_start = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        #multi-gpu\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "            model = torch.nn.DataParallel(model)\n",
    "            \n",
    "    print(device)\n",
    "    \n",
    "    weights_stance = torch.tensor([my_max_train_stance/pro_val_num, my_max_train_stance/agst_val_num, my_max_train_stance/neut_val_num, my_max_train_stance/notrel_val_num]).to(device) \n",
    "    loss_fct_relatedness_weighted = torch.nn.BCEWithLogitsLoss(pos_weight = weights_stance)\n",
    "            \n",
    "    if continue_train:    \n",
    "        #'./model_save/fnc/model_emergentbert_epoch90_withoutsep_serp.t7'\n",
    "        checkpoint = torch.load(model_save_path)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        epoch_start = checkpoint['epoch']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    optimizer_to(optimizer,device)\n",
    "    \n",
    "    \n",
    "    # For each epoch...\n",
    "    batch_epoch_count = 1\n",
    "    for epoch_i in range(epoch_start, epoch_start + epochs):\n",
    "        \n",
    "        print(\"---------Epoch----------\" + str(epoch_i))\n",
    "        \n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "    \n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # For each batch of training data...\n",
    "        mini_batch_avg_loss = 0\n",
    "        \n",
    "        if batch_epoch_count % 500 == 0:\n",
    "            batch_size = batch_size*2\n",
    "            accumulation_steps = int(batch_size/batch_size_max_once)\n",
    "        batch_epoch_count = batch_epoch_count + 1\n",
    "\n",
    "        #train_size = len(train_dataloader) / float(accumulation_steps)\n",
    "        \n",
    "        print(\"Batch Size: \" + str(batch_size))\n",
    "        print(float(accumulation_steps))\n",
    "        \n",
    "        #print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_relatedness = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            b_mmd_symbol = batch[3].to(device)\n",
    "            b_mmd_symbol_ = batch[4].to(device)\n",
    "        \n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            mmd_loss, P_relatedness, P_stance = model(input_ids = b_input_ids, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "            #P_stance = model(input_ids = b_input_ids, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "\n",
    "            \n",
    "            relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "            stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "\n",
    "            \n",
    "            loss = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "            #loss = stance_loss\n",
    "            loss = loss / accumulation_steps \n",
    "            total_train_loss += loss.item()\n",
    "                \n",
    "            loss.backward()\n",
    "            if (step+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "                \n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This is to help prevent the \"exploding gradients\" problem.\n",
    "                    #torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                    \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "                # modified based on their gradients, the learning rate, etc.\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update the learning rate.\n",
    "                scheduler.step()\n",
    "                \n",
    "                #for param_group in optimizer.param_groups:\n",
    "                #print(\"Learning Rate: \", optimizer.param_groups[\"lr\"])\n",
    "                \n",
    "                                \n",
    "                # Always clear any previously calculated gradients before performing a\n",
    "                # backward pass. PyTorch doesn't do this automatically because \n",
    "                # accumulating the gradients is \"convenient while training RNNs\". \n",
    "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()       \n",
    "    \n",
    "        print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader) * accumulation_steps\n",
    "        #avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    \n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        #print(\"\")\n",
    "        print(\"  Average training loss: {0:.6f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        #print(\"\")\n",
    "        #print(\"Running Validation...\")\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_true_eval_stance = 0\n",
    "        total_true_eval_ideology = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        agree_val_true = 0\n",
    "        disagree_val_true = 0 \n",
    "        discuss_val_true = 0 \n",
    "        unrelated_val_true = 0\n",
    "        \n",
    "        con_val_true = 0\n",
    "        lib_val_true = 0\n",
    "        na_val_true = 0\n",
    "        \n",
    "        total_true = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_relatedness = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            b_mmd_symbol = batch[3].to(device)\n",
    "            b_mmd_symbol_ = batch[4].to(device)\n",
    "        \n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                \n",
    "                mmd_loss, P_relatedness, P_stance = model(input_ids = b_input_ids, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "                #P_stance = model(input_ids = b_input_ids, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "            \n",
    "                relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "                stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "\n",
    "            \n",
    "                loss_val = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "                #loss_val = stance_loss\n",
    "                total_eval_loss += loss_val.item()\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                P_relatedness = P_relatedness.to('cpu')\n",
    "                b_relatedness = b_relatedness.to('cpu')\n",
    "                P_stance = P_stance.to('cpu')\n",
    "                b_labels = b_labels.to('cpu')\n",
    "\n",
    "                acc_list = predict_classwise_stance_ideology_meta(P_relatedness, P_stance, b_labels)\n",
    "                total_true_eval_stance += acc_list[0]\n",
    "                ###\n",
    "                agree_val_true += acc_list[1]\n",
    "                disagree_val_true += acc_list[2]\n",
    "                discuss_val_true += acc_list[3]\n",
    "                unrelated_val_true += acc_list[4]\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        print(total_true_eval_stance)\n",
    "        avg_val_accuracy_stance = total_true_eval_stance / stance_all_num\n",
    "        print(\"Avg Val Accuracy Stance: {0:.6f}\".format(avg_val_accuracy_stance))\n",
    "        print(\"Total True\")\n",
    "        print(total_true)\n",
    "        print(\"*************\")\n",
    "        avg_val_agree_accuracy = agree_val_true / pro_val_num\n",
    "        print(\"Avg Val Agree Accuracy: {0:.6f}\".format(avg_val_agree_accuracy))\n",
    "        avg_val_disagree_accuracy = disagree_val_true / agst_val_num\n",
    "        print(\"Avg Val Disagree Accuracy: {0:.6f}\".format(avg_val_disagree_accuracy))\n",
    "        avg_val_discuss_accuracy = discuss_val_true / neut_val_num\n",
    "        print(\"Avg Val Discuss Accuracy: {0:.6f}\".format(avg_val_discuss_accuracy))\n",
    "        avg_val_unrelated_accuracy = unrelated_val_true / notrel_val_num\n",
    "        print(\"Avg Val Unrelated Accuracy: {0:.6f}\".format(avg_val_unrelated_accuracy))\n",
    "        \n",
    "        relative_score = 0.25*avg_val_unrelated_accuracy + 0.75*(avg_val_agree_accuracy + avg_val_disagree_accuracy + avg_val_discuss_accuracy)/3\n",
    "        \n",
    "        print(\"*****************\")\n",
    "        print(\"Relative score: {0:.6f}\".format(relative_score))\n",
    "        print(\"*****************\")\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t1)\n",
    "        \n",
    "        if avg_val_loss < min_val_loss:\n",
    "            min_val_loss = avg_val_loss\n",
    "    \n",
    "        print(\"Avg Validation Loss: {0:.6f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "        \n",
    "        \n",
    "        avg_val_accuracy_ideology = 0\n",
    "\n",
    "        #avg_val_accuracy_ideology = 0\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Stance Accur.': avg_val_accuracy_stance,\n",
    "            'Valid. Ideology Accur.': avg_val_accuracy_ideology,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        model_save_state = {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "    \n",
    "        \n",
    "        es.__call__(avg_val_loss, avg_val_accuracy_stance, avg_val_accuracy_ideology, model_save_state, model_save_path, model)\n",
    "        last_epoch = epoch_i + 1\n",
    "        if es.early_stop == True:\n",
    "            break  # early stop criterion is met, we can stop now\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    \n",
    "    \n",
    "    min_val_loss = es.val_loss_min\n",
    "    max_val_acc = es.val_acc_max_stance\n",
    "\n",
    "    return training_stats, last_epoch, min_val_loss, max_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159bd2af-378a-4e63-aa72-2f009152bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "#from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import EarlyStopping\n",
    "def train_stance_ideology_paper(train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, datasetTrain, datasetVal, epochs, batch_size, optimizer, scheduler, patience, verbose, delta, seedVal, continue_train = False):\n",
    "    \n",
    "    pro_val_num = val_nums[0]\n",
    "    agst_val_num = val_nums[1]\n",
    "    neut_val_num = val_nums[2]\n",
    "    notrel_val_num = val_nums[3]\n",
    "    \n",
    "    ambigious_num = val_nums[0]\n",
    "    not_ambigious_num = val_nums[1]\n",
    "    \n",
    "    ambigious_total = ambigious_num + not_ambigious_num\n",
    "    \n",
    "    stance_all_num = pro_val_num + agst_val_num + neut_val_num + notrel_val_num\n",
    "    \n",
    "    con_val_num = 0.1\n",
    "    lib_val_num = 0.1\n",
    "    na_val_num = 0.1\n",
    "    \n",
    "    con_train_num = 0.1\n",
    "    lib_train_num = 0.1\n",
    "    na_train_num = 0.1\n",
    "    \n",
    "    #con_train_num = train_nums_ideology[0]\n",
    "    #lib_train_num = train_nums_ideology[1]\n",
    "    #na_train_num = train_nums_ideology[2]\n",
    "    \n",
    "    my_max_train_stance = max(pro_val_num, agst_val_num, neut_val_num, notrel_val_num)\n",
    "    my_max_train = max(con_train_num, lib_train_num, na_train_num)\n",
    "    \n",
    "    #con_val_num = val_nums_ideology[0]\n",
    "    #lib_val_num = val_nums_ideology[1]\n",
    "    #na_val_num = val_nums_ideology[2]\n",
    "    \n",
    "    my_max = max(con_val_num, lib_val_num, na_val_num)\n",
    "    \n",
    "    ideology_all_num = con_val_num + lib_val_num + na_val_num\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    min_val_loss = 100\n",
    "    \n",
    "    relatedness_size = 2\n",
    "    classes_size = 4\n",
    "    loss_fct_relatedness = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_fct_stance = torch.nn.CrossEntropyLoss()\n",
    "    #loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    alpha = 1.3\n",
    "    beta =  1e-3\n",
    "    theta = 0\n",
    "    gamma = 0\n",
    "    \n",
    "    batch_size_max_once = 2\n",
    "\n",
    "    if batch_size < batch_size_max_once:\n",
    "        batch_size_max_once = batch_size\n",
    "        \n",
    "    accumulation_steps = batch_size/batch_size_max_once\n",
    "    \n",
    "    es = EarlyStopping(patience,verbose, delta)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    train_dataloader, validation_dataloader = return_batches_datasets(datasetTrain, datasetVal, batch_size_max_once)\n",
    "    \n",
    "    epoch_start = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        #multi-gpu\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "            model = torch.nn.DataParallel(model)\n",
    "            \n",
    "    print(device)\n",
    "    \n",
    "    \n",
    "            \n",
    "    if continue_train:    \n",
    "        #'./model_save/fnc/model_emergentbert_epoch90_withoutsep_serp.t7'\n",
    "        checkpoint = torch.load(model_save_path)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        epoch_start = checkpoint['epoch']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    optimizer_to(optimizer,device)\n",
    "    \n",
    "    \n",
    "     #pos_weight=torch.FloatTensor ([28.36 / 0.5090]\n",
    "    \n",
    "     #pos_weight = torch.tensor([1.0, 1.0, 1.0])\n",
    "     #pos_weight = pos_weight.to(device)\n",
    "     #criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    weights_ideology = torch.tensor([my_max_train/con_train_num, my_max_train/lib_train_num, my_max_train/na_train_num]).to(device)   \n",
    "    weights_stance = torch.tensor([my_max_train_stance/pro_val_num, my_max_train_stance/agst_val_num, my_max_train_stance/neut_val_num, my_max_train_stance/notrel_val_num]).to(device) \n",
    "    loss_fct_relatedness_weighted = torch.nn.BCEWithLogitsLoss(pos_weight = weights_stance)\n",
    "    loss_fct_ideology_weighted = torch.nn.BCEWithLogitsLoss(pos_weight = weights_ideology)\n",
    "    \n",
    "    # For each epoch...\n",
    "    batch_epoch_count = 1\n",
    "    for epoch_i in range(epoch_start, epoch_start + epochs):\n",
    "        \n",
    "        print(\"---------Epoch----------\" + str(epoch_i))\n",
    "        \n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "    \n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        #print(\"\")\n",
    "        #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        #print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # For each batch of training data...\n",
    "        mini_batch_avg_loss = 0\n",
    "        #train_size = len(train_dataloader)\n",
    "        \n",
    "        if batch_epoch_count % 500 == 0:\n",
    "            batch_size = batch_size*2\n",
    "            accumulation_steps = int(batch_size/batch_size_max_once)\n",
    "        batch_epoch_count = batch_epoch_count + 1\n",
    "\n",
    "        #train_size = len(train_dataloader) / float(accumulation_steps)\n",
    "        \n",
    "        print(\"Batch Size: \" + str(batch_size))\n",
    "        print(float(accumulation_steps))\n",
    "\n",
    "        #print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "        \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_relatedness = batch[2].to(device)\n",
    "            b_labels = batch[3].to(device)\n",
    "            b_mmd_symbol = batch[4].to(device)\n",
    "            b_mmd_symbol_ = batch[5].to(device)\n",
    "            b_existedstances = batch[6].to(device)\n",
    "            b_ideologies = batch[7].to(device)\n",
    "        \n",
    "            \n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "\n",
    "            mmd_loss, P_relatedness, P_stance, P_existedstance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_, epoch_num = epoch_i)\n",
    "                \n",
    "                \n",
    "                \n",
    "            relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "            stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "            #existedstance_loss = loss_fct_relatedness(P_existedstance, b_existedstances.float())\n",
    "\n",
    "            \n",
    "            loss = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "            #loss = stance_loss\n",
    "            loss = loss / accumulation_steps \n",
    "            total_train_loss += loss.item()\n",
    "                \n",
    "            loss.backward()\n",
    "            if ((step+1) % accumulation_steps == 0) or (step + 1 == len(train_dataloader)):             \n",
    "                # Wait for several backward steps\n",
    "                    \n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This is to help prevent the \"exploding gradients\" problem.\n",
    "                    #torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                    \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "                # modified based on their gradients, the learning rate, etc.\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update the learning rate.\n",
    "                scheduler.step()\n",
    "                \n",
    "                #for param_group in optimizer.param_groups:\n",
    "                #print(\"Learning Rate: \", optimizer.param_groups[\"lr\"])\n",
    "                \n",
    "                                \n",
    "                # Always clear any previously calculated gradients before performing a\n",
    "                # backward pass. PyTorch doesn't do this automatically because \n",
    "                # accumulating the gradients is \"convenient while training RNNs\". \n",
    "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()       \n",
    "    \n",
    "        print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader) * accumulation_steps\n",
    "        #avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    \n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        #print(\"\")\n",
    "        print(\"  Average training loss: {0:.6f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        #print(\"\")\n",
    "        #print(\"Running Validation...\")\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_true_eval_stance = 0\n",
    "        total_true_eval_ideology = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        agree_val_true = 0\n",
    "        disagree_val_true = 0 \n",
    "        discuss_val_true = 0 \n",
    "        unrelated_val_true = 0\n",
    "        \n",
    "        con_val_true = 0\n",
    "        lib_val_true = 0\n",
    "        na_val_true = 0\n",
    "        \n",
    "        total_true = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "        \n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_relatedness = batch[2].to(device)\n",
    "            b_labels = batch[3].to(device)\n",
    "            b_mmd_symbol = batch[4].to(device)\n",
    "            b_mmd_symbol_ = batch[5].to(device)\n",
    "            b_existedstances = batch[6].to(device)\n",
    "            b_ideologies = batch[7].to(device)\n",
    "        \n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "\n",
    "                mmd_loss, P_relatedness, P_stance, P_existedstance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_, epoch_num = 12)\n",
    "                #P_stance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "\n",
    "                \n",
    "                #CrossEntropy Loss\n",
    "                relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "                stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "                #existedstance_loss = loss_fct_relatedness(P_existedstance, b_existedstances.float())\n",
    "                \n",
    "                loss_val = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "                #loss_val = stance_loss\n",
    "                total_eval_loss += loss_val.item()\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                P_relatedness = P_relatedness.to('cpu')\n",
    "                b_relatedness = b_relatedness.to('cpu')\n",
    "                P_stance = P_stance.to('cpu')\n",
    "                b_labels = b_labels.to('cpu')\n",
    "                #P_existedstance = P_existedstance.to('cpu')\n",
    "                #b_existedstances = b_existedstances.to('cpu')\n",
    "                \n",
    "                \n",
    "\n",
    "                # Calculate the accuracy for this batch of test sentences, and\n",
    "                # accumulate it over all batches.\n",
    "                #total_eval_accuracy += predict(P_relatedness, P_stance, b_labels)\n",
    "\n",
    "                acc_list = predict_classwise_stance_ideology(P_relatedness, P_stance, P_existedstance, b_labels)\n",
    "                #acc_list = predict_classwise_stance_ideology_bert(P_stance, b_labels)\n",
    "                total_true_eval_stance += acc_list[0]\n",
    "                ###\n",
    "                agree_val_true += acc_list[1]\n",
    "                disagree_val_true += acc_list[2]\n",
    "                discuss_val_true += acc_list[3]\n",
    "                unrelated_val_true += acc_list[4]\n",
    "                \n",
    "                total_true_eval_ideology += acc_list[5]\n",
    "                con_val_true += acc_list[6]\n",
    "                lib_val_true += acc_list[7]\n",
    "                na_val_true += acc_list[8]\n",
    "                \n",
    "                                \n",
    "                ##print(\"Batch Next\")\n",
    "                #for idx in range(0, len(P_stance)):\n",
    "                    \n",
    "                    #print(P_stance[idx], b_labels[idx], acc_list[9][idx]) \n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy_stance = total_true_eval_stance / stance_all_num\n",
    "        avg_val_accuracy_ideology = total_true_eval_ideology / ideology_all_num\n",
    "        print(\"Avg Val Accuracy Stance: {0:.6f}\".format(avg_val_accuracy_stance))\n",
    "        print(\"Avg Val Accuracy Ideology: {0:.6f}\".format(avg_val_accuracy_ideology))\n",
    "        print(\"Total True\")\n",
    "        print(total_true)\n",
    "        print(\"*************\")\n",
    "        avg_val_agree_accuracy = agree_val_true / pro_val_num\n",
    "        print(\"Avg Val Agree Accuracy: {0:.6f}\".format(avg_val_agree_accuracy))\n",
    "        avg_val_disagree_accuracy = disagree_val_true / agst_val_num\n",
    "        print(\"Avg Val Disagree Accuracy: {0:.6f}\".format(avg_val_disagree_accuracy))\n",
    "        avg_val_discuss_accuracy = discuss_val_true / neut_val_num\n",
    "        print(\"Avg Val Discuss Accuracy: {0:.6f}\".format(avg_val_discuss_accuracy))\n",
    "        avg_val_unrelated_accuracy = unrelated_val_true / notrel_val_num\n",
    "        print(\"Avg Val Unrelated Accuracy: {0:.6f}\".format(avg_val_unrelated_accuracy))\n",
    "        \n",
    "        relative_score = 0.25*avg_val_unrelated_accuracy + 0.75*(avg_val_agree_accuracy + avg_val_disagree_accuracy + avg_val_discuss_accuracy)/3\n",
    "        \n",
    "        print(\"*****************\")\n",
    "        print(\"Relative score: {0:.6f}\".format(relative_score))\n",
    "        print(\"*****************\")\n",
    "        print(\"-------------\")\n",
    "        avg_val_con_accuracy = con_val_true / con_val_num\n",
    "        print(\"Avg Val Con Accuracy: {0:.6f}\".format(avg_val_con_accuracy))\n",
    "        avg_lib_accuracy = lib_val_true / lib_val_num\n",
    "        print(\"Avg Val Lib Accuracy: {0:.6f}\".format(avg_lib_accuracy))\n",
    "        avg_na_discuss_accuracy = na_val_true / na_val_num\n",
    "        print(\"Avg Val NA Accuracy: {0:.6f}\".format(avg_na_discuss_accuracy))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "        \n",
    "        print(\"Total Validation loss\", total_eval_loss)\n",
    "        print(\"Len-validation loader\", len(validation_dataloader))\n",
    "    \n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t1)\n",
    "        \n",
    "        if avg_val_loss < min_val_loss:\n",
    "            min_val_loss = avg_val_loss\n",
    "    \n",
    "        print(\"Avg Validation Loss: {0:.6f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        #avg_val_accuracy_ideology = 0\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Stance Accur.': avg_val_accuracy_stance,\n",
    "            'Valid. Ideology Accur.': avg_val_accuracy_ideology,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        model_save_state = {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "    \n",
    "        es.__call__(avg_val_loss, avg_val_accuracy_stance, avg_val_accuracy_ideology, model_save_state, model_save_path, model)\n",
    "        last_epoch = epoch_i + 1\n",
    "        if es.early_stop == True:\n",
    "            break  # early stop criterion is met, we can stop now\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    \n",
    "    \n",
    "    min_val_loss = es.val_loss_min\n",
    "    max_val_acc = es.val_acc_max_stance\n",
    "\n",
    "    return training_stats, last_epoch, min_val_loss, max_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98f309-1dc0-4259-92a9-e237b1e5e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "#from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import EarlyStopping\n",
    "def train_stance_ideology(train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, datasetTrain, datasetVal, epochs, batch_size, optimizer, scheduler, patience, verbose, delta, seedVal, continue_train = False):\n",
    "    \n",
    "    ##pro_val_num = val_nums[0]\n",
    "    #agst_val_num = val_nums[1]\n",
    "    #neut_val_num = val_nums[2] + 0.01\n",
    "    #notrel_val_num = val_nums[3]\n",
    "    \n",
    "    pro_val_num = 0.1\n",
    "    agst_val_num = 0.1\n",
    "    neut_val_num = 0.1\n",
    "    notrel_val_num = 0.1\n",
    "    \n",
    "    stance_all_num = pro_val_num + agst_val_num + neut_val_num + notrel_val_num\n",
    "    \n",
    "    con_val_num = 0.1\n",
    "    lib_val_num = 0.1\n",
    "    na_val_num = 0.1\n",
    "    \n",
    "    con_train_num = 0.1\n",
    "    lib_train_num = 0.1\n",
    "    na_train_num = 0.1\n",
    "    \n",
    "    #con_train_num = train_nums_ideology[0]\n",
    "    #lib_train_num = train_nums_ideology[1]\n",
    "    #na_train_num = train_nums_ideology[2]\n",
    "    \n",
    "    my_max_train_stance = max(pro_val_num, agst_val_num, neut_val_num, notrel_val_num)\n",
    "    my_max_train = max(con_train_num, lib_train_num, na_train_num)\n",
    "    \n",
    "    #con_val_num = val_nums_ideology[0]\n",
    "    #lib_val_num = val_nums_ideology[1]\n",
    "    #na_val_num = val_nums_ideology[2]\n",
    "    \n",
    "    my_max = max(con_val_num, lib_val_num, na_val_num)\n",
    "    \n",
    "    ideology_all_num = con_val_num + lib_val_num + na_val_num\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    min_val_loss = 100\n",
    "    \n",
    "    relatedness_size = 2\n",
    "    classes_size = 4\n",
    "    loss_fct_relatedness = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_fct_stance = torch.nn.CrossEntropyLoss()\n",
    "    #loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    alpha = 1.3\n",
    "    beta = 1e-3\n",
    "    theta = 0\n",
    "    gamma = 0\n",
    "    \n",
    "    batch_size_max_once = 16\n",
    "\n",
    "    if batch_size < batch_size_max_once:\n",
    "        batch_size_max_once = batch_size\n",
    "        \n",
    "    accumulation_steps = batch_size/batch_size_max_once\n",
    "    \n",
    "    es = EarlyStopping(patience,verbose, delta)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    train_dataloader, validation_dataloader = return_batches_datasets(datasetTrain, datasetVal, batch_size_max_once)\n",
    "    \n",
    "    epoch_start = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        #multi-gpu\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "            model = torch.nn.DataParallel(model)\n",
    "            \n",
    "    print(device)\n",
    "    \n",
    "    \n",
    "            \n",
    "    if continue_train:    \n",
    "        #'./model_save/fnc/model_emergentbert_epoch90_withoutsep_serp.t7'\n",
    "        checkpoint = torch.load(model_save_path)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        epoch_start = checkpoint['epoch']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    optimizer_to(optimizer,device)\n",
    "    \n",
    "    \n",
    "     #pos_weight=torch.FloatTensor ([28.36 / 0.5090]\n",
    "    \n",
    "     #pos_weight = torch.tensor([1.0, 1.0, 1.0])\n",
    "     #pos_weight = pos_weight.to(device)\n",
    "     #criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    weights_ideology = torch.tensor([my_max_train/con_train_num, my_max_train/lib_train_num, my_max_train/na_train_num]).to(device)   \n",
    "    weights_stance = torch.tensor([my_max_train_stance/pro_val_num, my_max_train_stance/agst_val_num, my_max_train_stance/neut_val_num, my_max_train_stance/notrel_val_num]).to(device) \n",
    "    loss_fct_relatedness_weighted = torch.nn.BCEWithLogitsLoss(pos_weight = weights_stance)\n",
    "    loss_fct_ideology_weighted = torch.nn.BCEWithLogitsLoss(pos_weight = weights_ideology)\n",
    "    \n",
    "    # For each epoch...\n",
    "    batch_epoch_count = 1\n",
    "    for epoch_i in range(epoch_start, epoch_start + epochs):\n",
    "        \n",
    "        print(\"---------Epoch----------\" + str(epoch_i))\n",
    "        \n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "    \n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        #print(\"\")\n",
    "        #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        #print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # For each batch of training data...\n",
    "        mini_batch_avg_loss = 0\n",
    "        #train_size = len(train_dataloader)\n",
    "        \n",
    "        if batch_epoch_count % 500 == 0:\n",
    "            batch_size = batch_size*2\n",
    "            accumulation_steps = int(batch_size/batch_size_max_once)\n",
    "        batch_epoch_count = batch_epoch_count + 1\n",
    "\n",
    "        #train_size = len(train_dataloader) / float(accumulation_steps)\n",
    "        \n",
    "        print(\"Batch Size: \" + str(batch_size))\n",
    "        print(float(accumulation_steps))\n",
    "        \n",
    "        #print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "        \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "        \n",
    "            \n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "\n",
    "            #mmd_loss, P_relatedness, P_stance, P_existedstance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "            P_stance = model(input_ids = b_input_ids, attention_mask = b_input_mask)\n",
    "                \n",
    "                \n",
    "                \n",
    "            #relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "            stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "            #existedstance_loss = loss_fct_relatedness(P_existedstance, b_existedstances.float())\n",
    "\n",
    "            \n",
    "            #loss = alpha * stance_loss + theta * existedstance_loss + beta * mmd_loss + relatedness_loss\n",
    "            loss = stance_loss\n",
    "            loss = loss / accumulation_steps \n",
    "            total_train_loss += loss.item()\n",
    "                \n",
    "            loss.backward()\n",
    "            if (step+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "                    \n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This is to help prevent the \"exploding gradients\" problem.\n",
    "                    #torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                    \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "                # modified based on their gradients, the learning rate, etc.\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update the learning rate.\n",
    "                scheduler.step()\n",
    "                \n",
    "                #for param_group in optimizer.param_groups:\n",
    "                #print(\"Learning Rate: \", optimizer.param_groups[\"lr\"])\n",
    "                \n",
    "                                \n",
    "                # Always clear any previously calculated gradients before performing a\n",
    "                # backward pass. PyTorch doesn't do this automatically because \n",
    "                # accumulating the gradients is \"convenient while training RNNs\". \n",
    "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()       \n",
    "    \n",
    "        print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader) * accumulation_steps\n",
    "        #avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    \n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        #print(\"\")\n",
    "        print(\"  Average training loss: {0:.6f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        #print(\"\")\n",
    "        #print(\"Running Validation...\")\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_true_eval_stance = 0\n",
    "        total_true_eval_ideology = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        agree_val_true = 0\n",
    "        disagree_val_true = 0 \n",
    "        discuss_val_true = 0 \n",
    "        unrelated_val_true = 0\n",
    "        \n",
    "        con_val_true = 0\n",
    "        lib_val_true = 0\n",
    "        na_val_true = 0\n",
    "        \n",
    "        total_true = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "        \n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "        \n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "\n",
    "                #mmd_loss, P_relatedness, P_stance, P_existedstance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "                P_stance = model(input_ids = b_input_ids, attention_mask = b_input_mask)\n",
    "\n",
    "                \n",
    "                #CrossEntropy Loss\n",
    "                #relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "                stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "                #existedstance_loss = loss_fct_relatedness(P_existedstance, b_existedstances.float())\n",
    "                \n",
    "                #loss_val = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "                loss_val = stance_loss\n",
    "                total_eval_loss += loss_val.item()\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                #P_relatedness = P_relatedness.to('cpu')\n",
    "                #b_relatedness = b_relatedness.to('cpu')\n",
    "                P_stance = P_stance.to('cpu')\n",
    "                b_labels = b_labels.to('cpu')\n",
    "                #P_existedstance = P_existedstance.to('cpu')\n",
    "                #b_existedstances = b_existedstances.to('cpu')\n",
    "                \n",
    "                \n",
    "\n",
    "                # Calculate the accuracy for this batch of test sentences, and\n",
    "                # accumulate it over all batches.\n",
    "                #total_eval_accuracy += predict(P_relatedness, P_stance, b_labels)\n",
    "\n",
    "                #acc_list = predict_classwise_stance_ideology(P_relatedness, P_stance, P_existedstance, b_labels)\n",
    "                acc_list = predict_classwise_stance_ideology_bert(P_stance, b_labels)\n",
    "                total_true_eval_stance += acc_list[0]\n",
    "                ###\n",
    "                agree_val_true += acc_list[1]\n",
    "                disagree_val_true += acc_list[2]\n",
    "                discuss_val_true += acc_list[3]\n",
    "                unrelated_val_true += acc_list[4]\n",
    "                \n",
    "                total_true_eval_ideology += acc_list[5]\n",
    "                con_val_true += acc_list[6]\n",
    "                lib_val_true += acc_list[7]\n",
    "                na_val_true += acc_list[8]\n",
    "                \n",
    "                predict_labels = acc_list[9]\n",
    "                \n",
    "                                \n",
    "                ##print(\"Batch Next\")\n",
    "                #for idx in range(0, len(P_stance)):\n",
    "                    \n",
    "                    #print(P_stance[idx], b_labels[idx], acc_list[9][idx]) \n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy_stance = total_true_eval_stance / stance_all_num\n",
    "        avg_val_accuracy_ideology = total_true_eval_ideology / ideology_all_num\n",
    "        print(\"Avg Val Accuracy Stance: {0:.6f}\".format(avg_val_accuracy_stance))\n",
    "        print(\"Avg Val Accuracy Ideology: {0:.6f}\".format(avg_val_accuracy_ideology))\n",
    "        print(\"Total True\")\n",
    "        print(total_true)\n",
    "        print(\"*************\")\n",
    "        avg_val_agree_accuracy = agree_val_true / pro_val_num\n",
    "        print(\"Avg Val Agree Accuracy: {0:.6f}\".format(avg_val_agree_accuracy))\n",
    "        avg_val_disagree_accuracy = disagree_val_true / agst_val_num\n",
    "        print(\"Avg Val Disagree Accuracy: {0:.6f}\".format(avg_val_disagree_accuracy))\n",
    "        avg_val_discuss_accuracy = discuss_val_true / neut_val_num\n",
    "        print(\"Avg Val Discuss Accuracy: {0:.6f}\".format(avg_val_discuss_accuracy))\n",
    "        avg_val_unrelated_accuracy = unrelated_val_true / notrel_val_num\n",
    "        print(\"Avg Val Unrelated Accuracy: {0:.6f}\".format(avg_val_unrelated_accuracy))\n",
    "        \n",
    "        relative_score = 0.25*avg_val_unrelated_accuracy + 0.75*(avg_val_agree_accuracy + avg_val_disagree_accuracy + avg_val_discuss_accuracy)/3\n",
    "        \n",
    "        print(\"*****************\")\n",
    "        print(\"Relative score: {0:.6f}\".format(relative_score))\n",
    "        print(\"*****************\")\n",
    "        print(\"-------------\")\n",
    "        avg_val_con_accuracy = con_val_true / con_val_num\n",
    "        print(\"Avg Val Con Accuracy: {0:.6f}\".format(avg_val_con_accuracy))\n",
    "        avg_lib_accuracy = lib_val_true / lib_val_num\n",
    "        print(\"Avg Val Lib Accuracy: {0:.6f}\".format(avg_lib_accuracy))\n",
    "        avg_na_discuss_accuracy = na_val_true / na_val_num\n",
    "        print(\"Avg Val NA Accuracy: {0:.6f}\".format(avg_na_discuss_accuracy))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "        \n",
    "        print(\"Total Validation loss\", total_eval_loss)\n",
    "        print(\"Len-validation loader\", len(validation_dataloader))\n",
    "    \n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t1)\n",
    "        \n",
    "        if avg_val_loss < min_val_loss:\n",
    "            min_val_loss = avg_val_loss\n",
    "    \n",
    "        print(\"Avg Validation Loss: {0:.6f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        #avg_val_accuracy_ideology = 0\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Stance Accur.': avg_val_accuracy_stance,\n",
    "            'Valid. Ideology Accur.': avg_val_accuracy_ideology,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        model_save_state = {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "    \n",
    "        es.__call__(avg_val_loss, avg_val_accuracy_stance, avg_val_accuracy_ideology, model_save_state, model_save_path, model)\n",
    "        last_epoch = epoch_i + 1\n",
    "        if es.early_stop == True:\n",
    "            break  # early stop criterion is met, we can stop now\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    \n",
    "    \n",
    "    min_val_loss = es.val_loss_min\n",
    "    max_val_acc = es.val_acc_max_stance\n",
    "\n",
    "    return training_stats, last_epoch, min_val_loss, max_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf66ae-5fd6-4efb-8a5c-c6de65d0401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(training_stats):\n",
    "    # Display floats with two decimal places.\n",
    "    pd.set_option('precision', 4)\n",
    "    \n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "\n",
    "    # Create a DataFrame from our training statistics.\n",
    "    df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "    # Use the 'epoch' as the row index.\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "    # A hack to force the column headers to wrap.\n",
    "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "\n",
    "    # Display the table.\n",
    "    print(df_stats)\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fea4b1-3304-4575-8c17-e2c367c71a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df_stats, last_epoch):\n",
    "    # Use plot styling from seaborn.\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "    # Increase the plot size and font size.\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "    \n",
    "    plot1 = plt.figure(1)\n",
    "    \n",
    "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training_Loss\")\n",
    "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Val_Loss\")\n",
    "\n",
    "    # Label the plot.\n",
    "    plt.title(\"Training & Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    #plt.autoscale(enable=True, axis='x')\n",
    "    \n",
    "    plot2 = plt.figure(2)\n",
    "\n",
    "    x_ticks = []\n",
    "    for currEpoch in range(1, last_epoch+1):\n",
    "        x_ticks.append(currEpoch)\n",
    "    #plt.xticks(x_ticks)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.plot(df_stats['Valid. Stance Accur.'], 'b-o', label=\"Valid. Stance Accur.\")\n",
    "    plt.plot(df_stats['Valid. Ideology Accur.'], 'g-o', label=\"Valid. Ideology Accur.\")\n",
    "\n",
    "    # Label the plot.\n",
    "    plt.title(\"Val Stance & Ideology Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Acc\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafebaba-c27f-4db6-a093-2ec45ecaa7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "def run_test_stance_ideology_meta(test_nums, test_nums_ideology, model_current, model_savepath, instancesTest, stance_labels_Test, ideology_labels_Test, batch_size = 16):       \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #loss_fct = torch.nn.BCELoss()\n",
    "    loss_fct_relatedness = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    t_instancesTest = torch.as_tensor(instancesTest.to_numpy(), dtype=torch.float32)\n",
    "    t_test_relatedness, t_test_stance, t_test_mmd_symbol, t_test_mmd_symbol_ = preprocess_stance_ideology_new_meta(stance_labels_Test)\n",
    "    prediction_data = TensorDataset(t_instancesTest, t_test_relatedness, t_test_stance, t_test_mmd_symbol, t_test_mmd_symbol_)\n",
    "    \n",
    "    prediction_sampler = SequentialSampler(prediction_data)\n",
    "    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size, num_workers=8, drop_last=False)\n",
    "    \n",
    "    pro_val_num = test_nums[0]\n",
    "    agst_val_num = test_nums[1]\n",
    "    neut_val_num = test_nums[2]\n",
    "    notrel_val_num = test_nums[3]\n",
    "    \n",
    "    ##con_val_num = 0.1\n",
    "    ##lib_val_num = 0.1\n",
    "    ##na_val_num = 0.1\n",
    "    \n",
    "    con_val_num = 0.1\n",
    "    lib_val_num = 0.1\n",
    "    na_val_num = 0.1\n",
    "    \n",
    "    \n",
    "    total_num = pro_val_num + agst_val_num + neut_val_num + notrel_val_num\n",
    "    tokenizer = load_tokenizer(model_current)\n",
    "\n",
    "        \n",
    "    #model = StanceMetaLearner(model_current)\n",
    "    checkpoint = torch.load(model_savepath)\n",
    "    model = StanceMetaLearnerSimple(t_instancesTest)\n",
    "    model.load_state_dict(checkpoint['state_dict'])   \n",
    "    \n",
    "    \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  betas=(0.9, 0.999), \n",
    "                  eps=1e-08, \n",
    "                  weight_decay=1e-4,\n",
    "                  correct_bias=True\n",
    "    )\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    optimizer_to(optimizer,device)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    #model.cuda()\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_test_loss = 0.0\n",
    "    \n",
    "    total_test_accuracy_stance = 0.0\n",
    "    total_test_accuracy_ideology = 0.0\n",
    "    ####\n",
    "    agree_test_accuracy = 0.0\n",
    "    disagree_test_accuracy = 0.0\n",
    "    discuss_test_accuracy = 0.0\n",
    "    unrelated_test_accuracy = 0.0\n",
    "    \n",
    "    ideology_test_accuracy = 0.0\n",
    "    ideology_test_con_accuracy = 0.0\n",
    "    ideology_test_lib_accuracy = 0.0\n",
    "    ideology_test_na_accuracy = 0.0\n",
    "    predictions , true_labels = [], []\n",
    "    \n",
    "    alpha = 1.3\n",
    "    theta = 0\n",
    "    beta = 1e-3\n",
    "    gamma = 0\n",
    "    # Predict\n",
    "    my_predictions = []\n",
    "    my_all_predictions = []\n",
    "    for batch in prediction_dataloader:\n",
    "      #Add batch to GPU\n",
    "        \n",
    "        #batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "            \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_relatedness = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_mmd_symbol = batch[3].to(device)\n",
    "        b_mmd_symbol_ = batch[4].to(device)\n",
    "\n",
    "        with torch.no_grad():         \n",
    "            # Forward pass, calculate logit predictions\n",
    "            \n",
    "            \n",
    "            mmd_loss, P_relatedness, P_stance = model(input_ids = b_input_ids, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "            relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "            stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "\n",
    "            \n",
    "            loss = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "            #loss = stance_loss\n",
    "            loss = loss / accumulation_steps \n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            P_relatedness = P_relatedness.to('cpu')\n",
    "            b_relatedness = b_relatedness.to('cpu')\n",
    "            P_stance = P_stance.to('cpu')\n",
    "            b_labels = b_labels.to('cpu')\n",
    "            \n",
    "            acc_list = predict_classwise_stance_ideology_meta(P_stance, b_labels)\n",
    "            total_test_accuracy_stance += acc_list[0]\n",
    "            ###\n",
    "            agree_test_accuracy += acc_list[1]\n",
    "            disagree_test_accuracy += acc_list[2]\n",
    "            discuss_test_accuracy += acc_list[3]\n",
    "            unrelated_test_accuracy += acc_list[4]\n",
    "            #prob_stance = acc_list[9]\n",
    "            #prob_val_list = P_stance.numpy()\n",
    "            \n",
    "            #predict_labels = torch.argmax(prob_stance, 1)\n",
    "            #my_len = len(prob_stance)\n",
    "            \n",
    "            #for prob in prob_val_list:\n",
    "                #my_all_predictions.append(prob)\n",
    "            #for idx in range(0, my_len):\n",
    "                #my_predictions.append(str(prob_stance[idx]) + \" \" + str(predict_labels[idx]) + \"\\n\")\n",
    "\n",
    "    #arr = np.array(my_all_predictions)\n",
    "    #file1 = open('myfile.txt', 'w')\n",
    "    #file1.writelines(my_predictions)\n",
    "    #file1.close()\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_test_loss = total_test_loss / len(prediction_dataloader)\n",
    "    avg_test_accuracy_stance = total_test_accuracy_stance / total_num\n",
    "    \n",
    "    avg_agree_test_acc = agree_test_accuracy / pro_val_num\n",
    "    avg_disagree_test_acc = disagree_test_accuracy / agst_val_num\n",
    "    avg_discuss_test_acc = discuss_test_accuracy / neut_val_num\n",
    "    avg_unrelated_test_acc = unrelated_test_accuracy / notrel_val_num\n",
    "\n",
    "    return avg_test_loss, avg_test_accuracy_stance, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be35471-5926-467a-aec7-fa9314ae9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "def run_test_stance_ideology2(test_nums, test_nums_ideology, model_current, model_savepath, all_input_ids_Test, all_input_masks_Test, stance_labels_Test, ideology_labels_Test, batch_size = 16):       \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #loss_fct = torch.nn.BCELoss()\n",
    "    loss_fct_relatedness = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    #weights_ideology = torch.tensor([my_max_train/con_train_num, my_max_train/lib_train_num, 0.01]).to(device)   \n",
    "    #loss_fct_ideology_weighted = torch.nn.BCEWithLogitsLoss(pos_weight = weights_ideology)\n",
    "    \n",
    "    t_test_relatedness, t_test_stance, t_test_mmd_symbol, t_test_mmd_symbol_, t_test_existedstance, t_test_ideology = preprocess_stance_ideology(stance_labels_Test, ideology_labels_Test)\n",
    "    #t_test_stance = preprocess_ideology_new(stance_labels_Test)\n",
    "\n",
    "    # Create the DataLoader.\n",
    "    prediction_data = TensorDataset(all_input_ids_Test, all_input_masks_Test, t_test_relatedness, t_test_stance, t_test_mmd_symbol, t_test_mmd_symbol_, t_test_existedstance, t_test_ideology)\n",
    "    #prediction_data = TensorDataset(all_input_ids_Test, all_input_masks_Test, t_test_stance)\n",
    "    prediction_sampler = SequentialSampler(prediction_data)\n",
    "    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size, num_workers=8, drop_last=False)\n",
    "    \n",
    "    pro_val_num = test_nums[0]\n",
    "    agst_val_num = test_nums[1]\n",
    "    neut_val_num = test_nums[2]\n",
    "    notrel_val_num = test_nums[3]\n",
    "    \n",
    "    ##con_val_num = 0.1\n",
    "    ##lib_val_num = 0.1\n",
    "    ##na_val_num = 0.1\n",
    "    \n",
    "    con_val_num = 0.1\n",
    "    lib_val_num = 0.1\n",
    "    na_val_num = 0.1\n",
    "    \n",
    "    \n",
    "    total_num = pro_val_num + agst_val_num + neut_val_num + notrel_val_num\n",
    "    tokenizer = load_tokenizer(model_current)\n",
    "\n",
    "        \n",
    "    model = StanceIdeologyDetectionClass(model_current)\n",
    "    checkpoint = torch.load(model_savepath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])   \n",
    "    \n",
    "    \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  betas=(0.9, 0.999), \n",
    "                  eps=1e-08, \n",
    "                  weight_decay=1e-4,\n",
    "                  correct_bias=True\n",
    "    )\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    optimizer_to(optimizer,device)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    #model.cuda()\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_test_loss = 0.0\n",
    "    \n",
    "    total_test_accuracy_stance = 0.0\n",
    "    total_test_accuracy_ideology = 0.0\n",
    "    ####\n",
    "    agree_test_accuracy = 0.0\n",
    "    disagree_test_accuracy = 0.0\n",
    "    discuss_test_accuracy = 0.0\n",
    "    unrelated_test_accuracy = 0.0\n",
    "    \n",
    "    ideology_test_accuracy = 0.0\n",
    "    ideology_test_con_accuracy = 0.0\n",
    "    ideology_test_lib_accuracy = 0.0\n",
    "    ideology_test_na_accuracy = 0.0\n",
    "    predictions , true_labels = [], []\n",
    "    \n",
    "    alpha = 1.3\n",
    "    theta = 0\n",
    "    beta = 1e-3\n",
    "    gamma = 0\n",
    "    # Predict\n",
    "    my_predictions = []\n",
    "    my_all_predictions = []\n",
    "    for batch in prediction_dataloader:\n",
    "      #Add batch to GPU\n",
    "        \n",
    "        #batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_relatedness = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "        b_mmd_symbol = batch[4].to(device)\n",
    "        b_mmd_symbol_ = batch[5].to(device)\n",
    "        b_existedstances = batch[6].to(device)\n",
    "        b_ideologies = batch[7].to(device)\n",
    "  \n",
    "\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and \n",
    "        # speeding up prediction\n",
    "        with torch.no_grad():         \n",
    "            # Forward pass, calculate logit predictions\n",
    "            \n",
    "            n1 = torch.sum(b_mmd_symbol, dim=0)\n",
    "            n2 = torch.sum(b_mmd_symbol_, dim=0)\n",
    "        \n",
    "            aa = torch.reshape(b_mmd_symbol, (-1,1))\n",
    "            bb = torch.reshape(b_mmd_symbol_, (-1,1))\n",
    "            \n",
    "            \n",
    "            mmd_loss, P_relatedness, P_stance, P_existedstance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "            \n",
    "            #mmd_loss, P_relatedness, P_stance, P_oneside, P_ideology = model(input_ids = b_input_ids, attention_mask = b_input_mask)\n",
    "            #P_stance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "                \n",
    "            \n",
    "            relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "            #relatedness_loss = 0\n",
    "            stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "            #existedstance_loss = loss_fct_relatedness(P_existedstance, b_existedstances.float())\n",
    "            #ideology_loss = loss_fct_relatedness(P_ideology, b_ideologies.float())\n",
    "                \n",
    "    \n",
    "            loss_test = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "            #loss_test = stance_loss\n",
    "            total_test_loss += loss_test.item()\n",
    "            \n",
    "            # Move logits and labels to CPU\n",
    "            P_relatedness = P_relatedness.to('cpu')\n",
    "            b_relatedness = b_relatedness.to('cpu')\n",
    "            P_stance = P_stance.to('cpu')\n",
    "            b_labels = b_labels.to('cpu')\n",
    "            ##b_existedstances = b_existedstances.to('cpu')\n",
    "            #P_existedstance = P_existedstance.to('cpu')\n",
    "            #P_ideology = P_ideology.to('cpu')\n",
    "            #b_ideologies = b_ideologies.to('cpu')\n",
    "            \n",
    "\n",
    "            acc_list = predict_classwise_stance_ideology(P_relatedness, P_stance, b_labels)\n",
    "            total_test_accuracy_stance += acc_list[0]\n",
    "            ###\n",
    "            agree_test_accuracy += acc_list[1]\n",
    "            disagree_test_accuracy += acc_list[2]\n",
    "            discuss_test_accuracy += acc_list[3]\n",
    "            unrelated_test_accuracy += acc_list[4]\n",
    "            predict_labels = acc_list[9]\n",
    "            \n",
    "            predict_labels = torch.argmax(prob_stance, 1)\n",
    "            my_len = len(predict_labels)\n",
    "            \n",
    "            for prob in predict_labels:\n",
    "                my_all_predictions.append(prob)\n",
    "            #for idx in range(0, my_len):\n",
    "                #my_predictions.append(str(prob_stance[idx]) + \" \" + str(predict_labels[idx]) + \"\\n\")\n",
    "\n",
    "    arr = np.array(my_all_predictions)\n",
    "    #file1 = open('myfile.txt', 'w')\n",
    "    #file1.writelines(my_predictions)\n",
    "    #file1.close()\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_test_loss = total_test_loss / len(prediction_dataloader)\n",
    "    avg_test_accuracy_stance = total_test_accuracy_stance / total_num\n",
    "    \n",
    "    avg_agree_test_acc = agree_test_accuracy / pro_val_num\n",
    "    avg_disagree_test_acc = disagree_test_accuracy / agst_val_num\n",
    "    avg_discuss_test_acc = discuss_test_accuracy / neut_val_num\n",
    "    avg_unrelated_test_acc = unrelated_test_accuracy / notrel_val_num\n",
    "\n",
    "    return avg_test_loss, avg_test_accuracy_stance, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0daf73-d45f-43e3-a9e2-e9633c572783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "def run_test_stance_ideology(test_nums, test_nums_ideology, model_current, model_savepath, all_input_ids_Test, \n",
    "                             all_input_masks_Test, stance_labels_Test, ideology_labels_Test, batch_size = 16):       \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #loss_fct = torch.nn.BCELoss()\n",
    "    loss_fct_relatedness = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    #weights_ideology = torch.tensor([my_max_train/con_train_num, my_max_train/lib_train_num, 0.01]).to(device)   \n",
    "    #loss_fct_ideology_weighted = torch.nn.BCEWithLogitsLoss(pos_weight = weights_ideology)\n",
    "    \n",
    "    t_test_relatedness, t_test_stance, t_test_mmd_symbol, t_test_mmd_symbol_, t_test_existedstance, t_test_ideology = preprocess_stance_ideology(stance_labels_Test, ideology_labels_Test)\n",
    "    #t_test_stance = preprocess_ideology_new(stance_labels_Test)\n",
    "\n",
    "    # Create the DataLoader.\n",
    "    prediction_data = TensorDataset(all_input_ids_Test, all_input_masks_Test, t_test_relatedness, t_test_stance, t_test_mmd_symbol, t_test_mmd_symbol_, t_test_existedstance, t_test_ideology)\n",
    "    #prediction_data = TensorDataset(all_input_ids_Test, all_input_masks_Test, t_test_stance)\n",
    "    prediction_sampler = SequentialSampler(prediction_data)\n",
    "    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size, num_workers=8, drop_last=False)\n",
    "    \n",
    "    pro_val_num = test_nums[0]\n",
    "    agst_val_num = test_nums[1]\n",
    "    neut_val_num = test_nums[2]\n",
    "    notrel_val_num = test_nums[3]\n",
    "    \n",
    "    ##con_val_num = 0.1\n",
    "    ##lib_val_num = 0.1\n",
    "    ##na_val_num = 0.1\n",
    "    \n",
    "    con_val_num = 0.1\n",
    "    lib_val_num = 0.1\n",
    "    na_val_num = 0.1\n",
    "    \n",
    "    \n",
    "    total_num = pro_val_num + agst_val_num + neut_val_num + notrel_val_num\n",
    "    tokenizer = load_tokenizer(model_current)\n",
    "\n",
    "        \n",
    "    model = StanceIdeologyDetectionClassMixout(model_current)\n",
    "    checkpoint = torch.load(model_savepath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])   \n",
    "    \n",
    "    \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  betas=(0.9, 0.999), \n",
    "                  eps=1e-08, \n",
    "                  weight_decay=1e-4,\n",
    "                  correct_bias=True\n",
    "    )\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    optimizer_to(optimizer,device)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    #model.cuda()\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_test_loss = 0.0\n",
    "    \n",
    "    total_test_accuracy_stance = 0.0\n",
    "    total_test_accuracy_ideology = 0.0\n",
    "    ####\n",
    "    agree_test_accuracy = 0.0\n",
    "    disagree_test_accuracy = 0.0\n",
    "    discuss_test_accuracy = 0.0\n",
    "    unrelated_test_accuracy = 0.0\n",
    "    \n",
    "    ideology_test_accuracy = 0.0\n",
    "    ideology_test_con_accuracy = 0.0\n",
    "    ideology_test_lib_accuracy = 0.0\n",
    "    ideology_test_na_accuracy = 0.0\n",
    "    predictions , true_labels = [], []\n",
    "    \n",
    "    alpha = 1.3\n",
    "    theta = 0\n",
    "    beta = 1e-3\n",
    "    gamma = 0\n",
    "    # Predict\n",
    "    my_all_batch_preds = []\n",
    "    my_predictions = []\n",
    "    my_all_predictions = []\n",
    "    for batch in prediction_dataloader:\n",
    "      #Add batch to GPU\n",
    "        \n",
    "        #batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_relatedness = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "        b_mmd_symbol = batch[4].to(device)\n",
    "        b_mmd_symbol_ = batch[5].to(device)\n",
    "        b_existedstances = batch[6].to(device)\n",
    "        b_ideologies = batch[7].to(device)\n",
    "  \n",
    "\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and \n",
    "        # speeding up prediction\n",
    "        with torch.no_grad():         \n",
    "            # Forward pass, calculate logit predictions\n",
    "            \n",
    "            n1 = torch.sum(b_mmd_symbol, dim=0)\n",
    "            n2 = torch.sum(b_mmd_symbol_, dim=0)\n",
    "        \n",
    "            aa = torch.reshape(b_mmd_symbol, (-1,1))\n",
    "            bb = torch.reshape(b_mmd_symbol_, (-1,1))\n",
    "            \n",
    "            \n",
    "            mmd_loss, P_relatedness, P_stance, P_existedstance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_, epoch_num = 12)\n",
    "            \n",
    "            #mmd_loss, P_relatedness, P_stance, P_oneside, P_ideology = model(input_ids = b_input_ids, attention_mask = b_input_mask)\n",
    "            #P_stance = model(input_ids = b_input_ids, attention_mask = b_input_mask, mmd_pl = b_mmd_symbol, mmd_pl_ = b_mmd_symbol_)\n",
    "                \n",
    "            \n",
    "            relatedness_loss = loss_fct_relatedness(P_relatedness, b_relatedness.float())\n",
    "            #relatedness_loss = 0\n",
    "            stance_loss = loss_fct_relatedness(P_stance, b_labels.float())\n",
    "            #existedstance_loss = loss_fct_relatedness(P_existedstance, b_existedstances.float())\n",
    "            #ideology_loss = loss_fct_relatedness(P_ideology, b_ideologies.float())\n",
    "                \n",
    "    \n",
    "            loss_test = alpha * stance_loss + beta * mmd_loss + relatedness_loss\n",
    "            loss_test = loss_test\n",
    "            total_test_loss += loss_test.item()\n",
    "            \n",
    "            # Move logits and labels to CPU\n",
    "            P_relatedness = P_relatedness.to('cpu')\n",
    "            b_relatedness = b_relatedness.to('cpu')\n",
    "            P_stance = P_stance.to('cpu')\n",
    "            b_labels = b_labels.to('cpu')\n",
    "            b_existedstances = b_existedstances.to('cpu')\n",
    "            #P_existedstance = P_existedstance.to('cpu')\n",
    "            #P_ideology = P_ideology.to('cpu')\n",
    "            b_ideologies = b_ideologies.to('cpu')\n",
    "                \n",
    "            \n",
    "\n",
    "            acc_list = predict_classwise_stance_ideology(P_relatedness, P_stance, P_existedstance, b_labels)\n",
    "            total_test_accuracy_stance += acc_list[0]\n",
    "            ###\n",
    "            agree_test_accuracy += acc_list[1]\n",
    "            disagree_test_accuracy += acc_list[2]\n",
    "            discuss_test_accuracy += acc_list[3]\n",
    "            unrelated_test_accuracy += acc_list[4]\n",
    "            prob_stance = acc_list[9]\n",
    "            prob_val_list = prob_stance.numpy()\n",
    "            \n",
    "            predict_labels = torch.argmax(prob_stance, 1)\n",
    "            my_len = len(prob_stance)\n",
    "            my_all_batch_preds.extend(predict_labels)\n",
    "            for prob in prob_val_list:\n",
    "                my_all_predictions.append(prob)\n",
    "            #for idx in range(0, my_len):\n",
    "                #my_predictions.append(str(prob_stance[idx]) + \" \" + str(predict_labels[idx]) + \"\\n\")\n",
    "    \n",
    "    #arr = np.array(my_all_batch_preds)\n",
    "    file1 = open('myfile.txt', 'w')\n",
    "    for elt in my_all_predictions:\n",
    "        file1.write(str(elt))\n",
    "        file1.write(str(\"\\n\"))\n",
    "    file1.close()\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_test_loss = total_test_loss / len(prediction_dataloader)\n",
    "    avg_test_accuracy_stance = total_test_accuracy_stance / total_num\n",
    "    \n",
    "    avg_agree_test_acc = agree_test_accuracy / pro_val_num\n",
    "    avg_disagree_test_acc = disagree_test_accuracy / agst_val_num\n",
    "    avg_discuss_test_acc = discuss_test_accuracy / neut_val_num\n",
    "    avg_unrelated_test_acc = unrelated_test_accuracy / notrel_val_num\n",
    "\n",
    "    return avg_test_loss, avg_test_accuracy_stance, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, my_all_batch_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d7a085-88e5-4efc-ac81-c08394721d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from random import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "\n",
    "def run_wholeprocess_stance_serp_ambigious(train_path, val_path, max_len, doc_stride, batch_size, num_warmup_steps, learning_rate, epochs, seedVal):\n",
    "    device = run_utils()\n",
    "    #model_save_path = './model_save/fnc/model_emergentbert_epoch90_withoutsep_serp.t7'  \n",
    "    model_save_path = './models/BERT_SERP/bert_titleonly_finetuned'  \n",
    "    #model_fnc = './model_save/fnc/model_fnc.t7'   \n",
    "    #model_current = \"ponmari/Question-Answering\"\n",
    "        \n",
    "    #model_current = 'distilbert-base-uncased'\n",
    "    #model_current = './models/BERT_SERP/bert_titleonly_finetuned'\n",
    "    model_current = 'roberta-base'\n",
    "    #model_current = 'bert-large-uncased'\n",
    "    #model_current = 'xlnet-base-cased'\n",
    "    #model_current = 'bert-base-multilingual-cased'\n",
    "    #model_current = 'albert-large-v1'\n",
    "    #model_current = './models/ROBERTA/checkpoint-40000'\n",
    "    #model_current = './models/BERT_SERP/bert_titleonly_finetuned_robertalarge' \n",
    "    tokenizer = load_tokenizer(model_current)\n",
    "\n",
    "#--------------LOAD DATASETS--------------#\n",
    "\n",
    "    \n",
    "    ##df = load_dataset_emergent(train_path)\n",
    "    #dfVal = load_dataset_emergent(val_path)\n",
    "    #dfTest = load_dataset_emergent(test_path)\n",
    "    \n",
    "    #df = pd.concat([df, dfVal], ignore_index=True)\n",
    "    \n",
    "\n",
    "    #train_path = './dataset/batches_cleaned/stance/Train_latest.tsv'\n",
    "    #val_path = './dataset/batches_cleaned/stance/Val_latest.tsv'\n",
    "    #test_path = './dataset/batches_cleaned/stance/Test_latest.tsv'\n",
    "\n",
    "    trainPer = 1.2\n",
    "    valPer = 0.2\n",
    "    testPer = 0.2\n",
    "    \n",
    "    #df_all = load_dataset_ambigious('./dataset/batches_cleaned/stance/FullDataset_16.09.2021.tsv')\n",
    "    #create_more_notrel_docs(df_all)\n",
    "    #df_all_added = load_dataset_stance('./dataset/batches_cleaned/stance/Final_Dataset_AddedNotRelated.tsv')\n",
    "    #df, dfVal, dfTest = sample_dataset_ambigious(df_all, seedVal)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df = load_dataset_ambigious('./dataset/batches_cleaned/stance/train_serp_ambigious.tsv')\n",
    "    dfVal = load_dataset_ambigious('./dataset/batches_cleaned/stance/val_serp_ambigious.tsv')\n",
    "    dfTest = load_dataset_ambigious('./dataset/batches_cleaned/stance/test_serp_ambigious.tsv')\n",
    "    #dfTest = load_dataset_stance('./dataset/batches_cleaned/stance/test_serp.tsv')\n",
    "    \n",
    "    #dfTest = dfTest.append(df_all_neut, ignore_index = True)\n",
    "    #dfTest.to_csv('./dataset/batches_cleaned/stance/test_serp_allneut.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    #df, dfTest = merge_datasets(df, dfVal, dfTest)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    train_nums_ideology = []\n",
    "    val_nums_ideology = []\n",
    "    test_nums_ideology = []\n",
    "    \n",
    "    #train_nums_ideology = count_class_num_ideology (df)\n",
    "    #val_nums_ideology = count_class_num_ideology (dfVal)\n",
    "    #test_nums_ideology = count_class_num_ideology (dfTest)\n",
    "\n",
    "    \n",
    "    sentencesQueryCont_Train = []\n",
    "    labelsTrain = []\n",
    "    \n",
    "    labelsTrain_ideology = []\n",
    "    labelsVal_ideology = []\n",
    "    labelsTest_ideology = []\n",
    "\n",
    "    #sentencesQueryTitle_Train, labelsTrain = generate_datasets_emergent (df)\n",
    "    sentencesQueryTitle_Train, sentencesQueryTitleCont_Train, labelsTrain, labelsTrain_ideology = generate_datasets_ambigious (df)\n",
    "\n",
    "    \n",
    "    #print(labelsTrain)\n",
    "\n",
    "    sentencesQueryCont_Val = []\n",
    "    labelsVal = []\n",
    "\n",
    "    #--------------DATASETS-------------#\n",
    "    \n",
    "    #sentencesQueryTitle_Val, labelsVal = generate_datasets_emergent (dfVal)\n",
    "    sentencesQueryTitle_Val, sentencesQueryTitleCont_Val, labelsVal, labelsVal_ideology = generate_datasets_ambigious (dfVal)\n",
    "    \n",
    "    \n",
    "    sentencesQueryCont_Test = []\n",
    "    labelsTest = []\n",
    "    \n",
    "    #sentencesQueryTitle_Test, labelsTest = generate_datasets_emergent (dfTest)\n",
    "    sentencesQueryTitle_Test, sentencesQueryTitleCont_Test, labelsTest, labelsTest_ideology = generate_datasets_ambigious (dfTest)\n",
    "    \n",
    "    \n",
    "    train_nums = count_class_num_ambigious (df)\n",
    "    val_nums = count_class_num_ambigious (dfVal)\n",
    "    test_nums = count_class_num_ambigious (dfTest)\n",
    "    \n",
    "    print(train_nums)\n",
    "        \n",
    "    # Report the number of sentences.\n",
    "    print('Number of training sentences: {:,}'.format(df.shape[0]))\n",
    "    print('Number of val sentences: {:,}'.format(dfVal.shape[0]))\n",
    "    print('Number of test sentences: {:,}'.format(dfTest.shape[0]))\n",
    "    \n",
    "    print(\"Starting neural net\")\n",
    "    \n",
    "    all_input_ids_Train, all_input_masks_Train  = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Train, max_len, doc_stride) #train\n",
    "    all_input_ids_Val, all_input_masks_Val = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Val, max_len, doc_stride) #train\n",
    "    all_input_ids_Test, all_input_masks_Test = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Test, max_len, doc_stride) #train\n",
    "    \n",
    "    train_nums_ideology = []\n",
    "    val_nums_ideology = []\n",
    "    test_nums_ideology = []\n",
    "    \n",
    "    \n",
    "    model, train_dataloader, validation_dataloader, optimizer, scheduler = prepare_for_training_ambigious(all_input_ids_Train, all_input_masks_Train, labelsTrain, all_input_ids_Val,\n",
    "                                                                                                              all_input_masks_Val, labelsVal, model_current, batch_size, epochs, num_warmup_steps, learning_rate)    \n",
    "    training_stats, last_epoch, min_val_loss, max_val_acc = train_stance_ideology (train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, train_dataloader, validation_dataloader, epochs, batch_size, optimizer,\n",
    "                                                                     scheduler, patience, verbose, delta, seedVal, False)\n",
    "    \n",
    "    \n",
    "    #test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr = run_test_stance_ideology(train_nums, train_nums_ideology, model_current, model_save_path, all_input_ids_Train, \n",
    "    #                                                                                                                                        #all_input_masks_Train, labelsTrain, labelsTrain_ideology)\n",
    "    \n",
    "    #test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr = run_test_stance_ideology(val_nums, val_nums_ideology, model_current, model_save_path, all_input_ids_Val, \n",
    "    #                                                                                                                                        all_input_masks_Val, labelsVal, labelsVal_ideology)\n",
    "    \n",
    "    test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr_test = run_test_stance_ideology(test_nums, test_nums_ideology, model_current, model_save_path, all_input_ids_Test, \n",
    "                                                                                                                                            all_input_masks_Test, labelsTest, labelsTest_ideology)\n",
    "    #df_stats = print_summary(training_stats)\n",
    "    #plot_results(df_stats, last_epoch)\n",
    "    \n",
    "    print(\"****************\")\n",
    "    print('Test Loss: ' + str(test_loss))\n",
    "    print('Test Stance Acc: ' + str(test_acc))\n",
    "    \n",
    "    print('Agree Class Acc: ' + str(avg_agree_test_acc))\n",
    "    print('Disagree Class Acc: ' + str(avg_disagree_test_acc))\n",
    "    print('Discuss Class Acc: ' + str(avg_discuss_test_acc))\n",
    "    print('Unrelated Class Acc: ' + str(avg_unrelated_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83ece2-5389-46ac-88b8-9a621b02e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from random import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "#from transformers import LongformerModel\n",
    "\n",
    "\n",
    "\n",
    "def run_wholeprocess_stance_serp_DT(train_path, val_path, max_len, doc_stride, batch_size, num_warmup_steps, learning_rate, epochs, seedVal):\n",
    "    device = run_utils()\n",
    "    #model_save_path = './model_save/fnc/model_emergentbert_epoch90_withoutsep_serp.t7'  \n",
    "    model_save_path = './models/BERT_SERP/bert_titleonly_finetuned'  \n",
    "    #model_fnc = './model_save/fnc/model_fnc.t7'   \n",
    "    #model_current = \"ponmari/Question-Answering\"\n",
    "        \n",
    "    #model_current = 'distilbert-base-uncased'\n",
    "    #model_current = './models/BERT_SERP/bert_titleonly_finetuned'\n",
    "    model_current = 'roberta-large'\n",
    "    #model_current = './models/2b/'\n",
    "    #model_current = 'bert-large-uncased'\n",
    "    #model_current = 'xlnet-large-cased'\n",
    "    #model_current = 'albert-xxlarge-v2'\n",
    "    #model_current = 'bert-base-multilingual-cased'\n",
    "    #model_current = 'albert-large-v2'\n",
    "    #model_current = './models/ROBERTA/checkpoint-40000'\n",
    "    #model_current = './models/BERT_SERP/bert_titleonly_finetuned_robertalarge'\n",
    "    #model_current = 'allenai/longformer-large-4096'\n",
    "    tokenizer = load_tokenizer(model_current)\n",
    "\n",
    "#--------------LOAD DATASETS--------------#\n",
    "\n",
    "    train_path = 'emergent_train.csv'\n",
    "    val_path = 'emergent_val.csv'\n",
    "    test_path = 'emergent_test.csv'\n",
    "    \n",
    "    ##df = load_dataset_emergent(train_path)\n",
    "    #dfVal = load_dataset_emergent(val_path)\n",
    "    #dfTest = load_dataset_emergent(test_path)\n",
    "    \n",
    "    #df = pd.concat([df, dfVal], ignore_index=True)\n",
    "    \n",
    "\n",
    "    #train_path = './dataset/batches_cleaned/stance/Train_latest.tsv'\n",
    "    #val_path = './dataset/batches_cleaned/stance/Val_latest.tsv'\n",
    "    #test_path = './dataset/batches_cleaned/stance/Test_latest.tsv'\n",
    "\n",
    "    trainPer = 1.2\n",
    "    valPer = 0.2\n",
    "    testPer = 0.2\n",
    "    \n",
    "    df_all = load_dataset_stance('./dataset/batches_cleaned/stance/MergedDataset_20.06.2021.tsv')\n",
    "    create_more_notrel_docs(df_all)\n",
    "    df_all_added = load_dataset_stance('./dataset/batches_cleaned/stance/Final_Dataset_AddedNotRelated.tsv')\n",
    "    df, dfVal, dfTest = sample_dataset_stance(df_all_added, seedVal)\n",
    "    \n",
    "    \n",
    "    df = load_dataset_stance('./dataset/batches_cleaned/stance/train_serp.tsv')\n",
    "    dfVal = load_dataset_stance('./dataset/batches_cleaned/stance/val_serp.tsv')\n",
    "    dfTest = load_dataset_stance('./dataset/batches_cleaned/stance/test_serp.tsv')\n",
    "    #dfTest = load_dataset_stance('./dataset/batches_cleaned/stance/test_serp.tsv')\n",
    "    \n",
    "    #dfTest = dfTest.append(df_all_neut, ignore_index = True)\n",
    "    #dfTest.to_csv('./dataset/batches_cleaned/stance/test_serp_allneut.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    #df, dfTest = merge_datasets(df, dfVal, dfTest)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    train_nums_ideology = []\n",
    "    val_nums_ideology = []\n",
    "    test_nums_ideology = []\n",
    "    \n",
    "    #train_nums_ideology = count_class_num_ideology (df)\n",
    "    #val_nums_ideology = count_class_num_ideology (dfVal)\n",
    "    #test_nums_ideology = count_class_num_ideology (dfTest)\n",
    "\n",
    "    \n",
    "    sentencesQueryCont_Train = []\n",
    "    labelsTrain = []\n",
    "    \n",
    "    labelsTrain_ideology = []\n",
    "    labelsVal_ideology = []\n",
    "    labelsTest_ideology = []\n",
    "\n",
    "    #sentencesQueryTitle_Train, labelsTrain = generate_datasets_emergent (df)\n",
    "    sentencesQueryTitle_Train, sentencesQueryTitleCont_Train, labelsTrain, labelsTrain_ideology = generate_datasets (df)\n",
    "\n",
    "    \n",
    "    #print(labelsTrain)\n",
    "\n",
    "    sentencesQueryCont_Val = []\n",
    "    labelsVal = []\n",
    "\n",
    "    #--------------DATASETS-------------#\n",
    "    \n",
    "    #sentencesQueryTitle_Val, labelsVal = generate_datasets_emergent (dfVal)\n",
    "    sentencesQueryTitle_Val, sentencesQueryTitleCont_Val, labelsVal, labelsVal_ideology = generate_datasets (dfVal)\n",
    "    \n",
    "    \n",
    "    sentencesQueryCont_Test = []\n",
    "    labelsTest = []\n",
    "    \n",
    "    #sentencesQueryTitle_Test, labelsTest = generate_datasets_emergent (dfTest)\n",
    "    sentencesQueryTitle_Test, sentencesQueryTitleCont_Test, labelsTest, labelsTest_ideology = generate_datasets (dfTest)\n",
    "    \n",
    "    \n",
    "    train_nums = count_class_num (df)\n",
    "    val_nums = count_class_num (dfVal)\n",
    "    test_nums = count_class_num (dfTest)\n",
    "    \n",
    "    print(train_nums)\n",
    "        \n",
    "    # Report the number of sentences.\n",
    "    print('Number of training sentences: {:,}'.format(df.shape[0]))\n",
    "    print('Number of val sentences: {:,}'.format(dfVal.shape[0]))\n",
    "    print('Number of test sentences: {:,}'.format(dfTest.shape[0]))\n",
    "    \n",
    "    print(\"Starting neural net\")\n",
    "    \n",
    "    all_input_ids_Train, all_input_masks_Train  = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Train, max_len, doc_stride) #train\n",
    "    all_input_ids_Val, all_input_masks_Val = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Val, max_len, doc_stride) #train\n",
    "    all_input_ids_Test, all_input_masks_Test = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Test, max_len, doc_stride) #train\n",
    "    \n",
    "    train_nums_ideology = []\n",
    "    val_nums_ideology = []\n",
    "    test_nums_ideology = []\n",
    "    \n",
    "    \n",
    "    #model, train_dataloader, validation_dataloader, optimizer, scheduler = prepare_for_training_stance_ideology_paper(all_input_ids_Train, all_input_masks_Train, labelsTrain, labelsTrain_ideology, all_input_ids_Val,\n",
    "    #                                                                                                          all_input_masks_Val, labelsVal, labelsVal_ideology, model_current, batch_size, epochs, num_warmup_steps, learning_rate)    \n",
    "    #training_stats, last_epoch, min_val_loss, max_val_acc = train_stance_ideology_paper (train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, train_dataloader, validation_dataloader, epochs, batch_size, optimizer,\n",
    "    #                                                                 scheduler, patience, verbose, delta, seedVal, False)\n",
    "    \n",
    "    \n",
    "    #test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr = run_test_stance_ideology(train_nums, train_nums_ideology, model_current, model_save_path, all_input_ids_Train, \n",
    "    #                                                                                                                                        all_input_masks_Train, labelsTrain, labelsTrain_ideology)\n",
    "    \n",
    "    #test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr = run_test_stance_ideology(val_nums, val_nums_ideology, model_current, model_save_path, all_input_ids_Val, \n",
    "    #                                                                                                                                        all_input_masks_Val, labelsVal, labelsVal_ideology)\n",
    "    \n",
    "    #test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr_test = run_test_stance_ideology(test_nums, test_nums_ideology, model_current, model_save_path, all_input_ids_Test, \n",
    "    #                                                                                                                                        all_input_masks_Test, labelsTest, labelsTest_ideology)\n",
    "    #df_stats = print_summary(training_stats)\n",
    "    #plot_results(df_stats, last_epoch)\n",
    "    \n",
    "    print(\"****************\")\n",
    "    #print('Test Loss: ' + str(test_loss))\n",
    "    #print('Test Stance Acc: ' + str(test_acc))\n",
    "    \n",
    "    #print('Agree Class Acc: ' + str(avg_agree_test_acc))\n",
    "    #print('Disagree Class Acc: ' + str(avg_disagree_test_acc))\n",
    "    #print('Discuss Class Acc: ' + str(avg_discuss_test_acc))\n",
    "    #print('Unrelated Class Acc: ' + str(avg_unrelated_test_acc))\n",
    "    \n",
    "    #t_test_relatedness, t_test_stance, t_test_mmd_symbol, t_test_mmd_symbol_, t_test_existedstance, t_test_ideology = preprocess_stance_ideology(labelsTest, labelsTest_ideology)\n",
    "    #true_labels = torch.argmax(t_test_stance, 1)\n",
    "    #pred_stance = torch.as_tensor(arr_test, dtype=torch.int32)\n",
    "    \n",
    "    #print(\"Confusion Matrix\")\n",
    "    \n",
    "    \n",
    "    #print(true_labels.shape[0])\n",
    "    #print(pred_stance.shape[0])\n",
    "    \n",
    "    #print (pd.DataFrame(confusion_matrix(true_labels, pred_stance), columns=['Pro','Agst','Neut','Not-rel']))\n",
    "    print(\"*********\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.concat([df, dfVal], ignore_index=True)\n",
    "    sentencesQueryTitle_Train, sentencesQueryTitleCont_Train, labelsTrain, labelsTrain_ideology = generate_datasets (df)\n",
    "    \n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    clf1 = SVC(kernel= \"linear\", class_weight= 'balanced', max_iter = 10000, probability=True, C=1)\n",
    "    #clf = CalibratedClassifierCV(svm) \n",
    "    #svm = LinearSVC(probability=True)\n",
    "    #svm = SVC(kernel='rbf', random_state=0, gamma=.01, C=1)\n",
    "    X_train = vectorizer.fit_transform(sentencesQueryTitleCont_Train)\n",
    "    X_test = vectorizer.transform(sentencesQueryTitleCont_Test)\n",
    "    \n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    #param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "    #          'kernel': ['linear']} \n",
    "  \n",
    "    #grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "    \n",
    "  \n",
    "    # fitting the model for grid search\n",
    "    #grid = grid.fit(X_train, labelsTrain)\n",
    "    #grid_predictions = grid.predict(X_test)\n",
    "  \n",
    "    # print classification report\n",
    "\n",
    "    \n",
    "    clf1 = clf1.fit(X_train, labelsTrain)\n",
    "    y_pred1 = clf1.predict(X_test)\n",
    "    print(classification_report(labelsTest, y_pred1))\n",
    "    \n",
    "    train_predictions_prob_svm = clf1.predict_proba(X_train)\n",
    "    test_predictions_prob_svm = clf1.predict_proba(X_test)\n",
    "    \n",
    "    #tree_param = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "    #clf = GridSearchCV(DecisionTreeClassifier(), tree_param, cv=5)\n",
    "    #clf.fit(X_train, labelsTrain)\n",
    "    \n",
    "    #grid_predictions = clf.predict(X_test)\n",
    "\n",
    "    # print classification report\n",
    "    #print(classification_report(labelsTest, grid_predictions))\n",
    "    \n",
    "    \n",
    "    print(\"*****************\")\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(test_predictions_prob_svm)\n",
    "    df.to_csv('svm_preds' + \".tsv\", sep='\\t', index=False)\n",
    "    \n",
    "    # Create Decision Tree classifer object\n",
    "    #clf = DecisionTreeClassifier()\n",
    "    \n",
    "    clf2 = RandomForestClassifier(max_depth=2, class_weight= 'balanced', n_estimators = 1000)\n",
    "\n",
    "    # Train Decision Tree Classifer\n",
    "    fit = clf2.fit(X_train, labelsTrain)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred2 = clf2.predict(X_test)\n",
    "    \n",
    "    print(\"*****************\")\n",
    "    \n",
    "    print(classification_report(labelsTest, y_pred2))\n",
    "    train_predictions_prob_rf = clf2.predict_proba(X_train)\n",
    "    test_predictions_prob_rf = clf1.predict_proba(X_test)\n",
    "    \n",
    "    df1 = pd.DataFrame(test_predictions_prob_rf) \n",
    "    df1.to_csv('rf_preds' + \".tsv\", sep='\\t', index=False)\n",
    "    \n",
    "    \n",
    "    df2 = pd.DataFrame(labelsTest)\n",
    "    df2.to_csv('test_labels' + \".tsv\", sep='\\t', index=False)\n",
    "    \n",
    "    \n",
    "    clf3 = XGBClassifier(use_label_encoder=True, class_weight= 'balanced', eval_metric='auc')\n",
    "    clf3.fit(X_train, labelsTrain)\n",
    "    y_pred3 = clf3.predict(X_test)\n",
    "\n",
    "    print(classification_report(labelsTest, y_pred3))\n",
    "    train_predictions_prob_xgboost = clf3.predict_proba(X_train)\n",
    "    test_predictions_prob_xgboost = clf3.predict_proba(X_test)\n",
    "    \n",
    "    df3 = pd.DataFrame(test_predictions_prob_xgboost)\n",
    "    df3.to_csv('xgboost_preds' + \".tsv\", sep='\\t', index=False)\n",
    "    \n",
    "    \n",
    "    print(train_predictions_prob_svm[0])\n",
    "    train_predictions_prob_svm = pd.DataFrame(train_predictions_prob_svm)\n",
    "    train_predictions_prob_rf = pd.DataFrame(train_predictions_prob_rf)\n",
    "    train_predictions_prob_xgboost = pd.DataFrame(train_predictions_prob_xgboost)\n",
    "    train_predictions_prob_neural = pd.DataFrame(arr)\n",
    "    \n",
    "    test_predictions_prob_svm = pd.DataFrame(test_predictions_prob_svm)\n",
    "    test_predictions_prob_rf = pd.DataFrame(test_predictions_prob_rf)\n",
    "    test_predictions_prob_xgboost = pd.DataFrame(test_predictions_prob_xgboost)\n",
    "    test_predictions_prob_neural = pd.DataFrame(arr_test)\n",
    "    \n",
    "    \n",
    "    if train_predictions_prob_neural.isnull().values.any():\n",
    "        print(\"train predictions - NAN\")\n",
    "    if test_predictions_prob_neural.isnull().values.any():\n",
    "        print(\"test predictions - NAN\")\n",
    "        \n",
    "    print(train_predictions_prob_svm.shape[0], train_predictions_prob_neural.shape[0])\n",
    "    print(len(sentencesQueryTitleCont_Train), X_train.shape[0], len(labelsTrain))\n",
    "    all_pred_prob = pd.concat([train_predictions_prob_svm, train_predictions_prob_rf, train_predictions_prob_xgboost], axis = 1, ignore_index=True)\n",
    "    all_pred_prob_test = pd.concat([test_predictions_prob_svm, test_predictions_prob_rf, test_predictions_prob_xgboost], axis = 1, ignore_index=True)\n",
    "    \n",
    "    clf1.fit(all_pred_prob, labelsTrain)\n",
    "    y_pred_new = clf1.predict(all_pred_prob_test)\n",
    "    \n",
    "    print(classification_report(labelsTest, y_pred_new))\n",
    "    \n",
    "    all_preds = pd.concat([df, df1, df2, df3], axis = 1, ignore_index=True)\n",
    "    all_preds.to_csv('all_preds' + \".tsv\", sep='\\t', index=False)\n",
    "    \n",
    "    eclf1 = VotingClassifier(estimators=[('svm', clf1), ('rf', clf2), ('xg', clf3)], voting='hard')\n",
    "    eclf1 = eclf1.fit(X_train, labelsTrain)\n",
    "    y_pred4 = eclf1.predict(X_test)\n",
    "    print(classification_report(labelsTest, y_pred4))\n",
    "    \n",
    "    eclf2 = VotingClassifier(estimators=[('svm', clf1), ('rf', clf2), ('xg', clf3)], voting='soft')\n",
    "    eclf2 = eclf2.fit(X_train, labelsTrain)\n",
    "    y_pred5 = eclf2.predict(X_test)\n",
    "    print(classification_report(labelsTest, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6276059-e924-4489-b0d5-00b3da6fd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "\n",
    "def run_wholeprocess_stance_serp(train_path, val_path, max_len, doc_stride, batch_size, num_warmup_steps, learning_rate, epochs, seedVal):\n",
    "    device = run_utils()\n",
    "    #model_save_path = './model_save/fnc/model_emergentbert_epoch90_withoutsep_serp.t7'  \n",
    "    model_save_path = './models/BERT_SERP/bert_titleonly_finetuned'  \n",
    "    #model_fnc = './model_save/fnc/model_fnc.t7'   \n",
    "    #model_current = \"ponmari/Question-Answering\"\n",
    "        \n",
    "    #model_current = 'distilbert-base-uncased'\n",
    "    #model_current = './models/BERT_SERP/bert_titleonly_finetuned'\n",
    "    #model_current = 'roberta-base'\n",
    "    #model_current = 'bert-base-uncased'\n",
    "    #model_current = 'xlnet-base-cased'\n",
    "    #model_current = 'bert-base-multilingual-cased'\n",
    "    model_current = 'albert-base-v2'\n",
    "    #model_current = './models/mnli_model/'\n",
    "    #model_current = './model_save/fnc/model_emergentbert_epoch90.t7'\n",
    "    tokenizer = load_tokenizer(model_current)\n",
    "\n",
    "#--------------LOAD DATASETS--------------#\n",
    "\n",
    "    train_path = 'emergent_train.csv'\n",
    "    val_path = 'emergent_val.csv'\n",
    "    test_path = 'emergent_test.csv'\n",
    "    \n",
    "    ##df = load_dataset_emergent(train_path)\n",
    "    #dfVal = load_dataset_emergent(val_path)\n",
    "    #dfTest = load_dataset_emergent(test_path)\n",
    "    \n",
    "    #df = pd.concat([df, dfVal], ignore_index=True)\n",
    "    \n",
    "\n",
    "    #train_path = './dataset/batches_cleaned/stance/Train_latest.tsv'\n",
    "    #val_path = './dataset/batches_cleaned/stance/Val_latest.tsv'\n",
    "    #test_path = './dataset/batches_cleaned/stance/Test_latest.tsv'\n",
    "\n",
    "    trainPer = 1.2\n",
    "    valPer = 0.2\n",
    "    testPer = 0.2\n",
    "    \n",
    "    df_all = load_dataset_stance('./dataset/batches_cleaned/stance/MergedDataset_20.06.2021.tsv')\n",
    "    create_more_notrel_docs(df_all)\n",
    "    df_all_added = load_dataset_stance('./dataset/batches_cleaned/stance/Final_Dataset_AddedNotRelated.tsv')\n",
    "    df, dfVal, dfTest = sample_dataset_stance(df_all_added, seedVal)\n",
    "    \n",
    "    \n",
    "    df = load_dataset_stance('./dataset/batches_cleaned/stance/train_serp.tsv')\n",
    "    dfVal = load_dataset_stance('./dataset/batches_cleaned/stance/val_serp.tsv')\n",
    "    dfTest = load_dataset_stance('./dataset/batches_cleaned/stance/test_serp.tsv')\n",
    "    #dfTest = load_dataset_stance('./dataset/batches_cleaned/stance/test_serp.tsv')\n",
    "    \n",
    "    #dfTest = dfTest.append(df_all_neut, ignore_index = True)\n",
    "    #dfTest.to_csv('./dataset/batches_cleaned/stance/test_serp_allneut.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    #df, dfTest = merge_datasets(df, dfVal, dfTest)\n",
    "    \n",
    "    #df = pd.concat([df, dfVal], ignore_index=True)\n",
    "    \n",
    "    train_nums = count_class_num (df)\n",
    "    val_nums = count_class_num (dfVal)\n",
    "    test_nums = count_class_num (dfTest)\n",
    "    \n",
    "    train_nums_ideology = []\n",
    "    val_nums_ideology = []\n",
    "    test_nums_ideology = []\n",
    "    \n",
    "    #train_nums_ideology = count_class_num_ideology (df)\n",
    "    #val_nums_ideology = count_class_num_ideology (dfVal)\n",
    "    #test_nums_ideology = count_class_num_ideology (dfTest)\n",
    "\n",
    "    \n",
    "    sentencesQueryCont_Train = []\n",
    "    labelsTrain = []\n",
    "    \n",
    "    labelsTrain_ideology = []\n",
    "    labelsVal_ideology = []\n",
    "    labelsTest_ideology = []\n",
    "\n",
    "    #sentencesQueryTitle_Train, labelsTrain = generate_datasets_emergent (df)\n",
    "    sentencesQueryTitle_Train, sentencesQueryTitleCont_Train, labelsTrain, labelsTrain_ideology = generate_datasets (df)\n",
    "\n",
    "    \n",
    "    #print(labelsTrain)\n",
    "\n",
    "    sentencesQueryCont_Val = []\n",
    "    labelsVal = []\n",
    "\n",
    "    #--------------DATASETS-------------#\n",
    "    \n",
    "    #sentencesQueryTitle_Val, labelsVal = generate_datasets_emergent (dfVal)\n",
    "    sentencesQueryTitle_Val, sentencesQueryTitleCont_Val, labelsVal, labelsVal_ideology = generate_datasets (dfVal)\n",
    "    \n",
    "    \n",
    "    sentencesQueryCont_Test = []\n",
    "    labelsTest = []\n",
    "    \n",
    "    #sentencesQueryTitle_Test, labelsTest = generate_datasets_emergent (dfTest)\n",
    "    sentencesQueryTitle_Test, sentencesQueryTitleCont_Test, labelsTest, labelsTest_ideology = generate_datasets (dfTest)\n",
    "    \n",
    "        \n",
    "    # Report the number of sentences.\n",
    "    print('Number of training sentences: {:,}'.format(df.shape[0]))\n",
    "    print('Number of val sentences: {:,}'.format(dfVal.shape[0]))\n",
    "    print('Number of test sentences: {:,}'.format(dfTest.shape[0]))\n",
    "\n",
    "    all_input_ids_Train, all_input_masks_Train  = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Train, max_len, doc_stride) #train\n",
    "    all_input_ids_Val, all_input_masks_Val = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Val, max_len, doc_stride) #train\n",
    "    all_input_ids_Test, all_input_masks_Test = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Test, max_len, doc_stride) #train\n",
    "    \n",
    "    \n",
    "    #all_input_ids_Train, all_input_masks_Train, a, b  = transform_sequences_longer(tokenizer, sentencesQueryTitle_Train, labelsTrain, labelsTrain_ideology, max_len, doc_stride) #train\n",
    "    #all_input_ids_Val, all_input_masks_Val, c, d = transform_sequences_longer(tokenizer, sentencesQueryTitle_Val, labelsVal, labelsVal_ideology, max_len, doc_stride) #train\n",
    "    #all_input_ids_Test, all_input_masks_Test, e, f = transform_sequences_longer(tokenizer, sentencesQueryTitle_Test, labelsTest, labelsTest_ideology, max_len, doc_stride) #train\n",
    "\n",
    "    #--------------TRAINING-------------#\n",
    "    \n",
    "\n",
    "    \n",
    "    model, train_dataloader, validation_dataloader, optimizer, scheduler = prepare_for_training_stance_ideology_paper(all_input_ids_Train, all_input_masks_Train, labelsTrain, labelsTrain_ideology, all_input_ids_Val,\n",
    "                                                                                                              all_input_masks_Val, labelsVal, labelsVal_ideology, model_current, batch_size, epochs, num_warmup_steps, learning_rate)    \n",
    "    training_stats, last_epoch, min_val_loss, max_val_acc = train_stance_ideology_paper (train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, train_dataloader, validation_dataloader, epochs, batch_size, optimizer,\n",
    "                                                                      scheduler, patience, verbose, delta, seedVal, False)\n",
    "    #\n",
    "    #model, train_dataloader, validation_dataloader, optimizer, scheduler = prepare_for_training_stance_ideology(all_input_ids_Train, all_input_masks_Train, labelsTrain, labelsTrain_ideology, all_input_masks_Train,\n",
    "    #                                                                                                           all_input_ids_Train, labelsTrain, labelsTrain_ideology, model_current, batch_size, epochs, num_warmup_steps, learning_rate)    \n",
    "    #training_stats, last_epoch, min_val_loss, max_val_acc = train_stance_ideology_novel (train_nums, train_nums, train_nums_ideology, train_nums_ideology, model_save_path, model, tokenizer, train_dataloader, validation_dataloader, epochs, batch_size, optimizer,\n",
    "    #                                                                      scheduler, patience, verbose, delta, seedVal, False)\n",
    "\n",
    "        \n",
    "    #df_stats = print_summary(training_stats)\n",
    "    #plot_results(df_stats, last_epoch)\n",
    "\n",
    "    #print('Min Val Loss: ' + str(min_val_loss))\n",
    "    #print('Max Val Acc: ' + str(max_val_acc))\n",
    "    #test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc = run_test_stance_ideology(train_nums, train_nums_ideology, model_save_path, all_input_ids_Train, all_input_masks_Train, labelsTrain, labelsTrain_ideology)\n",
    "    \n",
    "    \n",
    "    #print('Test Loss: ' + str(test_loss))\n",
    "    #print('Test Stance Acc: ' + str(test_acc))\n",
    "    \n",
    "    #print('Agree Class Acc: ' + str(avg_agree_test_acc))\n",
    "    #print('Disagree Class Acc: ' + str(avg_disagree_test_acc))\n",
    "    #print('Discuss Class Acc: ' + str(avg_discuss_test_acc))\n",
    "    #print('Unrelated Class Acc: ' + str(avg_unrelated_test_acc))\n",
    "    \n",
    "    #test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc = run_test_stance_ideology(val_nums, val_nums_ideology, model_save_path, all_input_ids_Val, all_input_masks_Val, labelsVal, labelsVal_ideology)\n",
    "    \n",
    "    \n",
    "    #print('Test Loss: ' + str(test_loss))\n",
    "    #print('Test Stance Acc: ' + str(test_acc))\n",
    "    \n",
    "    #print('Agree Class Acc: ' + str(avg_agree_test_acc))\n",
    "    #print('Disagree Class Acc: ' + str(avg_disagree_test_acc))\n",
    "    #print('Discuss Class Acc: ' + str(avg_discuss_test_acc))\n",
    "    #print('Unrelated Class Acc: ' + str(avg_unrelated_test_acc))\n",
    "\n",
    "    test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, arr = run_test_stance_ideology(test_nums, test_nums_ideology, model_current, model_save_path, all_input_ids_Test, \n",
    "                                                                                                                                            all_input_masks_Test, labelsTest, labelsTest_ideology)\n",
    "    \n",
    "    print('Test Loss: ' + str(test_loss))\n",
    "    print('Test Stance Acc: ' + str(test_acc))\n",
    "    \n",
    "    print('Agree Class Acc: ' + str(avg_agree_test_acc))\n",
    "    print('Disagree Class Acc: ' + str(avg_disagree_test_acc))\n",
    "    print('Discuss Class Acc: ' + str(avg_discuss_test_acc))\n",
    "    print('Unrelated Class Acc: ' + str(avg_unrelated_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb742f0-b20d-486a-987b-985c37fcea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "def run_wholeprocess_stance_serp2(train_path, val_path, max_len, doc_stride, batch_size, num_warmup_steps, learning_rate, epochs, seedVal):\n",
    "    device = run_utils()\n",
    "    #model_save_path = './model_save/fnc/model_emergentbert_epoch90_withoutsep_serp.t7'  \n",
    "     \n",
    "    #model_fnc = './model_save/fnc/model_fnc.t7'   \n",
    "    #model_current = \"ponmari/Question-Answering\"\n",
    "        \n",
    "    #model_current = 'distilbert-base-uncased'\n",
    "    #model_current = './models/BERT_SERP/bert_titleonly_finetuned'\n",
    "    #model_current = 'roberta-large'\n",
    "    #model_current = 'bert-base-uncased'\n",
    "    #model_current = 'xlnet-base-cased'\n",
    "    #model_current = 'bert-base-multilingual-cased'\n",
    "    #model_current = 'albert-base-v2'\n",
    "    #model_current = './models/mnli_model/'\n",
    "    #model_current = './model_save/fnc/model_emergentbert_epoch90.t7'\n",
    "    \n",
    "\n",
    "#--------------LOAD DATASETS--------------#\n",
    "\n",
    "    train_path = 'emergent_train.csv'\n",
    "    val_path = 'emergent_val.csv'\n",
    "    test_path = 'emergent_test.csv'\n",
    "    \n",
    "    ##df = load_dataset_emergent(train_path)\n",
    "    #dfVal = load_dataset_emergent(val_path)\n",
    "    #dfTest = load_dataset_emergent(test_path)\n",
    "    \n",
    "    #df = pd.concat([df, dfVal], ignore_index=True)\n",
    "    \n",
    "\n",
    "    #train_path = './dataset/batches_cleaned/stance/Train_latest.tsv'\n",
    "    #val_path = './dataset/batches_cleaned/stance/Val_latest.tsv'\n",
    "    #test_path = './dataset/batches_cleaned/stance/Test_latest.tsv'\n",
    "    \n",
    "    labelsTrain_ideology = []\n",
    "    labelsVal_ideology = []\n",
    "    labelsTest_ideology = []\n",
    "    \n",
    "    train_nums_ideology = 0\n",
    "    val_nums_ideology = 0\n",
    "    test_nums_ideology = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    trainPer = 1.2\n",
    "    valPer = 0.2\n",
    "    testPer = 0.2\n",
    "    \n",
    "    #df_all = load_dataset_stance('./dataset/batches_cleaned/stance/MergedDataset_20.06.2021.tsv')\n",
    "    #df_all_added = create_more_notrel_docs(df_all)\n",
    "    \n",
    "    df_all_added = load_dataset_stance('./dataset/batches_cleaned/stance/Final_Dataset_AddedNotRelated.tsv')\n",
    "    y = df_all_added['stance'].copy(deep=True)\n",
    "    X = df_all_added.drop('stance', axis=1).copy(deep=True)\n",
    "    \n",
    "    print(seedVal)\n",
    "    #split train and test datasets once\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state=seedVal)\n",
    "    \n",
    "    \n",
    "        \n",
    "    train_nums = count_class_num (df_all_added)\n",
    "    # Report the number of sentences.\n",
    "    print('Number of all sentences: ', train_nums)\n",
    "    \n",
    "    dfTrain = X_train.copy(deep=True)\n",
    "    dfTest = X_test.copy(deep=True)\n",
    "    \n",
    "    dfTrain.insert(2, \"stance\", y_train.values)\n",
    "    dfTest.insert(2, \"stance\", y_test.values) \n",
    "    \n",
    "    dfTrain.to_csv('./dataset/batches_cleaned/stance/train_serp.tsv', sep='\\t', index=False)\n",
    "    dfTest.to_csv('./dataset/batches_cleaned/stance/test_serp.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    test_nums = count_class_num (dfTest)\n",
    "    print('Number of test sentences: {:,}'.format(dfTest.shape[0]))\n",
    "    \n",
    "    #X_train.to_csv('./dataset/batches_cleaned/stance/train_serp.tsv', sep='\\t', index=False)\n",
    "    #X_val.to_csv('./dataset/batches_cleaned/stance/val_serp.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    k_fold = 5\n",
    "    model_list = ['xlnet-base-cased', 'xlnet-base-cased']\n",
    "    \n",
    "    \n",
    "    num_base_models = len(model_list)\n",
    "    model_save_list = []\n",
    "    model_losses = []\n",
    "    all_val_folds_all_predictions = np.empty((100, num_base_models*4))\n",
    "    all_val_encoded_targets = np.empty((100, 4))\n",
    "    best_val_losses = []\n",
    "    best_model_savepaths = []\n",
    "    for idx in range(0, k_fold):\n",
    "        X = pd.DataFrame (columns=['qID', 'docID', 'ideology', 'docCont' 'Q', 'title'])\n",
    "        y = pd.DataFrame (columns=['stance'])\n",
    "        \n",
    "        X_2 = pd.DataFrame (columns=['qID', 'docID', 'ideology', 'docCont' 'Q', 'title'])\n",
    "        y_2 = pd.DataFrame (columns=['stance'])\n",
    "        \n",
    "        print(\"******************\")\n",
    "        print(\"Training is starting for cross validation dataset \" + str(idx))\n",
    "        print(\"******************\")\n",
    "        \n",
    "        seedVal = get_random_seed()\n",
    "        print(seedVal)\n",
    "        \n",
    "        #creating a k-fold CV\n",
    "        X, X_2, y, y_2 = train_test_split(X_train, y_train, test_size=1.0/k_fold, shuffle = True, random_state = seedVal)\n",
    "        \n",
    "        df = X.copy(deep=True)\n",
    "        dfVal = X_2.copy(deep=True)\n",
    "        \n",
    "        df.insert(2, \"stance\", y.values)\n",
    "        dfVal.insert(2, \"stance\", y_2.values)\n",
    "        \n",
    "        df.to_csv('./dataset/batches_cleaned/stance/train_serp' + \"_\" + str(idx) + \".tsv\", sep='\\t', index=False)\n",
    "        dfVal.to_csv('./dataset/batches_cleaned/stance/val_serp' + \"_\" + str(idx) + \".tsv\", sep='\\t', index=False)\n",
    "        \n",
    "        #df = pd.read_csv('./dataset/batches_cleaned/stance/train_serp' + \"_\" + str(idx) + \".tsv\", sep='\\t')\n",
    "        #dfVal = pd.read_csv('./dataset/batches_cleaned/stance/val_serp' + \"_\" + str(idx) + \".tsv\", sep='\\t')\n",
    "        \n",
    "        #df = pd.read_csv(path, delimiter='\\t', header = 0, names=['qID', 'docID', 'stance', 'ideology', 'docCont', 'Q', 'title']\n",
    "        \n",
    "        \n",
    "    \n",
    "        train_nums = count_class_num (df)\n",
    "        val_nums = count_class_num (dfVal)\n",
    "\n",
    "    \n",
    "        #sentencesQueryCont_Train = []\n",
    "        labelsTrain = []\n",
    "\n",
    "        #sentencesQueryTitle_Train, labelsTrain = generate_datasets_emergent (df)\n",
    "        sentencesQueryTitle_Train, sentencesQueryTitleCont_Train, labelsTrain, labelsTrain_ideology = generate_datasets (df)\n",
    "\n",
    "\n",
    "        #sentencesQueryCont_Val = []\n",
    "        labelsVal = []\n",
    "\n",
    "        #--------------DATASETS-------------#\n",
    "    \n",
    "        #sentencesQueryTitle_Val, labelsVal = generate_datasets_emergent (dfVal)\n",
    "        sentencesQueryTitle_Val, sentencesQueryTitleCont_Val, labelsVal, labelsVal_ideology = generate_datasets (dfVal)\n",
    "        \n",
    "        encoded_current_val_targets = preprocess_stance_ideology_meta(labelsVal)\n",
    "        if idx == 0:\n",
    "            all_val_encoded_targets = encoded_current_val_targets\n",
    "        else:\n",
    "            all_val_encoded_targets = np.concatenate((all_val_encoded_targets, encoded_current_val_targets))\n",
    "    \n",
    "        # Report the number of sentences.\n",
    "        print('Number of training sentences: ', train_nums)\n",
    "        print('Number of val sentences: ', val_nums)\n",
    "        \n",
    "        #first: bert-base, second: roberta-base, third: xlnet-base\n",
    "        \n",
    "        current_val_fold_all_predictions = np.empty((dfVal.shape[0], num_base_models))\n",
    "        \n",
    "        for idxModel in range(0, num_base_models):\n",
    "            \n",
    "            model_current = model_list[idxModel]\n",
    "            tokenizer = load_tokenizer(model_current)\n",
    "            \n",
    "            #tokenize the dataset for current k-fold training and val\n",
    "            model_save_path = './models/BERT_SERP/model_finetuned' + \"_\" + str(idxModel) + \"_\" + str(idx)\n",
    "            if idxModel % 2 == 1:\n",
    "            \n",
    "                all_input_ids_Train, all_input_masks_Train  = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Train, max_len, doc_stride) #train\n",
    "                all_input_ids_Val, all_input_masks_Val = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Val, max_len, doc_stride) #train\n",
    "\n",
    "            #--------------TRAINING-------------#\n",
    "        \n",
    "            \n",
    "                model, train_dataloader, validation_dataloader, optimizer, scheduler = prepare_for_training_stance_ideology_paper(all_input_ids_Train, all_input_masks_Train, labelsTrain, labelsTrain_ideology, all_input_ids_Val,\n",
    "                                                                            all_input_masks_Val, labelsVal, labelsVal_ideology, model_current, batch_size, epochs, num_warmup_steps, learning_rate)    \n",
    "                training_stats, last_epoch, min_val_loss, max_val_acc = train_stance_ideology_paper (train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, train_dataloader, validation_dataloader, epochs, batch_size, optimizer,\n",
    "                                                                            scheduler, patience, verbose, delta, seedVal, False)\n",
    "                \n",
    "                val_loss, val_acc, avg_agree_val_acc, avg_disagree_val_acc, avg_discuss_val_acc, avg_unrelated_val_acc, val_predictions = run_test_stance_ideology(val_nums, val_nums_ideology, model_current, model_save_path, all_input_ids_Val, all_input_masks_Val, labelsVal, labelsVal_ideology)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                all_input_ids_Train, all_input_masks_Train  = preprocessing_for_bert(tokenizer, sentencesQueryTitle_Train, max_len, doc_stride) #train\n",
    "                all_input_ids_Val, all_input_masks_Val = preprocessing_for_bert(tokenizer, sentencesQueryTitle_Val, max_len, doc_stride) #train\n",
    "            \n",
    "            \n",
    "                model, train_dataloader, validation_dataloader, optimizer, scheduler = prepare_for_training_stance_ideology_paper(all_input_ids_Train, all_input_masks_Train, labelsTrain, labelsTrain_ideology, all_input_ids_Val,\n",
    "                                                                            all_input_masks_Val, labelsVal, labelsVal_ideology, model_current, batch_size, epochs, num_warmup_steps, learning_rate)    \n",
    "                training_stats, last_epoch, min_val_loss, max_val_acc = train_stance_ideology_paper(train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path, model, train_dataloader, validation_dataloader, epochs, batch_size, optimizer,\n",
    "                                                                            scheduler, patience, verbose, delta, seedVal, False)\n",
    "        \n",
    "        \n",
    "                val_loss, val_acc, avg_agree_val_acc, avg_disagree_val_acc, avg_discuss_val_acc, avg_unrelated_val_acc, val_predictions = run_test_stance_ideology(val_nums, val_nums_ideology, model_current, model_save_path, all_input_ids_Val, all_input_masks_Val, labelsVal, labelsVal_ideology)\n",
    "            #if idx == 0:\n",
    "                #best_val_losses.append(val_loss)\n",
    "                #best_model_savepaths.append(model_save_path)\n",
    "            #else:\n",
    "                #if val_loss < best_val_losses[idxModel]:\n",
    "                    #best_val_losses[idxModel] = val_loss\n",
    "                    #best_model_savepaths[idxModel] = model_save_path\n",
    "            \n",
    "            print(len(val_predictions))\n",
    "            if idxModel == 0:\n",
    "                current_val_fold_all_predictions = val_predictions\n",
    "            else:\n",
    "                current_val_fold_all_predictions = np.concatenate((current_val_fold_all_predictions, val_predictions), axis=1)\n",
    "                \n",
    "            print(current_val_fold_all_predictions.shape)\n",
    "\n",
    "        print(\"**************\")\n",
    "        print(current_val_fold_all_predictions)\n",
    "        current_concat_meta_layer_features = np.concatenate((all_input_ids_Val, all_input_masks_Val, current_val_fold_all_predictions), axis=1)\n",
    "        \n",
    "        \n",
    "        filename_fold_predictions = './dataset/batches_cleaned/stance/cv_set_val_predictions_' + str(idx) + '.tsv'\n",
    "        pd.DataFrame(current_val_fold_all_predictions).to_csv(filename_fold_predictions, sep='\\t', header=None, index=None)\n",
    "        \n",
    "        filename_fold_targets = './dataset/batches_cleaned/stance/cv_set_val_targets_' + str(idx) + '.tsv'\n",
    "        pd.DataFrame(encoded_current_val_targets).to_csv(filename_fold_targets, sep='\\t', header=None, index=None)\n",
    "    \n",
    "        if idx == 0:\n",
    "            all_val_folds_all_predictions = current_val_fold_all_predictions\n",
    "        else:\n",
    "            all_val_folds_all_predictions = np.concatenate((all_val_folds_all_predictions,current_val_fold_all_predictions))\n",
    "    \n",
    "    #all_val_encoded_targets_tensor = torch.cat(all_val_encoded_targets, dim=0)\n",
    "    #meta-learner phase\n",
    "    \n",
    "    current_val_fold_all_predictions = np.empty((100, num_base_models))\n",
    "    encoded_current_val_targets = np.empty((100, k_fold))\n",
    "    for idx in range(0, k_fold):\n",
    "        filename_curr = './dataset/batches_cleaned/stance/cv_set_val_predictions_' + str(idx) + '.tsv'\n",
    "        current_val_fold_all_predictions = pd.read_csv(filename_curr, sep='\\t', header = 0, dtype='float64')\n",
    "        \n",
    "        \n",
    "        filename_fold_targets = './dataset/batches_cleaned/stance/cv_set_val_targets_' + str(idx) + '.tsv'\n",
    "        encoded_current_val_targets = pd.read_csv(filename_fold_targets, sep='\\t', header = 0, dtype='int64')\n",
    "        #current_val_fold_all_predictions = np.loadtxt(filename_curr, dtype=float)\n",
    "        \n",
    "        if idx == 0:\n",
    "            all_val_folds_all_predictions = current_val_fold_all_predictions\n",
    "            all_val_encoded_targets = encoded_current_val_targets\n",
    "        else:\n",
    "            all_val_folds_all_predictions = np.concatenate((all_val_folds_all_predictions, current_val_fold_all_predictions))\n",
    "            all_val_encoded_targets = np.concatenate((all_val_encoded_targets, encoded_current_val_targets))\n",
    "    \n",
    "    \n",
    "    for idxModel in range(0, num_base_models):\n",
    "        model_save_path = './models/BERT_SERP/model_finetuned' + \"_\" + str(idxModel) + \"_\" + str(0)\n",
    "        best_model_savepaths.append(model_save_path)\n",
    "\n",
    "    print(\"---------------\")\n",
    "    print(all_val_folds_all_predictions.shape)\n",
    "    print(all_val_encoded_targets.shape)\n",
    "    print(\"Meta Learning Training is Starting...\")\n",
    "    \n",
    "    X = pd.DataFrame (columns=['qID', 'docID', 'ideology', 'docCont' 'Q', 'title'])\n",
    "    y = pd.DataFrame (columns=['pro', 'agst', 'neut', 'not-rel'])\n",
    "        \n",
    "    X_val = pd.DataFrame (columns=['qID', 'docID', 'ideology', 'docCont' 'Q', 'title'])\n",
    "    y_val = pd.DataFrame (columns=['pro', 'agst', 'neut', 'not-rel'])\n",
    "    \n",
    "    new_df = pd.DataFrame(all_val_folds_all_predictions)\n",
    "    new_y = pd.DataFrame(all_val_encoded_targets)\n",
    "    \n",
    "    new_df  = new_df.iloc[: , -16:]\n",
    "    \n",
    "    #creating a k-fold CV\n",
    "    X, X_val, y, y_val = train_test_split(new_df, new_y, test_size=0.25, shuffle = True, random_state = seedVal, stratify = new_y)\n",
    "    \n",
    "    print(y)\n",
    "    y = y.replace(-1, 1)\n",
    "    y_val = y_val.replace(-1, 1)\n",
    "    \n",
    "    print(y)\n",
    "    \n",
    "    \n",
    "    df = X.copy()\n",
    "    dfVal = X_val.copy()\n",
    "\n",
    "    \n",
    "    #There is a problem here!\n",
    "    train_nums = count_class_num (y)\n",
    "    val_nums = count_class_num (y_val)\n",
    "    \n",
    "    print(train_nums)\n",
    "    print(val_nums)\n",
    "    \n",
    "    model_save_path_metalearner = './models/BERT_SERP/metalearner'\n",
    "    \n",
    "    \n",
    "    model, train_dataloader, validation_dataloader, optimizer, scheduler = prepare_for_training_stance_ideology_metalearner(X, y, X_val, y_val, batch_size, epochs, num_warmup_steps, learning_rate)\n",
    "    training_stats, last_epoch, min_val_loss, max_val_acc = train_stance_ideology_metalearner (train_nums, val_nums, train_nums_ideology, val_nums_ideology, model_save_path_metalearner, model, train_dataloader, validation_dataloader, epochs, batch_size, optimizer,\n",
    "                                                                            scheduler, patience, verbose, delta, seedVal, False)    \n",
    "    \n",
    "    \n",
    "    print(\"Testing phase is starting...\")\n",
    "    #apply the same process to the test set\n",
    "    \n",
    "    sentencesQueryCont_Test = []\n",
    "    labelsTest = []\n",
    "    \n",
    "    #sentencesQueryTitle_Test, labelsTest = generate_datasets_emergent (dfTest)\n",
    "    sentencesQueryTitle_Test, sentencesQueryTitleCont_Test, labelsTest, labelsTest_ideology = generate_datasets (dfTest)\n",
    "\n",
    "    \n",
    "    current_test_fold_all_predictions = np.empty((dfTest.shape[0], num_base_models))\n",
    "    for idxModel in range(0, num_base_models):\n",
    "        model_current = model_list[idxModel]\n",
    "        tokenizer = load_tokenizer(model_current)\n",
    "        \n",
    "        all_input_ids_Test, all_input_masks_Test = preprocessing_for_bert(tokenizer, sentencesQueryTitleCont_Test, max_len, doc_stride) #test\n",
    "        \n",
    "        model_save_path = './models/BERT_SERP/model_finetuned' + \"_\" + str(idxModel) + \"_\" + str(4)\n",
    "        \n",
    "        print(\"Current best model: \" + str(model_save_path))\n",
    "        \n",
    "        test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc, test_predictions = run_test_stance_ideology(test_nums, test_nums_ideology, model_current, \n",
    "        model_save_path, all_input_ids_Test, all_input_masks_Test, labelsTest, labelsTest_ideology)\n",
    "        \n",
    "        if idxModel == 0:\n",
    "            current_test_fold_all_predictions = test_predictions\n",
    "        else:\n",
    "            current_test_fold_all_predictions = np.concatenate((current_test_fold_all_predictions, test_predictions), axis=1)\n",
    "            \n",
    "    print(current_test_fold_all_predictions.shape)\n",
    "    print(labelsTest.shape)\n",
    "    \n",
    "    print(\"Testing Meta phase is starting...\")\n",
    " \n",
    "    test_loss, test_acc, avg_agree_test_acc, avg_disagree_test_acc, avg_discuss_test_acc, avg_unrelated_test_acc = run_test_stance_ideology_meta(test_nums, test_nums_ideology, model_current, model_save_path_metalearner, current_test_fold_all_predictions, labelsTest, labelsTest_ideology)\n",
    "    \n",
    "    print(\"****************\")\n",
    "    print('Test Loss: ' + str(test_loss))\n",
    "    print('Test Stance Acc: ' + str(test_acc))\n",
    "    \n",
    "    print('Agree Class Acc: ' + str(avg_agree_test_acc))\n",
    "    print('Disagree Class Acc: ' + str(avg_disagree_test_acc))\n",
    "    print('Discuss Class Acc: ' + str(avg_discuss_test_acc))\n",
    "    print('Unrelated Class Acc: ' + str(avg_unrelated_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b83361-d9d9-4e85-b98d-4bcbc899fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_determinism(seedVal):\n",
    "    torch.manual_seed(seedVal)\n",
    "    torch.cuda.manual_seed(seedVal)\n",
    "    np.random.seed(seedVal)\n",
    "    random.seed(seedVal)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb1799-7772-4a39-bc69-0dcf66d88779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%rm -rf \"./runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb5c6a-189d-4c52-94b2-a309594574be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#with zipfile.ZipFile('./dataset/file.zip', 'r') as zip_ref:\n",
    "    #zip_ref.extractall('./dataset/myFolder/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb531782-c469-4a39-b95e-03f954ec17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5832ef-2749-497b-8ce8-c752290f9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "import time\n",
    "import datetime\n",
    "from transformers import AutoModel\n",
    "from transformers import DistilBertModel\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_ipynb\n",
    "import module_mix\n",
    "from module_mix import MixLinear\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#model = \"bert-base-uncased\"\n",
    "train_path = './dataset/fnc/train'\n",
    "val_path = './dataset/fnc/test'\n",
    "\n",
    "model_save_path = './model_save'\n",
    "\n",
    "\n",
    "max_len = 512\n",
    "doc_stride = 0\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "num_warmup_steps = 10\n",
    "learning_rate = 1e-5\n",
    "##-----Early Stopping\n",
    "patience = 10\n",
    "verbose = True\n",
    "delta = 0.000001\n",
    "#seedVal = 42\n",
    "\n",
    "seedVal = get_random_seed()\n",
    "print(seedVal)\n",
    "\n",
    "#value = randint(0, 100)\n",
    "\n",
    "\n",
    "#0 - tinybert\n",
    "#1 - distilbert\n",
    "#2 - bert\n",
    "\n",
    "#bert_type = 2\n",
    "\n",
    "#create_determinism(seedVal)\n",
    "\n",
    "#folder_preparations()\n",
    "run_wholeprocess_stance_serp_DT(train_path, val_path, max_len, doc_stride, batch_size, num_warmup_steps, learning_rate, epochs, seedVal)\n",
    "#run_wholeprocess_stance_serp(train_path, val_path, max_len, doc_stride, batch_size, num_warmup_steps, learning_rate, epochs, seedVal)\n",
    "#create_more_notrel_docs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
