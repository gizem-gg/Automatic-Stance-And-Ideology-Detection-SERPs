{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3612e-f0d8-4658-9720-389b0760a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "#4.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7dc8d-333b-464f-89f3-c3d868cc9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75fc76-c0a5-4e6b-ba3a-71fde07a8698",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cda4b-e6bf-4060-a8c0-53d54200e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, AutoModel\n",
    "import import_ipynb\n",
    "from datasets import load_dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5955301-fdfe-4d24-b77a-55d44c2f809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"dataset/...\"\n",
    "path2 = \"dataset/...\"\n",
    "#onlyfiles = [f for f in listdir(path1) if isfile(join(path1, f))]\n",
    "all_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9338101-fd4b-4358-aeb6-aa475d860776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concanListStrings(list1, list2):\n",
    "    list3 = []\n",
    "    myLen1 = len(list1)\n",
    "    if myLen1 != len(list2):\n",
    "        print(\"Length - error\")\n",
    "    for idx in range(0, myLen1):\n",
    "        list3.append(list1[idx] + \" \" + list2[idx])\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7d89e-db56-4e9c-b786-da3ca0373988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the datasets with the different fields.\n",
    "def generate_datasets(df):\n",
    "    sentencesTitle = df.title.values\n",
    "    sentencesCont = df.docCont.values\n",
    "    sentencesTitleCont = concanListStrings(sentencesTitle, sentencesCont)\n",
    "\n",
    "    return sentencesTitleCont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fade3-ab58-439a-9ee8-7337ca501c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_huggingface(dataset):\n",
    "    def join(example):\n",
    "        example['text'] = ' '.join(str(example['title']) + str(example['docCont']))\n",
    "        return example\n",
    "\n",
    "    return dataset.map(join, num_proc=8, remove_columns=['link', 'title', 'docCont'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7e3f4-8eab-43d6-b875-9892e1b41eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(block_size:int):\n",
    "    def func(examples):\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result['labels'] = result['input_ids'].copy()\n",
    "        return result\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8df4c5-a04b-4e7a-ad95-866bc466c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tokenizer):\n",
    "    def func(df):\n",
    "        return tokenizer(df['text'])\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e00c0d-2b62-488e-a97f-4c2dceb8ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model.cuda()\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe72a9a-acb5-4f6a-b67b-1340ea7b1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_from_disk\n",
    "\n",
    "my_path = \"dataset/...\"\n",
    "lm_dataset = load_from_disk(my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adeb11-7ba0-4535-9034-b1e1a112e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de598808-9705-4136-a21b-7edb5a905c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8b7d8-aa8a-4369-bfbf-68a0bfd5041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "output_dir=\"./models/ROBERTA/\",\n",
    "evaluation_strategy='epoch',\n",
    "save_steps = 10000,\n",
    "num_train_epochs = 2,\n",
    "learning_rate = 2e-5,\n",
    "logging_steps = 10000,\n",
    "disable_tqdm = True,\n",
    "weight_decay = 0.1,\n",
    "adam_beta2  = 0.98,\n",
    "adam_epsilon = 1e-6,\n",
    "warmup_ratio  = 0.1,\n",
    "gradient_accumulation_steps = 2)\n",
    "\n",
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=lm_dataset['train'],\n",
    "eval_dataset=lm_dataset['test'],\n",
    "data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff4b0d-4edd-4994-9f40-169e3e8468f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Started training\")\n",
    "trainer.train(\"./models/ROBERTA/checkpoint-30000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d37e4-8722-44e4-8652-b12446757ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {np.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bf9bc-31f8-4997-a154-2b03e8a478a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving the model\")\n",
    "model.save_pretrained('./models/BERT_SERP/mlm_model_serp_en.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
